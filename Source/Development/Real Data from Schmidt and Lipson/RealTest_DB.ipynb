{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import sys \n",
                "sys.path.append(r'../../Python Script/')\n",
                "\n",
                "from sympy import symbols, simplify, derive_by_array\n",
                "from scipy.integrate import solve_ivp\n",
                "from xLSINDy import *\n",
                "from sympy.physics.mechanics import *\n",
                "from sympy import *\n",
                "import sympy\n",
                "import torch\n",
                "import HLsearch as HL\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "def generate_data(func, time, init_values):\n",
                "    sol = solve_ivp(func,[time[0],time[-1]],init_values,t_eval=time, method='RK45',rtol=1e-10,atol=1e-10)\n",
                "    return sol.y.T, np.array([func(0,sol.y.T[i,:]) for i in range(sol.y.T.shape[0])],dtype=np.float64)\n",
                "\n",
                "def pendulum(t,x):\n",
                "    return x[1],-9.81*np.sin(x[0])\n",
                "\n",
                "# Pendulum rod lengths (m), bob masses (kg).\n",
                "L1, L2 = 1, 1\n",
                "m1, m2 = 1, 1\n",
                "# The gravitational acceleration (m.s-2).\n",
                "g = 9.81\n",
                "tau = 0\n",
                "\n",
                "def doublePendulum(t,y,M=0.0):\n",
                "    q1,q2,q1_t,q2_t = y\n",
                "    q1_2t = (-L1*g*m1*np.sin(q1) - L1*g*m2*np.sin(q1) + M + m2*(2*L1*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q1)*q1_t - 2*L1*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q1)*q1_t)/2 - m2*(2*L1*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q1)*q1_t + 2*L1*(-L1*np.sin(q1)*q1_t**2 - L2*np.sin(q2)*q2_t**2)*np.cos(q1) - 2*L1*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q1)*q1_t + 2*L1*(L1*np.cos(q1)*q1_t**2 + L2*np.cos(q2)*q2_t**2)*np.sin(q1))/2 - m2*(2*L1*L2*np.sin(q1)*np.sin(q2) + 2*L1*L2*np.cos(q1)*np.cos(q2))*(-L2*g*m2*np.sin(q2) + m2*(2*L2*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q2)*q2_t - 2*L2*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q2)*q2_t)/2 - m2*(2*L2*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q2)*q2_t + 2*L2*(-L1*np.sin(q1)*q1_t**2 - L2*np.sin(q2)*q2_t**2)*np.cos(q2) - 2*L2*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q2)*q2_t + 2*L2*(L1*np.cos(q1)*q1_t**2 + L2*np.cos(q2)*q2_t**2)*np.sin(q2))/2 - m2*(2*L1*L2*np.sin(q1)*np.sin(q2) + 2*L1*L2*np.cos(q1)*np.cos(q2))*(-L1*g*m1*np.sin(q1) - L1*g*m2*np.sin(q1) + M + m2*(2*L1*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q1)*q1_t - 2*L1*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q1)*q1_t)/2 - m2*(2*L1*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q1)*q1_t + 2*L1*(-L1*np.sin(q1)*q1_t**2 - L2*np.sin(q2)*q2_t**2)*np.cos(q1) - 2*L1*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q1)*q1_t + 2*L1*(L1*np.cos(q1)*q1_t**2 + L2*np.cos(q2)*q2_t**2)*np.sin(q1))/2)/(2*(m1*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2 + m2*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2)))/(2*(-m2**2*(2*L1*L2*np.sin(q1)*np.sin(q2) + 2*L1*L2*np.cos(q1)*np.cos(q2))**2/(4*(m1*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2 + m2*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2)) + m2*(2*L2**2*np.sin(q2)**2 + 2*L2**2*np.cos(q2)**2)/2)))/(m1*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2 + m2*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2)\n",
                "    q2_2t = (-L2*g*m2*np.sin(q2) + m2*(2*L2*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q2)*q2_t - 2*L2*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q2)*q2_t)/2 - m2*(2*L2*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q2)*q2_t + 2*L2*(-L1*np.sin(q1)*q1_t**2 - L2*np.sin(q2)*q2_t**2)*np.cos(q2) - 2*L2*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q2)*q2_t + 2*L2*(L1*np.cos(q1)*q1_t**2 + L2*np.cos(q2)*q2_t**2)*np.sin(q2))/2 - m2*(2*L1*L2*np.sin(q1)*np.sin(q2) + 2*L1*L2*np.cos(q1)*np.cos(q2))*(-L1*g*m1*np.sin(q1) - L1*g*m2*np.sin(q1) + M + m2*(2*L1*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q1)*q1_t - 2*L1*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q1)*q1_t)/2 - m2*(2*L1*(L1*np.sin(q1)*q1_t + L2*np.sin(q2)*q2_t)*np.cos(q1)*q1_t + 2*L1*(-L1*np.sin(q1)*q1_t**2 - L2*np.sin(q2)*q2_t**2)*np.cos(q1) - 2*L1*(L1*np.cos(q1)*q1_t + L2*np.cos(q2)*q2_t)*np.sin(q1)*q1_t + 2*L1*(L1*np.cos(q1)*q1_t**2 + L2*np.cos(q2)*q2_t**2)*np.sin(q1))/2)/(2*(m1*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2 + m2*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2)))/(-m2**2*(2*L1*L2*np.sin(q1)*np.sin(q2) + 2*L1*L2*np.cos(q1)*np.cos(q2))**2/(4*(m1*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2 + m2*(2*L1**2*np.sin(q1)**2 + 2*L1**2*np.cos(q1)**2)/2)) + m2*(2*L2**2*np.sin(q2)**2 + 2*L2**2*np.cos(q2)**2)/2)\n",
                "    return q1_t,q2_t,q1_2t,q2_2t"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Saving Directory\n",
                "rootdir = \"invar_datasets/real_double_pend_h_1.csv\"\n",
                "save = False\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Check data from Schimdt and Lipson\n",
                "\n",
                "data = np.genfromtxt(rootdir,delimiter=',')\n",
                "\n",
                "trial = data[:,0]\n",
                "t = np.arange(len(data))\n",
                "X_real = data[:,2:6]\n",
                "Xdot_real = data[:,6:]\n",
                "\n",
                "boundaryid = np.where(trial==0)[0][-1] + 1\n",
                "\n",
                "X = X_real[:boundaryid]\n",
                "Xdot = Xdot_real[:boundaryid]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "states are: (x0, x1, x0_t, x1_t)\n",
                        "states derivatives are:  (x0_t, x1_t, x0_tt, x1_tt)\n"
                    ]
                }
            ],
            "source": [
                "states_dim = 4\n",
                "states = ()\n",
                "states_dot = ()\n",
                "for i in range(states_dim):\n",
                "    if(i<states_dim//2):\n",
                "        states = states + (symbols('x{}'.format(i)),)\n",
                "        states_dot = states_dot + (symbols('x{}_t'.format(i)),)\n",
                "    else:\n",
                "        states = states + (symbols('x{}_t'.format(i-states_dim//2)),)\n",
                "        states_dot = states_dot + (symbols('x{}_tt'.format(i-states_dim//2)),)\n",
                "print('states are:',states)\n",
                "print('states derivatives are: ', states_dot)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Turn from sympy to str\n",
                "states_sym = states\n",
                "states_dot_sym = states_dot\n",
                "states = list(str(descr) for descr in states)\n",
                "states_dot = list(str(descr) for descr in states_dot)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "#build function expression for the library in str\n",
                "exprdummy = HL.buildFunctionExpressions(1,states_dim,states,use_sine=True)\n",
                "polynom = exprdummy[2:4]\n",
                "trig = exprdummy[4:]\n",
                "polynom = HL.buildFunctionExpressions(2,len(polynom),polynom)\n",
                "trig = HL.buildFunctionExpressions(2, len(trig),trig)\n",
                "product = []\n",
                "for p in polynom:\n",
                "    for t in trig:\n",
                "        product.append(p + '*' + t)\n",
                "expr = polynom + trig + product"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creating library tensor\n",
                "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "## separating known and unknown terms ##\n",
                "expr = np.array(expr)\n",
                "i1 = np.where(expr == 'x0_t**2')[0]\n",
                "\n",
                "## Garbage terms ##\n",
                "\n",
                "'''\n",
                "Explanation :\n",
                "x0_t, x1_t terms are not needed and will always satisfy EL's equation.\n",
                "Since x0_t, x1_t are garbages, we want to avoid (x0_t*sin()**2 + x0_t*cos()**2), thus we remove\n",
                "one of them, either  x0_t*sin()**2 or x0_t*cos()**2. \n",
                "Since the known term is x0_t**2, we also want to avoid the solution of (x0_t**2*sin()**2 + x0_t**2*cos()**2),\n",
                "so we remove either one of x0_t**2*sin()**2 or x0_t**2*cos()**2.\n",
                "'''\n",
                "\n",
                "\n",
                "i2 = np.where(expr == 'x0_t**2*cos(x0)**2')[0]\n",
                "i3 = np.where(expr == 'x0_t**2*cos(x1)**2')[0]\n",
                "i7 = np.where(expr == 'x1_t*cos(x0)**2')[0]\n",
                "i8 = np.where(expr == 'x1_t*cos(x1)**2')[0]\n",
                "i9 = np.where(expr == 'x1_t')[0]\n",
                "i10 = np.where(expr == 'x0_t*cos(x0)**2')[0]\n",
                "i11 = np.where(expr == 'x0_t*cos(x1)**2')[0]\n",
                "i12 = np.where(expr == 'x0_t')[0]\n",
                "i13 = np.where(expr == 'cos(x0)**2')[0]\n",
                "i14 = np.where(expr == 'cos(x1)**2')[0]\n",
                "\n",
                "#Deleting unused terms \n",
                "idx = np.arange(0,len(expr))\n",
                "idx = np.delete(idx,[i1,i2,i3,i7,i8,i9,i10,i11,i12,i13,i14])\n",
                "known_expr = expr[i1].tolist()\n",
                "expr = np.delete(expr,[i1,i2,i3,i7,i8,i9,i10,i11,i12,i13,i14])\n",
                "\n",
                "\n",
                "#Deleting unused terms \n",
                "idx = np.arange(0,len(expr))\n",
                "idx = np.delete(idx,[i1])\n",
                "known_expr = expr[i1].tolist()\n",
                "expr = np.delete(expr,[i1])\n",
                "\n",
                "#non-penalty index from prev knowledge\n",
                "i4 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i5 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i6 = np.where(expr == 'cos(x1)')[0][0]\n",
                "nonpenaltyidx = [i4, i5, i6]\n",
                "\n",
                "expr = expr.tolist()\n",
                "\n",
                "Zeta_ = Zeta[:,:,i1,:].clone().detach()\n",
                "Eta_ = Eta[:,:,i1,:].clone().detach()\n",
                "Delta_ = Delta[:,i1,:].clone().detach()\n",
                "\n",
                "Zeta = Zeta[:,:,idx,:]\n",
                "Eta = Eta[:,:,idx,:]\n",
                "Delta = Delta[:,idx,:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Moving to Cuda\n",
                "device = 'cuda:0'\n",
                "\n",
                "Zeta = Zeta.to(device)\n",
                "Eta = Eta.to(device)\n",
                "Delta = Delta.to(device)\n",
                "\n",
                "Zeta_ = Zeta_.to(device)\n",
                "Eta_ = Eta_.to(device)\n",
                "Delta_ = Delta_.to(device)\n",
                "\n",
                "UpsilonL = Upsilonforward(Zeta, Eta, Delta, Xdot, device)\n",
                "UpsilonR = Upsilonforward(Zeta_, Eta_, Delta_, Xdot, device)\n",
                "scale = torch.ones(UpsilonL.shape[1])\n",
                "\n",
                "## Scaling for upsilon\n",
                "for i in range(UpsilonL.shape[1]):\n",
                "    scale[i] = UpsilonL[:,i,:].max() - UpsilonL[:,i,:].min()\n",
                "    if(scale[i]!=0):\n",
                "        UpsilonL[:,i,:] = UpsilonL[:,i,:]/scale[i] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "xi_L = torch.ones(len(expr), device=device).data.uniform_(-10,10).requires_grad_(True)\n",
                "prevxi_L = xi_L.clone().detach()\n",
                "c = torch.ones(len(known_expr), device=device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "def loss(pred, targ):\n",
                "    loss = torch.mean((pred - targ)**2) \n",
                "    return loss "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clip(w, alpha):\n",
                "    clipped = torch.minimum(w,alpha)\n",
                "    clipped = torch.maximum(clipped,-alpha)\n",
                "    return clipped\n",
                "\n",
                "def proxL1norm(w_hat, alpha, nonpenaltyidx):\n",
                "    if(torch.is_tensor(alpha)==False):\n",
                "        alpha = torch.tensor(alpha)\n",
                "    w = w_hat - clip(w_hat,alpha)\n",
                "    for idx in nonpenaltyidx:\n",
                "        w[idx] = w_hat[idx]\n",
                "    return w"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "def training_loop(c,coef, prevcoef, UpsilonR, UpsilonL, xdot, bs, lr, lam, momentum=True):\n",
                "    loss_list = []\n",
                "    tl = xdot.shape[0]\n",
                "    n = xdot.shape[1]\n",
                "\n",
                "    if(torch.is_tensor(xdot)==False):\n",
                "        xdot = torch.from_numpy(xdot).to(device).float()\n",
                "    \n",
                "    v = coef.clone().detach().requires_grad_(True)\n",
                "    prev = v\n",
                "    \n",
                "    for i in range(tl//bs):\n",
                "                \n",
                "        #computing acceleration with momentum\n",
                "        if(momentum==True):\n",
                "            vhat = (v + ((i-1)/(i+2))*(v - prev)).clone().detach().requires_grad_(True)\n",
                "        else:\n",
                "            vhat = v.requires_grad_(True).clone().detach().requires_grad_(True)\n",
                "   \n",
                "        prev = v\n",
                "\n",
                "        #Computing loss\n",
                "        upsilonL = UpsilonL[:,:,i*bs:(i+1)*bs]\n",
                "        upsilonR = UpsilonR[:,:,i*bs:(i+1)*bs]\n",
                " \n",
                "        x_t = xdot[i*bs:(i+1)*bs,:]\n",
                "\n",
                "        #forward\n",
                "        pred = torch.einsum('jkl,k->jl', upsilonL, vhat)\n",
                "        targ = torch.einsum('jkl,k->jl', upsilonR, c)\n",
                "        \n",
                "        lossval = loss(pred, -targ)\n",
                "        print(lossval.item())\n",
                "        \n",
                "        #Backpropagation\n",
                "        lossval.backward()\n",
                "\n",
                "        with torch.no_grad():\n",
                "            v = vhat - lr*vhat.grad\n",
                "            v = (proxL1norm(v,lr*lam,nonpenaltyidx))\n",
                "            \n",
                "            # Manually zero the gradients after updating weights\n",
                "            vhat.grad = None\n",
                "        \n",
                "        \n",
                "    \n",
                "        \n",
                "        loss_list.append(lossval.item())\n",
                "    print(\"Average loss : \" , torch.tensor(loss_list).mean().item())\n",
                "    return v, prevcoef, torch.tensor(loss_list).mean().item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Epoch 0/5000\n",
                        "Learning rate :  0.001\n",
                        "5662.8505859375\n",
                        "5359.0615234375\n",
                        "5619.509765625\n",
                        "7971.91357421875\n",
                        "5937.744140625\n",
                        "4372.734375\n",
                        "Average loss :  5820.63525390625\n",
                        "\n",
                        "\n",
                        "Epoch 1/5000\n",
                        "Learning rate :  0.001\n",
                        "5629.7275390625\n",
                        "5326.26806640625\n",
                        "5580.39794921875\n",
                        "7913.15673828125\n",
                        "5893.8056640625\n",
                        "4343.5576171875\n",
                        "Average loss :  5781.15234375\n",
                        "\n",
                        "\n",
                        "Epoch 2/5000\n",
                        "Learning rate :  0.001\n",
                        "5596.83837890625\n",
                        "5293.7021484375\n",
                        "5541.599609375\n",
                        "7854.8798828125\n",
                        "5850.2255859375\n",
                        "4314.60009765625\n",
                        "Average loss :  5741.974609375\n",
                        "\n",
                        "\n",
                        "Epoch 3/5000\n",
                        "Learning rate :  0.001\n",
                        "5564.1826171875\n",
                        "5261.3623046875\n",
                        "5503.1103515625\n",
                        "7797.080078125\n",
                        "5807.0048828125\n",
                        "4285.859375\n",
                        "Average loss :  5703.10009765625\n",
                        "\n",
                        "\n",
                        "Epoch 4/5000\n",
                        "Learning rate :  0.001\n",
                        "5531.7568359375\n",
                        "5229.2490234375\n",
                        "5464.9296875\n",
                        "7739.75244140625\n",
                        "5764.1376953125\n",
                        "4257.333984375\n",
                        "Average loss :  5664.52685546875\n",
                        "\n",
                        "\n",
                        "Epoch 5/5000\n",
                        "Learning rate :  0.001\n",
                        "5499.560546875\n",
                        "5197.3583984375\n",
                        "5427.0537109375\n",
                        "7682.892578125\n",
                        "5721.623046875\n",
                        "4229.02294921875\n",
                        "Average loss :  5626.25244140625\n",
                        "\n",
                        "\n",
                        "Epoch 6/5000\n",
                        "Learning rate :  0.001\n",
                        "5467.5927734375\n",
                        "5165.68896484375\n",
                        "5389.478515625\n",
                        "7626.4970703125\n",
                        "5679.45556640625\n",
                        "4200.92333984375\n",
                        "Average loss :  5588.27294921875\n",
                        "\n",
                        "\n",
                        "Epoch 7/5000\n",
                        "Learning rate :  0.001\n",
                        "5435.84912109375\n",
                        "5134.2412109375\n",
                        "5352.2041015625\n",
                        "7570.5615234375\n",
                        "5637.6318359375\n",
                        "4173.033203125\n",
                        "Average loss :  5550.58642578125\n",
                        "\n",
                        "\n",
                        "Epoch 8/5000\n",
                        "Learning rate :  0.001\n",
                        "5404.3291015625\n",
                        "5103.013671875\n",
                        "5315.2275390625\n",
                        "7515.08203125\n",
                        "5596.1494140625\n",
                        "4145.3515625\n",
                        "Average loss :  5513.19189453125\n",
                        "\n",
                        "\n",
                        "Epoch 9/5000\n",
                        "Learning rate :  0.001\n",
                        "5373.0302734375\n",
                        "5072.00390625\n",
                        "5278.546875\n",
                        "7460.0546875\n",
                        "5555.0048828125\n",
                        "4117.8759765625\n",
                        "Average loss :  5476.0859375\n",
                        "\n",
                        "\n",
                        "Epoch 10/5000\n",
                        "Learning rate :  0.001\n",
                        "5341.951171875\n",
                        "5041.21142578125\n",
                        "5242.15966796875\n",
                        "7405.47607421875\n",
                        "5514.1962890625\n",
                        "4090.60546875\n",
                        "Average loss :  5439.26708984375\n",
                        "\n",
                        "\n",
                        "Epoch 11/5000\n",
                        "Learning rate :  0.001\n",
                        "5311.08984375\n",
                        "5010.6337890625\n",
                        "5206.0625\n",
                        "7351.341796875\n",
                        "5473.7197265625\n",
                        "4063.538330078125\n",
                        "Average loss :  5402.73095703125\n",
                        "\n",
                        "\n",
                        "Epoch 12/5000\n",
                        "Learning rate :  0.001\n",
                        "5280.4453125\n",
                        "4980.26953125\n",
                        "5170.25732421875\n",
                        "7297.658203125\n",
                        "5433.59130859375\n",
                        "4036.703857421875\n",
                        "Average loss :  5366.48779296875\n",
                        "\n",
                        "\n",
                        "Epoch 13/5000\n",
                        "Learning rate :  0.001\n",
                        "5250.0380859375\n",
                        "4950.1533203125\n",
                        "5134.763671875\n",
                        "7244.4345703125\n",
                        "5393.80615234375\n",
                        "4010.08154296875\n",
                        "Average loss :  5330.54638671875\n",
                        "\n",
                        "\n",
                        "Epoch 14/5000\n",
                        "Learning rate :  0.001\n",
                        "5219.84814453125\n",
                        "4920.24951171875\n",
                        "5099.55224609375\n",
                        "7191.64453125\n",
                        "5354.34375\n",
                        "3983.65966796875\n",
                        "Average loss :  5294.88330078125\n",
                        "\n",
                        "\n",
                        "Epoch 15/5000\n",
                        "Learning rate :  0.001\n",
                        "5189.8779296875\n",
                        "4890.5634765625\n",
                        "5064.63623046875\n",
                        "7139.31201171875\n",
                        "5315.23046875\n",
                        "3957.445068359375\n",
                        "Average loss :  5259.51123046875\n",
                        "\n",
                        "\n",
                        "Epoch 16/5000\n",
                        "Learning rate :  0.001\n",
                        "5160.13330078125\n",
                        "4861.09765625\n",
                        "5030.00927734375\n",
                        "7087.4150390625\n",
                        "5276.43505859375\n",
                        "3931.42529296875\n",
                        "Average loss :  5224.41943359375\n",
                        "\n",
                        "\n",
                        "Epoch 17/5000\n",
                        "Learning rate :  0.001\n",
                        "5130.59765625\n",
                        "4831.8369140625\n",
                        "4995.6572265625\n",
                        "7035.939453125\n",
                        "5237.955078125\n",
                        "3905.599365234375\n",
                        "Average loss :  5189.59716796875\n",
                        "\n",
                        "\n",
                        "Epoch 18/5000\n",
                        "Learning rate :  0.001\n",
                        "5101.26806640625\n",
                        "4802.78076171875\n",
                        "4961.5791015625\n",
                        "6984.880859375\n",
                        "5199.78759765625\n",
                        "3879.96484375\n",
                        "Average loss :  5155.04345703125\n",
                        "\n",
                        "\n",
                        "Epoch 19/5000\n",
                        "Learning rate :  0.001\n",
                        "5072.1435546875\n",
                        "4773.9267578125\n",
                        "4927.77099609375\n",
                        "6934.2373046875\n",
                        "5161.9306640625\n",
                        "3854.52099609375\n",
                        "Average loss :  5120.75537109375\n",
                        "\n",
                        "\n",
                        "Epoch 20/5000\n",
                        "Learning rate :  0.001\n",
                        "5043.22265625\n",
                        "4745.2734375\n",
                        "4894.23193359375\n",
                        "6884.0048828125\n",
                        "5124.3798828125\n",
                        "3829.26611328125\n",
                        "Average loss :  5086.72998046875\n",
                        "\n",
                        "\n",
                        "Epoch 21/5000\n",
                        "Learning rate :  0.001\n",
                        "5014.50341796875\n",
                        "4716.8193359375\n",
                        "4860.958984375\n",
                        "6834.1787109375\n",
                        "5087.134765625\n",
                        "3804.198974609375\n",
                        "Average loss :  5052.96533203125\n",
                        "\n",
                        "\n",
                        "Epoch 22/5000\n",
                        "Learning rate :  0.001\n",
                        "4985.984375\n",
                        "4688.5634765625\n",
                        "4827.9501953125\n",
                        "6784.7578125\n",
                        "5050.19091796875\n",
                        "3779.317626953125\n",
                        "Average loss :  5019.4609375\n",
                        "\n",
                        "\n",
                        "Epoch 23/5000\n",
                        "Learning rate :  0.001\n",
                        "4957.6640625\n",
                        "4660.5048828125\n",
                        "4795.203125\n",
                        "6735.736328125\n",
                        "5013.546875\n",
                        "3754.62109375\n",
                        "Average loss :  4986.21240234375\n",
                        "\n",
                        "\n",
                        "Epoch 24/5000\n",
                        "Learning rate :  0.001\n",
                        "4929.5419921875\n",
                        "4632.640625\n",
                        "4762.7158203125\n",
                        "6687.1123046875\n",
                        "4977.2001953125\n",
                        "3730.107666015625\n",
                        "Average loss :  4953.22021484375\n",
                        "\n",
                        "\n",
                        "Epoch 25/5000\n",
                        "Learning rate :  0.001\n",
                        "4901.615234375\n",
                        "4604.970703125\n",
                        "4730.4853515625\n",
                        "6638.8818359375\n",
                        "4941.14794921875\n",
                        "3705.776123046875\n",
                        "Average loss :  4920.47998046875\n",
                        "\n",
                        "\n",
                        "Epoch 26/5000\n",
                        "Learning rate :  0.001\n",
                        "4873.88330078125\n",
                        "4577.4931640625\n",
                        "4698.5107421875\n",
                        "6591.04150390625\n",
                        "4905.38720703125\n",
                        "3681.625\n",
                        "Average loss :  4887.98974609375\n",
                        "\n",
                        "\n",
                        "Epoch 27/5000\n",
                        "Learning rate :  0.001\n",
                        "4846.34423828125\n",
                        "4550.208984375\n",
                        "4666.79638671875\n",
                        "6543.61572265625\n",
                        "4869.9453125\n",
                        "3657.6904296875\n",
                        "Average loss :  4855.7666015625\n",
                        "\n",
                        "\n",
                        "Epoch 28/5000\n",
                        "Learning rate :  0.001\n",
                        "4819.0341796875\n",
                        "4523.162109375\n",
                        "4635.3671875\n",
                        "6496.6181640625\n",
                        "4834.8125\n",
                        "3633.941162109375\n",
                        "Average loss :  4823.822265625\n",
                        "\n",
                        "\n",
                        "Epoch 29/5000\n",
                        "Learning rate :  0.001\n",
                        "4791.91796875\n",
                        "4496.302734375\n",
                        "4604.1875\n",
                        "6449.99951171875\n",
                        "4799.962890625\n",
                        "3610.36767578125\n",
                        "Average loss :  4792.123046875\n",
                        "\n",
                        "\n",
                        "Epoch 30/5000\n",
                        "Learning rate :  0.001\n",
                        "4764.990234375\n",
                        "4469.6298828125\n",
                        "4573.25390625\n",
                        "6403.7578125\n",
                        "4765.3955078125\n",
                        "3586.968994140625\n",
                        "Average loss :  4760.666015625\n",
                        "\n",
                        "\n",
                        "Epoch 31/5000\n",
                        "Learning rate :  0.001\n",
                        "4738.2490234375\n",
                        "4443.14208984375\n",
                        "4542.564453125\n",
                        "6357.8896484375\n",
                        "4731.10791015625\n",
                        "3563.742919921875\n",
                        "Average loss :  4729.44921875\n",
                        "\n",
                        "\n",
                        "Epoch 32/5000\n",
                        "Learning rate :  0.001\n",
                        "4711.69384765625\n",
                        "4416.837890625\n",
                        "4512.11669921875\n",
                        "6312.3916015625\n",
                        "4697.0966796875\n",
                        "3540.688720703125\n",
                        "Average loss :  4698.470703125\n",
                        "\n",
                        "\n",
                        "Epoch 33/5000\n",
                        "Learning rate :  0.001\n",
                        "4685.32275390625\n",
                        "4390.71630859375\n",
                        "4481.9091796875\n",
                        "6267.26025390625\n",
                        "4663.35986328125\n",
                        "3517.8046875\n",
                        "Average loss :  4667.72900390625\n",
                        "\n",
                        "\n",
                        "Epoch 34/5000\n",
                        "Learning rate :  0.001\n",
                        "4659.134765625\n",
                        "4364.77587890625\n",
                        "4451.93994140625\n",
                        "6222.4931640625\n",
                        "4629.89599609375\n",
                        "3495.090087890625\n",
                        "Average loss :  4637.22119140625\n",
                        "\n",
                        "\n",
                        "Epoch 35/5000\n",
                        "Learning rate :  0.001\n",
                        "4633.126953125\n",
                        "4339.01513671875\n",
                        "4422.20703125\n",
                        "6178.0869140625\n",
                        "4596.7021484375\n",
                        "3472.543212890625\n",
                        "Average loss :  4606.94677734375\n",
                        "\n",
                        "\n",
                        "Epoch 36/5000\n",
                        "Learning rate :  0.001\n",
                        "4607.30078125\n",
                        "4313.43212890625\n",
                        "4392.7080078125\n",
                        "6134.0380859375\n",
                        "4563.77490234375\n",
                        "3450.162353515625\n",
                        "Average loss :  4576.90283203125\n",
                        "\n",
                        "\n",
                        "Epoch 37/5000\n",
                        "Learning rate :  0.001\n",
                        "4581.65234375\n",
                        "4288.02685546875\n",
                        "4363.44091796875\n",
                        "6090.34423828125\n",
                        "4531.1142578125\n",
                        "3427.947265625\n",
                        "Average loss :  4547.08740234375\n",
                        "\n",
                        "\n",
                        "Epoch 38/5000\n",
                        "Learning rate :  0.001\n",
                        "4556.181640625\n",
                        "4262.79736328125\n",
                        "4334.40380859375\n",
                        "6047.00244140625\n",
                        "4498.71630859375\n",
                        "3405.895751953125\n",
                        "Average loss :  4517.49951171875\n",
                        "\n",
                        "\n",
                        "Epoch 39/5000\n",
                        "Learning rate :  0.001\n",
                        "4530.8876953125\n",
                        "4237.7421875\n",
                        "4305.595703125\n",
                        "6004.0087890625\n",
                        "4466.580078125\n",
                        "3384.00732421875\n",
                        "Average loss :  4488.13671875\n",
                        "\n",
                        "\n",
                        "Epoch 40/5000\n",
                        "Learning rate :  0.001\n",
                        "4505.76806640625\n",
                        "4212.86083984375\n",
                        "4277.013671875\n",
                        "5961.3623046875\n",
                        "4434.7021484375\n",
                        "3362.27978515625\n",
                        "Average loss :  4458.998046875\n",
                        "\n",
                        "\n",
                        "Epoch 41/5000\n",
                        "Learning rate :  0.001\n",
                        "4480.822265625\n",
                        "4188.1513671875\n",
                        "4248.65625\n",
                        "5919.0576171875\n",
                        "4403.0810546875\n",
                        "3340.713134765625\n",
                        "Average loss :  4430.080078125\n",
                        "\n",
                        "\n",
                        "Epoch 42/5000\n",
                        "Learning rate :  0.001\n",
                        "4456.048828125\n",
                        "4163.61328125\n",
                        "4220.521484375\n",
                        "5877.09375\n",
                        "4371.71435546875\n",
                        "3319.30517578125\n",
                        "Average loss :  4401.3828125\n",
                        "\n",
                        "\n",
                        "Epoch 43/5000\n",
                        "Learning rate :  0.001\n",
                        "4431.4462890625\n",
                        "4139.244140625\n",
                        "4192.607421875\n",
                        "5835.46728515625\n",
                        "4340.6005859375\n",
                        "3298.05517578125\n",
                        "Average loss :  4372.9033203125\n",
                        "\n",
                        "\n",
                        "Epoch 44/5000\n",
                        "Learning rate :  0.001\n",
                        "4407.01416015625\n",
                        "4115.0439453125\n",
                        "4164.912109375\n",
                        "5794.1748046875\n",
                        "4309.73681640625\n",
                        "3276.96142578125\n",
                        "Average loss :  4344.640625\n",
                        "\n",
                        "\n",
                        "Epoch 45/5000\n",
                        "Learning rate :  0.001\n",
                        "4382.75\n",
                        "4091.01025390625\n",
                        "4137.4345703125\n",
                        "5753.2138671875\n",
                        "4279.12109375\n",
                        "3256.02294921875\n",
                        "Average loss :  4316.59228515625\n",
                        "\n",
                        "\n",
                        "Epoch 46/5000\n",
                        "Learning rate :  0.001\n",
                        "4358.65625\n",
                        "4067.148681640625\n",
                        "4110.181640625\n",
                        "5712.6005859375\n",
                        "4248.77197265625\n",
                        "3235.255859375\n",
                        "Average loss :  4288.76904296875\n",
                        "\n",
                        "\n",
                        "Epoch 47/5000\n",
                        "Learning rate :  0.001\n",
                        "4334.7490234375\n",
                        "4043.46826171875\n",
                        "4083.156494140625\n",
                        "5672.32958984375\n",
                        "4218.67822265625\n",
                        "3214.6513671875\n",
                        "Average loss :  4261.17236328125\n",
                        "\n",
                        "\n",
                        "Epoch 48/5000\n",
                        "Learning rate :  0.001\n",
                        "4311.02197265625\n",
                        "4019.966552734375\n",
                        "4056.3583984375\n",
                        "5632.400390625\n",
                        "4188.83447265625\n",
                        "3194.204833984375\n",
                        "Average loss :  4233.7978515625\n",
                        "\n",
                        "\n",
                        "Epoch 49/5000\n",
                        "Learning rate :  0.001\n",
                        "4287.4638671875\n",
                        "3996.6298828125\n",
                        "4029.770263671875\n",
                        "5592.791015625\n",
                        "4159.23095703125\n",
                        "3173.908935546875\n",
                        "Average loss :  4206.63232421875\n",
                        "\n",
                        "\n",
                        "Epoch 50/5000\n",
                        "Learning rate :  0.001\n",
                        "4264.068359375\n",
                        "3973.45458984375\n",
                        "4003.389892578125\n",
                        "5553.49951171875\n",
                        "4129.8642578125\n",
                        "3153.76220703125\n",
                        "Average loss :  4179.67333984375\n",
                        "\n",
                        "\n",
                        "Epoch 51/5000\n",
                        "Learning rate :  0.001\n",
                        "4240.83349609375\n",
                        "3950.439208984375\n",
                        "3977.2158203125\n",
                        "5514.5224609375\n",
                        "4100.7333984375\n",
                        "3133.763427734375\n",
                        "Average loss :  4152.91796875\n",
                        "\n",
                        "\n",
                        "Epoch 52/5000\n",
                        "Learning rate :  0.001\n",
                        "4217.7587890625\n",
                        "3927.581787109375\n",
                        "3951.245849609375\n",
                        "5475.857421875\n",
                        "4071.83642578125\n",
                        "3113.911865234375\n",
                        "Average loss :  4126.36572265625\n",
                        "\n",
                        "\n",
                        "Epoch 53/5000\n",
                        "Learning rate :  0.001\n",
                        "4194.841796875\n",
                        "3904.88232421875\n",
                        "3925.478759765625\n",
                        "5437.501953125\n",
                        "4043.1708984375\n",
                        "3094.205810546875\n",
                        "Average loss :  4100.013671875\n",
                        "\n",
                        "\n",
                        "Epoch 54/5000\n",
                        "Learning rate :  0.001\n",
                        "4172.08251953125\n",
                        "3882.3388671875\n",
                        "3899.91259765625\n",
                        "5399.453125\n",
                        "4014.735107421875\n",
                        "3074.64404296875\n",
                        "Average loss :  4073.861083984375\n",
                        "\n",
                        "\n",
                        "Epoch 55/5000\n",
                        "Learning rate :  0.001\n",
                        "4149.4794921875\n",
                        "3859.951171875\n",
                        "3874.5458984375\n",
                        "5361.708984375\n",
                        "3986.52734375\n",
                        "3055.226318359375\n",
                        "Average loss :  4047.906494140625\n",
                        "\n",
                        "\n",
                        "Epoch 56/5000\n",
                        "Learning rate :  0.001\n",
                        "4127.03125\n",
                        "3837.717041015625\n",
                        "3849.376953125\n",
                        "5324.2666015625\n",
                        "3958.54541015625\n",
                        "3035.951171875\n",
                        "Average loss :  4022.147705078125\n",
                        "\n",
                        "\n",
                        "Epoch 57/5000\n",
                        "Learning rate :  0.001\n",
                        "4104.73828125\n",
                        "3815.636474609375\n",
                        "3824.404052734375\n",
                        "5287.123046875\n",
                        "3930.787353515625\n",
                        "3016.814208984375\n",
                        "Average loss :  3996.583984375\n",
                        "\n",
                        "\n",
                        "Epoch 58/5000\n",
                        "Learning rate :  0.001\n",
                        "4082.593017578125\n",
                        "3793.70361328125\n",
                        "3799.62841796875\n",
                        "5250.28125\n",
                        "3903.2568359375\n",
                        "2997.8125\n",
                        "Average loss :  3971.212646484375\n",
                        "\n",
                        "\n",
                        "Epoch 59/5000\n",
                        "Learning rate :  0.001\n",
                        "4060.59765625\n",
                        "3771.9169921875\n",
                        "3775.05126953125\n",
                        "5213.7431640625\n",
                        "3875.9521484375\n",
                        "2978.9423828125\n",
                        "Average loss :  3946.033935546875\n",
                        "\n",
                        "\n",
                        "Epoch 60/5000\n",
                        "Learning rate :  0.001\n",
                        "4038.7470703125\n",
                        "3750.275390625\n",
                        "3750.6669921875\n",
                        "5177.4970703125\n",
                        "3848.8662109375\n",
                        "2960.2109375\n",
                        "Average loss :  3921.043701171875\n",
                        "\n",
                        "\n",
                        "Epoch 61/5000\n",
                        "Learning rate :  0.001\n",
                        "4017.0458984375\n",
                        "3728.782470703125\n",
                        "3726.472412109375\n",
                        "5141.541015625\n",
                        "3821.99658203125\n",
                        "2941.616943359375\n",
                        "Average loss :  3896.242431640625\n",
                        "\n",
                        "\n",
                        "Epoch 62/5000\n",
                        "Learning rate :  0.001\n",
                        "3995.4931640625\n",
                        "3707.43701171875\n",
                        "3702.4658203125\n",
                        "5105.87109375\n",
                        "3795.341796875\n",
                        "2923.15869140625\n",
                        "Average loss :  3871.628173828125\n",
                        "\n",
                        "\n",
                        "Epoch 63/5000\n",
                        "Learning rate :  0.001\n",
                        "3974.087890625\n",
                        "3686.23876953125\n",
                        "3678.64599609375\n",
                        "5070.486328125\n",
                        "3768.900146484375\n",
                        "2904.835693359375\n",
                        "Average loss :  3847.19921875\n",
                        "\n",
                        "\n",
                        "Epoch 64/5000\n",
                        "Learning rate :  0.001\n",
                        "3952.8291015625\n",
                        "3665.18603515625\n",
                        "3655.010986328125\n",
                        "5035.3837890625\n",
                        "3742.669677734375\n",
                        "2886.646728515625\n",
                        "Average loss :  3822.954345703125\n",
                        "\n",
                        "\n",
                        "Epoch 65/5000\n",
                        "Learning rate :  0.001\n",
                        "3931.71533203125\n",
                        "3644.27783203125\n",
                        "3631.55908203125\n",
                        "5000.56005859375\n",
                        "3716.6484375\n",
                        "2868.59130859375\n",
                        "Average loss :  3798.891845703125\n",
                        "\n",
                        "\n",
                        "Epoch 66/5000\n",
                        "Learning rate :  0.001\n",
                        "3910.74609375\n",
                        "3623.512939453125\n",
                        "3608.2890625\n",
                        "4966.013671875\n",
                        "3690.8349609375\n",
                        "2850.66748046875\n",
                        "Average loss :  3775.0107421875\n",
                        "\n",
                        "\n",
                        "Epoch 67/5000\n",
                        "Learning rate :  0.001\n",
                        "3889.919921875\n",
                        "3602.89111328125\n",
                        "3585.19970703125\n",
                        "4931.74267578125\n",
                        "3665.227294921875\n",
                        "2832.874755859375\n",
                        "Average loss :  3751.309326171875\n",
                        "\n",
                        "\n",
                        "Epoch 68/5000\n",
                        "Learning rate :  0.001\n",
                        "3869.2353515625\n",
                        "3582.41015625\n",
                        "3562.288818359375\n",
                        "4897.744140625\n",
                        "3639.82421875\n",
                        "2815.212646484375\n",
                        "Average loss :  3727.785888671875\n",
                        "\n",
                        "\n",
                        "Epoch 69/5000\n",
                        "Learning rate :  0.001\n",
                        "3848.6923828125\n",
                        "3562.069580078125\n",
                        "3539.5556640625\n",
                        "4864.0166015625\n",
                        "3614.623779296875\n",
                        "2797.678955078125\n",
                        "Average loss :  3704.439453125\n",
                        "\n",
                        "\n",
                        "Epoch 70/5000\n",
                        "Learning rate :  0.001\n",
                        "3828.289306640625\n",
                        "3541.86865234375\n",
                        "3516.998046875\n",
                        "4830.556640625\n",
                        "3589.62353515625\n",
                        "2780.2734375\n",
                        "Average loss :  3681.268310546875\n",
                        "\n",
                        "\n",
                        "Epoch 71/5000\n",
                        "Learning rate :  0.001\n",
                        "3808.025146484375\n",
                        "3521.806396484375\n",
                        "3494.61474609375\n",
                        "4797.36279296875\n",
                        "3564.8232421875\n",
                        "2762.99560546875\n",
                        "Average loss :  3658.271484375\n",
                        "\n",
                        "\n",
                        "Epoch 72/5000\n",
                        "Learning rate :  0.001\n",
                        "3787.89892578125\n",
                        "3501.88134765625\n",
                        "3472.40478515625\n",
                        "4764.4326171875\n",
                        "3540.219970703125\n",
                        "2745.843505859375\n",
                        "Average loss :  3635.446533203125\n",
                        "\n",
                        "\n",
                        "Epoch 73/5000\n",
                        "Learning rate :  0.001\n",
                        "3767.909912109375\n",
                        "3482.0927734375\n",
                        "3450.3662109375\n",
                        "4731.76416015625\n",
                        "3515.81298828125\n",
                        "2728.816650390625\n",
                        "Average loss :  3612.793701171875\n",
                        "\n",
                        "\n",
                        "Epoch 74/5000\n",
                        "Learning rate :  0.001\n",
                        "3748.056884765625\n",
                        "3462.43994140625\n",
                        "3428.498291015625\n",
                        "4699.35546875\n",
                        "3491.599853515625\n",
                        "2711.9140625\n",
                        "Average loss :  3590.310546875\n",
                        "\n",
                        "\n",
                        "Epoch 75/5000\n",
                        "Learning rate :  0.001\n",
                        "3728.3388671875\n",
                        "3442.92138671875\n",
                        "3406.798828125\n",
                        "4667.203125\n",
                        "3467.57958984375\n",
                        "2695.134765625\n",
                        "Average loss :  3567.99609375\n",
                        "\n",
                        "\n",
                        "Epoch 76/5000\n",
                        "Learning rate :  0.001\n",
                        "3708.754638671875\n",
                        "3423.53662109375\n",
                        "3385.266845703125\n",
                        "4635.306640625\n",
                        "3443.7509765625\n",
                        "2678.47802734375\n",
                        "Average loss :  3545.849365234375\n",
                        "\n",
                        "\n",
                        "Epoch 77/5000\n",
                        "Learning rate :  0.001\n",
                        "3689.3037109375\n",
                        "3404.284423828125\n",
                        "3363.90087890625\n",
                        "4603.66259765625\n",
                        "3420.111328125\n",
                        "2661.94091796875\n",
                        "Average loss :  3523.8671875\n",
                        "\n",
                        "\n",
                        "Epoch 78/5000\n",
                        "Learning rate :  0.001\n",
                        "3669.986572265625\n",
                        "3385.163818359375\n",
                        "3342.703125\n",
                        "4572.279296875\n",
                        "3396.66357421875\n",
                        "2645.517578125\n",
                        "Average loss :  3502.052490234375\n",
                        "\n",
                        "\n",
                        "Epoch 79/5000\n",
                        "Learning rate :  0.001\n",
                        "3650.805419921875\n",
                        "3366.173095703125\n",
                        "3321.6708984375\n",
                        "4541.1494140625\n",
                        "3373.403076171875\n",
                        "2629.21435546875\n",
                        "Average loss :  3480.402587890625\n",
                        "\n",
                        "\n",
                        "Epoch 80/5000\n",
                        "Learning rate :  0.001\n",
                        "3631.75439453125\n",
                        "3347.31298828125\n",
                        "3300.80078125\n",
                        "4510.26513671875\n",
                        "3350.327392578125\n",
                        "2613.02978515625\n",
                        "Average loss :  3458.9150390625\n",
                        "\n",
                        "\n",
                        "Epoch 81/5000\n",
                        "Learning rate :  0.001\n",
                        "3612.83251953125\n",
                        "3328.5810546875\n",
                        "3280.09130859375\n",
                        "4479.6259765625\n",
                        "3327.43505859375\n",
                        "2596.96337890625\n",
                        "Average loss :  3437.587890625\n",
                        "\n",
                        "\n",
                        "Epoch 82/5000\n",
                        "Learning rate :  0.001\n",
                        "3594.0390625\n",
                        "3309.97705078125\n",
                        "3259.541015625\n",
                        "4449.228515625\n",
                        "3304.7236328125\n",
                        "2581.013671875\n",
                        "Average loss :  3416.420654296875\n",
                        "\n",
                        "\n",
                        "Epoch 83/5000\n",
                        "Learning rate :  0.001\n",
                        "3575.37255859375\n",
                        "3291.500244140625\n",
                        "3239.148681640625\n",
                        "4419.07177734375\n",
                        "3282.193359375\n",
                        "2565.179931640625\n",
                        "Average loss :  3395.4111328125\n",
                        "\n",
                        "\n",
                        "Epoch 84/5000\n",
                        "Learning rate :  0.001\n",
                        "3556.83251953125\n",
                        "3273.14990234375\n",
                        "3218.9130859375\n",
                        "4389.1533203125\n",
                        "3259.841064453125\n",
                        "2549.46142578125\n",
                        "Average loss :  3374.55859375\n",
                        "\n",
                        "\n",
                        "Epoch 85/5000\n",
                        "Learning rate :  0.001\n",
                        "3538.417724609375\n",
                        "3254.92431640625\n",
                        "3198.8330078125\n",
                        "4359.4716796875\n",
                        "3237.66650390625\n",
                        "2533.857421875\n",
                        "Average loss :  3353.861572265625\n",
                        "\n",
                        "\n",
                        "Epoch 86/5000\n",
                        "Learning rate :  0.001\n",
                        "3520.127685546875\n",
                        "3236.823486328125\n",
                        "3178.90673828125\n",
                        "4330.0244140625\n",
                        "3215.667236328125\n",
                        "2518.366943359375\n",
                        "Average loss :  3333.319580078125\n",
                        "\n",
                        "\n",
                        "Epoch 87/5000\n",
                        "Learning rate :  0.001\n",
                        "3501.96142578125\n",
                        "3218.84619140625\n",
                        "3159.13330078125\n",
                        "4300.8095703125\n",
                        "3193.84228515625\n",
                        "2502.989013671875\n",
                        "Average loss :  3312.930419921875\n",
                        "\n",
                        "\n",
                        "Epoch 88/5000\n",
                        "Learning rate :  0.001\n",
                        "3483.91796875\n",
                        "3200.990966796875\n",
                        "3139.51171875\n",
                        "4271.8251953125\n",
                        "3172.19091796875\n",
                        "2487.72265625\n",
                        "Average loss :  3292.693359375\n",
                        "\n",
                        "\n",
                        "Epoch 89/5000\n",
                        "Learning rate :  0.001\n",
                        "3465.99609375\n",
                        "3183.2578125\n",
                        "3120.0400390625\n",
                        "4243.0703125\n",
                        "3150.710693359375\n",
                        "2472.567626953125\n",
                        "Average loss :  3272.607177734375\n",
                        "\n",
                        "\n",
                        "Epoch 90/5000\n",
                        "Learning rate :  0.001\n",
                        "3448.195556640625\n",
                        "3165.6455078125\n",
                        "3100.718017578125\n",
                        "4214.5419921875\n",
                        "3129.400390625\n",
                        "2457.522705078125\n",
                        "Average loss :  3252.670654296875\n",
                        "\n",
                        "\n",
                        "Epoch 91/5000\n",
                        "Learning rate :  0.001\n",
                        "3430.51513671875\n",
                        "3148.1533203125\n",
                        "3081.54345703125\n",
                        "4186.23779296875\n",
                        "3108.2587890625\n",
                        "2442.5869140625\n",
                        "Average loss :  3232.8828125\n",
                        "\n",
                        "\n",
                        "Epoch 92/5000\n",
                        "Learning rate :  0.001\n",
                        "3412.953857421875\n",
                        "3130.7802734375\n",
                        "3062.51611328125\n",
                        "4158.158203125\n",
                        "3087.2861328125\n",
                        "2427.761962890625\n",
                        "Average loss :  3213.242919921875\n",
                        "\n",
                        "\n",
                        "Epoch 93/5000\n",
                        "Learning rate :  0.001\n",
                        "3395.513671875\n",
                        "3113.531005859375\n",
                        "3043.63818359375\n",
                        "4130.31298828125\n",
                        "3066.48486328125\n",
                        "2413.048828125\n",
                        "Average loss :  3193.7548828125\n",
                        "\n",
                        "\n",
                        "Epoch 94/5000\n",
                        "Learning rate :  0.001\n",
                        "3378.193359375\n",
                        "3096.40234375\n",
                        "3024.905029296875\n",
                        "4102.68798828125\n",
                        "3045.848388671875\n",
                        "2398.442138671875\n",
                        "Average loss :  3174.413330078125\n",
                        "\n",
                        "\n",
                        "Epoch 95/5000\n",
                        "Learning rate :  0.001\n",
                        "3360.98974609375\n",
                        "3079.39013671875\n",
                        "3006.3154296875\n",
                        "4075.280517578125\n",
                        "3025.37451171875\n",
                        "2383.94140625\n",
                        "Average loss :  3155.215087890625\n",
                        "\n",
                        "\n",
                        "Epoch 96/5000\n",
                        "Learning rate :  0.001\n",
                        "3343.90185546875\n",
                        "3062.494140625\n",
                        "2987.86767578125\n",
                        "4048.088623046875\n",
                        "3005.063232421875\n",
                        "2369.5458984375\n",
                        "Average loss :  3136.16015625\n",
                        "\n",
                        "\n",
                        "Epoch 97/5000\n",
                        "Learning rate :  0.001\n",
                        "3326.929443359375\n",
                        "3045.712646484375\n",
                        "2969.56103515625\n",
                        "4021.11083984375\n",
                        "2984.91162109375\n",
                        "2355.2548828125\n",
                        "Average loss :  3117.246826171875\n",
                        "\n",
                        "\n",
                        "Epoch 98/5000\n",
                        "Learning rate :  0.001\n",
                        "3310.07080078125\n",
                        "3029.04541015625\n",
                        "2951.393310546875\n",
                        "3994.3447265625\n",
                        "2964.91943359375\n",
                        "2341.067138671875\n",
                        "Average loss :  3098.4736328125\n",
                        "\n",
                        "\n",
                        "Epoch 99/5000\n",
                        "Learning rate :  0.001\n",
                        "3293.325439453125\n",
                        "3012.4912109375\n",
                        "2933.3642578125\n",
                        "3967.7890625\n",
                        "2945.0849609375\n",
                        "2326.982421875\n",
                        "Average loss :  3079.839599609375\n",
                        "\n",
                        "\n",
                        "Epoch 100/5000\n",
                        "Learning rate :  0.001\n",
                        "3276.692626953125\n",
                        "2996.04931640625\n",
                        "2915.472900390625\n",
                        "3941.4423828125\n",
                        "2925.406982421875\n",
                        "2312.999755859375\n",
                        "Average loss :  3061.34375\n",
                        "\n",
                        "\n",
                        "Epoch 101/5000\n",
                        "Learning rate :  0.001\n",
                        "3260.171875\n",
                        "2979.719482421875\n",
                        "2897.71728515625\n",
                        "3915.30224609375\n",
                        "2905.8837890625\n",
                        "2299.1181640625\n",
                        "Average loss :  3042.985595703125\n",
                        "\n",
                        "\n",
                        "Epoch 102/5000\n",
                        "Learning rate :  0.001\n",
                        "3243.76123046875\n",
                        "2963.5\n",
                        "2880.09716796875\n",
                        "3889.367431640625\n",
                        "2886.51513671875\n",
                        "2285.3369140625\n",
                        "Average loss :  3024.762939453125\n",
                        "\n",
                        "\n",
                        "Epoch 103/5000\n",
                        "Learning rate :  0.001\n",
                        "3227.4609375\n",
                        "2947.39111328125\n",
                        "2862.61083984375\n",
                        "3863.635986328125\n",
                        "2867.298828125\n",
                        "2271.65576171875\n",
                        "Average loss :  3006.67578125\n",
                        "\n",
                        "\n",
                        "Epoch 104/5000\n",
                        "Learning rate :  0.001\n",
                        "3211.270263671875\n",
                        "2931.39111328125\n",
                        "2845.25732421875\n",
                        "3838.10693359375\n",
                        "2848.23388671875\n",
                        "2258.0732421875\n",
                        "Average loss :  2988.722412109375\n",
                        "\n",
                        "\n",
                        "Epoch 105/5000\n",
                        "Learning rate :  0.001\n",
                        "3195.18798828125\n",
                        "2915.5\n",
                        "2828.0361328125\n",
                        "3812.777587890625\n",
                        "2829.31884765625\n",
                        "2244.5888671875\n",
                        "Average loss :  2970.901611328125\n",
                        "\n",
                        "\n",
                        "Epoch 106/5000\n",
                        "Learning rate :  0.001\n",
                        "3179.213134765625\n",
                        "2899.71630859375\n",
                        "2810.9453125\n",
                        "3787.646484375\n",
                        "2810.552734375\n",
                        "2231.2021484375\n",
                        "Average loss :  2953.212646484375\n",
                        "\n",
                        "\n",
                        "Epoch 107/5000\n",
                        "Learning rate :  0.001\n",
                        "3163.34521484375\n",
                        "2884.039306640625\n",
                        "2793.984130859375\n",
                        "3762.71240234375\n",
                        "2791.9345703125\n",
                        "2217.912109375\n",
                        "Average loss :  2935.654541015625\n",
                        "\n",
                        "\n",
                        "Epoch 108/5000\n",
                        "Learning rate :  0.001\n",
                        "3147.583740234375\n",
                        "2868.468994140625\n",
                        "2777.15185546875\n",
                        "3737.97412109375\n",
                        "2773.462890625\n",
                        "2204.71826171875\n",
                        "Average loss :  2918.226806640625\n",
                        "\n",
                        "\n",
                        "Epoch 109/5000\n",
                        "Learning rate :  0.001\n",
                        "3131.927978515625\n",
                        "2853.004150390625\n",
                        "2760.44677734375\n",
                        "3713.4287109375\n",
                        "2755.13623046875\n",
                        "2191.61962890625\n",
                        "Average loss :  2900.927001953125\n",
                        "\n",
                        "\n",
                        "Epoch 110/5000\n",
                        "Learning rate :  0.001\n",
                        "3116.37646484375\n",
                        "2837.643798828125\n",
                        "2743.86865234375\n",
                        "3689.07568359375\n",
                        "2736.95361328125\n",
                        "2178.615478515625\n",
                        "Average loss :  2883.755615234375\n",
                        "\n",
                        "\n",
                        "Epoch 111/5000\n",
                        "Learning rate :  0.001\n",
                        "3100.9287109375\n",
                        "2822.387451171875\n",
                        "2727.416015625\n",
                        "3664.91357421875\n",
                        "2718.9140625\n",
                        "2165.705078125\n",
                        "Average loss :  2866.7109375\n",
                        "\n",
                        "\n",
                        "Epoch 112/5000\n",
                        "Learning rate :  0.001\n",
                        "3085.58447265625\n",
                        "2807.234375\n",
                        "2711.087646484375\n",
                        "3640.939697265625\n",
                        "2701.016357421875\n",
                        "2152.88818359375\n",
                        "Average loss :  2849.791748046875\n",
                        "\n",
                        "\n",
                        "Epoch 113/5000\n",
                        "Learning rate :  0.001\n",
                        "3070.34228515625\n",
                        "2792.18408203125\n",
                        "2694.88330078125\n",
                        "3617.1533203125\n",
                        "2683.259033203125\n",
                        "2140.16357421875\n",
                        "Average loss :  2832.997314453125\n",
                        "\n",
                        "\n",
                        "Epoch 114/5000\n",
                        "Learning rate :  0.001\n",
                        "3055.202392578125\n",
                        "2777.23486328125\n",
                        "2678.80126953125\n",
                        "3593.55322265625\n",
                        "2665.640869140625\n",
                        "2127.5302734375\n",
                        "Average loss :  2816.3271484375\n",
                        "\n",
                        "\n",
                        "Epoch 115/5000\n",
                        "Learning rate :  0.001\n",
                        "3040.16259765625\n",
                        "2762.38671875\n",
                        "2662.84033203125\n",
                        "3570.13720703125\n",
                        "2648.1611328125\n",
                        "2114.988525390625\n",
                        "Average loss :  2799.779296875\n",
                        "\n",
                        "\n",
                        "Epoch 116/5000\n",
                        "Learning rate :  0.001\n",
                        "3025.2236328125\n",
                        "2747.639404296875\n",
                        "2647.000244140625\n",
                        "3546.9033203125\n",
                        "2630.818359375\n",
                        "2102.537109375\n",
                        "Average loss :  2783.353515625\n",
                        "\n",
                        "\n",
                        "Epoch 117/5000\n",
                        "Learning rate :  0.001\n",
                        "3010.3837890625\n",
                        "2732.991455078125\n",
                        "2631.27978515625\n",
                        "3523.8515625\n",
                        "2613.61181640625\n",
                        "2090.17529296875\n",
                        "Average loss :  2767.048828125\n",
                        "\n",
                        "\n",
                        "Epoch 118/5000\n",
                        "Learning rate :  0.001\n",
                        "2995.642578125\n",
                        "2718.4423828125\n",
                        "2615.677734375\n",
                        "3500.97900390625\n",
                        "2596.540283203125\n",
                        "2077.90234375\n",
                        "Average loss :  2750.864013671875\n",
                        "\n",
                        "\n",
                        "Epoch 119/5000\n",
                        "Learning rate :  0.001\n",
                        "2981.0\n",
                        "2703.9912109375\n",
                        "2600.193359375\n",
                        "3478.28515625\n",
                        "2579.60205078125\n",
                        "2065.718017578125\n",
                        "Average loss :  2734.798095703125\n",
                        "\n",
                        "\n",
                        "Epoch 120/5000\n",
                        "Learning rate :  0.001\n",
                        "2966.454345703125\n",
                        "2689.63818359375\n",
                        "2584.826171875\n",
                        "3455.77197265625\n",
                        "2562.7998046875\n",
                        "2053.6259765625\n",
                        "Average loss :  2718.8525390625\n",
                        "\n",
                        "\n",
                        "Epoch 121/5000\n",
                        "Learning rate :  0.001\n",
                        "2952.00927734375\n",
                        "2675.3876953125\n",
                        "2569.57861328125\n",
                        "3433.4443359375\n",
                        "2546.1318359375\n",
                        "2041.6219482421875\n",
                        "Average loss :  2703.02880859375\n",
                        "\n",
                        "\n",
                        "Epoch 122/5000\n",
                        "Learning rate :  0.001\n",
                        "2937.66064453125\n",
                        "2661.23388671875\n",
                        "2554.445556640625\n",
                        "3411.2900390625\n",
                        "2529.59423828125\n",
                        "2029.70458984375\n",
                        "Average loss :  2687.321533203125\n",
                        "\n",
                        "\n",
                        "Epoch 123/5000\n",
                        "Learning rate :  0.001\n",
                        "2923.406982421875\n",
                        "2647.175048828125\n",
                        "2539.4267578125\n",
                        "3389.30810546875\n",
                        "2513.18603515625\n",
                        "2017.8726806640625\n",
                        "Average loss :  2671.729248046875\n",
                        "\n",
                        "\n",
                        "Epoch 124/5000\n",
                        "Learning rate :  0.001\n",
                        "2909.248291015625\n",
                        "2633.211181640625\n",
                        "2524.5205078125\n",
                        "3367.49755859375\n",
                        "2496.90625\n",
                        "2006.1258544921875\n",
                        "Average loss :  2656.251708984375\n",
                        "\n",
                        "\n",
                        "Epoch 125/5000\n",
                        "Learning rate :  0.001\n",
                        "2895.18310546875\n",
                        "2619.34130859375\n",
                        "2509.72607421875\n",
                        "3345.856201171875\n",
                        "2480.75341796875\n",
                        "1994.4637451171875\n",
                        "Average loss :  2640.887451171875\n",
                        "\n",
                        "\n",
                        "Epoch 126/5000\n",
                        "Learning rate :  0.001\n",
                        "2881.21142578125\n",
                        "2605.564697265625\n",
                        "2495.04345703125\n",
                        "3324.38330078125\n",
                        "2464.727294921875\n",
                        "1982.8851318359375\n",
                        "Average loss :  2625.6357421875\n",
                        "\n",
                        "\n",
                        "Epoch 127/5000\n",
                        "Learning rate :  0.001\n",
                        "2867.33251953125\n",
                        "2591.88134765625\n",
                        "2480.470458984375\n",
                        "3303.0771484375\n",
                        "2448.826171875\n",
                        "1971.3896484375\n",
                        "Average loss :  2610.496337890625\n",
                        "\n",
                        "\n",
                        "Epoch 128/5000\n",
                        "Learning rate :  0.001\n",
                        "2853.54541015625\n",
                        "2578.289306640625\n",
                        "2466.006591796875\n",
                        "3281.936279296875\n",
                        "2433.04931640625\n",
                        "1959.976806640625\n",
                        "Average loss :  2595.46728515625\n",
                        "\n",
                        "\n",
                        "Epoch 129/5000\n",
                        "Learning rate :  0.001\n",
                        "2839.84912109375\n",
                        "2564.7890625\n",
                        "2451.651611328125\n",
                        "3260.95947265625\n",
                        "2417.39501953125\n",
                        "1948.645751953125\n",
                        "Average loss :  2580.548095703125\n",
                        "\n",
                        "\n",
                        "Epoch 130/5000\n",
                        "Learning rate :  0.001\n",
                        "2826.24365234375\n",
                        "2551.379150390625\n",
                        "2437.40380859375\n",
                        "3240.1455078125\n",
                        "2401.86328125\n",
                        "1937.39599609375\n",
                        "Average loss :  2565.738525390625\n",
                        "\n",
                        "\n",
                        "Epoch 131/5000\n",
                        "Learning rate :  0.001\n",
                        "2812.72802734375\n",
                        "2538.0595703125\n",
                        "2423.2626953125\n",
                        "3219.49267578125\n",
                        "2386.45263671875\n",
                        "1926.2269287109375\n",
                        "Average loss :  2551.037109375\n",
                        "\n",
                        "\n",
                        "Epoch 132/5000\n",
                        "Learning rate :  0.001\n",
                        "2799.301513671875\n",
                        "2524.829345703125\n",
                        "2409.2275390625\n",
                        "3199.0\n",
                        "2371.162353515625\n",
                        "1915.1376953125\n",
                        "Average loss :  2536.443115234375\n",
                        "\n",
                        "\n",
                        "Epoch 133/5000\n",
                        "Learning rate :  0.001\n",
                        "2785.9638671875\n",
                        "2511.688232421875\n",
                        "2395.29736328125\n",
                        "3178.666259765625\n",
                        "2355.9912109375\n",
                        "1904.128173828125\n",
                        "Average loss :  2521.955810546875\n",
                        "\n",
                        "\n",
                        "Epoch 134/5000\n",
                        "Learning rate :  0.001\n",
                        "2772.714599609375\n",
                        "2498.63525390625\n",
                        "2381.47119140625\n",
                        "3158.490234375\n",
                        "2340.938232421875\n",
                        "1893.197509765625\n",
                        "Average loss :  2507.574462890625\n",
                        "\n",
                        "\n",
                        "Epoch 135/5000\n",
                        "Learning rate :  0.001\n",
                        "2759.552490234375\n",
                        "2485.669677734375\n",
                        "2367.74853515625\n",
                        "3138.47021484375\n",
                        "2326.002685546875\n",
                        "1882.3450927734375\n",
                        "Average loss :  2493.298095703125\n",
                        "\n",
                        "\n",
                        "Epoch 136/5000\n",
                        "Learning rate :  0.001\n",
                        "2746.47705078125\n",
                        "2472.791015625\n",
                        "2354.12841796875\n",
                        "3118.60498046875\n",
                        "2311.183349609375\n",
                        "1871.5703125\n",
                        "Average loss :  2479.1259765625\n",
                        "\n",
                        "\n",
                        "Epoch 137/5000\n",
                        "Learning rate :  0.001\n",
                        "2733.48779296875\n",
                        "2459.9990234375\n",
                        "2340.609619140625\n",
                        "3098.8935546875\n",
                        "2296.4794921875\n",
                        "1860.872802734375\n",
                        "Average loss :  2465.056884765625\n",
                        "\n",
                        "\n",
                        "Epoch 138/5000\n",
                        "Learning rate :  0.001\n",
                        "2720.58447265625\n",
                        "2447.292724609375\n",
                        "2327.19189453125\n",
                        "3079.334716796875\n",
                        "2281.8896484375\n",
                        "1850.251708984375\n",
                        "Average loss :  2451.091064453125\n",
                        "\n",
                        "\n",
                        "Epoch 139/5000\n",
                        "Learning rate :  0.001\n",
                        "2707.765380859375\n",
                        "2434.67138671875\n",
                        "2313.8740234375\n",
                        "3059.9267578125\n",
                        "2267.41357421875\n",
                        "1839.7069091796875\n",
                        "Average loss :  2437.226318359375\n",
                        "\n",
                        "\n",
                        "Epoch 140/5000\n",
                        "Learning rate :  0.001\n",
                        "2695.031005859375\n",
                        "2422.134033203125\n",
                        "2300.654052734375\n",
                        "3040.667724609375\n",
                        "2253.05224609375\n",
                        "1829.23779296875\n",
                        "Average loss :  2423.462890625\n",
                        "\n",
                        "\n",
                        "Epoch 141/5000\n",
                        "Learning rate :  0.001\n",
                        "2682.3818359375\n",
                        "2409.6806640625\n",
                        "2287.532958984375\n",
                        "3021.55810546875\n",
                        "2238.802001953125\n",
                        "1818.8436279296875\n",
                        "Average loss :  2409.7998046875\n",
                        "\n",
                        "\n",
                        "Epoch 142/5000\n",
                        "Learning rate :  0.001\n",
                        "2669.8154296875\n",
                        "2397.310302734375\n",
                        "2274.509033203125\n",
                        "3002.595458984375\n",
                        "2224.66259765625\n",
                        "1808.52392578125\n",
                        "Average loss :  2396.236083984375\n",
                        "\n",
                        "\n",
                        "Epoch 143/5000\n",
                        "Learning rate :  0.001\n",
                        "2657.331787109375\n",
                        "2385.02294921875\n",
                        "2261.582275390625\n",
                        "2983.779052734375\n",
                        "2210.6328125\n",
                        "1798.27783203125\n",
                        "Average loss :  2382.771240234375\n",
                        "\n",
                        "\n",
                        "Epoch 144/5000\n",
                        "Learning rate :  0.001\n",
                        "2644.93017578125\n",
                        "2372.818115234375\n",
                        "2248.75\n",
                        "2965.106689453125\n",
                        "2196.71484375\n",
                        "1788.105712890625\n",
                        "Average loss :  2369.404296875\n",
                        "\n",
                        "\n",
                        "Epoch 145/5000\n",
                        "Learning rate :  0.001\n",
                        "2632.611328125\n",
                        "2360.693603515625\n",
                        "2236.012939453125\n",
                        "2946.57861328125\n",
                        "2182.90478515625\n",
                        "1778.00634765625\n",
                        "Average loss :  2356.134521484375\n",
                        "\n",
                        "\n",
                        "Epoch 146/5000\n",
                        "Learning rate :  0.001\n",
                        "2620.373779296875\n",
                        "2348.64990234375\n",
                        "2223.370361328125\n",
                        "2928.19287109375\n",
                        "2169.20166015625\n",
                        "1767.9788818359375\n",
                        "Average loss :  2342.961181640625\n",
                        "\n",
                        "\n",
                        "Epoch 147/5000\n",
                        "Learning rate :  0.001\n",
                        "2608.216064453125\n",
                        "2336.6865234375\n",
                        "2210.821533203125\n",
                        "2909.94873046875\n",
                        "2155.60498046875\n",
                        "1758.02294921875\n",
                        "Average loss :  2329.883544921875\n",
                        "\n",
                        "\n",
                        "Epoch 148/5000\n",
                        "Learning rate :  0.001\n",
                        "2596.137939453125\n",
                        "2324.803466796875\n",
                        "2198.36572265625\n",
                        "2891.84521484375\n",
                        "2142.11376953125\n",
                        "1748.1383056640625\n",
                        "Average loss :  2316.900634765625\n",
                        "\n",
                        "\n",
                        "Epoch 149/5000\n",
                        "Learning rate :  0.001\n",
                        "2584.140380859375\n",
                        "2312.998779296875\n",
                        "2186.001220703125\n",
                        "2873.880126953125\n",
                        "2128.728759765625\n",
                        "1738.32470703125\n",
                        "Average loss :  2304.01220703125\n",
                        "\n",
                        "\n",
                        "Epoch 150/5000\n",
                        "Learning rate :  0.001\n",
                        "2572.22119140625\n",
                        "2301.2734375\n",
                        "2173.728271484375\n",
                        "2856.05322265625\n",
                        "2115.447509765625\n",
                        "1728.5809326171875\n",
                        "Average loss :  2291.217529296875\n",
                        "\n",
                        "\n",
                        "Epoch 151/5000\n",
                        "Learning rate :  0.001\n",
                        "2560.38037109375\n",
                        "2289.625732421875\n",
                        "2161.5458984375\n",
                        "2838.363525390625\n",
                        "2102.26904296875\n",
                        "1718.906494140625\n",
                        "Average loss :  2278.51513671875\n",
                        "\n",
                        "\n",
                        "Epoch 152/5000\n",
                        "Learning rate :  0.001\n",
                        "2548.6162109375\n",
                        "2278.0556640625\n",
                        "2149.45361328125\n",
                        "2820.809326171875\n",
                        "2089.1923828125\n",
                        "1709.301025390625\n",
                        "Average loss :  2265.90478515625\n",
                        "\n",
                        "\n",
                        "Epoch 153/5000\n",
                        "Learning rate :  0.001\n",
                        "2536.92919921875\n",
                        "2266.5625\n",
                        "2137.450927734375\n",
                        "2803.39013671875\n",
                        "2076.217041015625\n",
                        "1699.763671875\n",
                        "Average loss :  2253.3857421875\n",
                        "\n",
                        "\n",
                        "Epoch 154/5000\n",
                        "Learning rate :  0.001\n",
                        "2525.318359375\n",
                        "2255.146484375\n",
                        "2125.536865234375\n",
                        "2786.104736328125\n",
                        "2063.342041015625\n",
                        "1690.2947998046875\n",
                        "Average loss :  2240.957275390625\n",
                        "\n",
                        "\n",
                        "Epoch 155/5000\n",
                        "Learning rate :  0.001\n",
                        "2513.78369140625\n",
                        "2243.806640625\n",
                        "2113.711181640625\n",
                        "2768.952392578125\n",
                        "2050.56689453125\n",
                        "1680.89306640625\n",
                        "Average loss :  2228.618896484375\n",
                        "\n",
                        "\n",
                        "Epoch 156/5000\n",
                        "Learning rate :  0.001\n",
                        "2502.32421875\n",
                        "2232.5419921875\n",
                        "2101.972412109375\n",
                        "2751.931396484375\n",
                        "2037.890625\n",
                        "1671.5582275390625\n",
                        "Average loss :  2216.369873046875\n",
                        "\n",
                        "\n",
                        "Epoch 157/5000\n",
                        "Learning rate :  0.001\n",
                        "2490.93896484375\n",
                        "2221.352294921875\n",
                        "2090.320556640625\n",
                        "2735.041015625\n",
                        "2025.31201171875\n",
                        "1662.28955078125\n",
                        "Average loss :  2204.208984375\n",
                        "\n",
                        "\n",
                        "Epoch 158/5000\n",
                        "Learning rate :  0.001\n",
                        "2479.6279296875\n",
                        "2210.23681640625\n",
                        "2078.75439453125\n",
                        "2718.27978515625\n",
                        "2012.830322265625\n",
                        "1653.08642578125\n",
                        "Average loss :  2192.1357421875\n",
                        "\n",
                        "\n",
                        "Epoch 159/5000\n",
                        "Learning rate :  0.001\n",
                        "2468.390380859375\n",
                        "2199.19482421875\n",
                        "2067.273193359375\n",
                        "2701.646484375\n",
                        "2000.44482421875\n",
                        "1643.948974609375\n",
                        "Average loss :  2180.149658203125\n",
                        "\n",
                        "\n",
                        "Epoch 160/5000\n",
                        "Learning rate :  0.001\n",
                        "2457.22607421875\n",
                        "2188.226806640625\n",
                        "2055.876708984375\n",
                        "2685.141357421875\n",
                        "1988.1552734375\n",
                        "1634.8765869140625\n",
                        "Average loss :  2168.25048828125\n",
                        "\n",
                        "\n",
                        "Epoch 161/5000\n",
                        "Learning rate :  0.001\n",
                        "2446.13427734375\n",
                        "2177.331787109375\n",
                        "2044.564208984375\n",
                        "2668.762451171875\n",
                        "1975.9605712890625\n",
                        "1625.868408203125\n",
                        "Average loss :  2156.43701171875\n",
                        "\n",
                        "\n",
                        "Epoch 162/5000\n",
                        "Learning rate :  0.001\n",
                        "2435.115234375\n",
                        "2166.509033203125\n",
                        "2033.334716796875\n",
                        "2652.5078125\n",
                        "1963.862548828125\n",
                        "1616.92529296875\n",
                        "Average loss :  2144.709228515625\n",
                        "\n",
                        "\n",
                        "Epoch 163/5000\n",
                        "Learning rate :  0.001\n",
                        "2424.1689453125\n",
                        "2155.7568359375\n",
                        "2022.1861572265625\n",
                        "2636.376953125\n",
                        "1951.858154296875\n",
                        "1608.045654296875\n",
                        "Average loss :  2133.065673828125\n",
                        "\n",
                        "\n",
                        "Epoch 164/5000\n",
                        "Learning rate :  0.001\n",
                        "2413.29443359375\n",
                        "2145.076171875\n",
                        "2011.119140625\n",
                        "2620.36962890625\n",
                        "1939.945556640625\n",
                        "1599.2291259765625\n",
                        "Average loss :  2121.505615234375\n",
                        "\n",
                        "\n",
                        "Epoch 165/5000\n",
                        "Learning rate :  0.001\n",
                        "2402.48974609375\n",
                        "2134.466552734375\n",
                        "2000.134033203125\n",
                        "2604.48486328125\n",
                        "1928.125244140625\n",
                        "1590.47509765625\n",
                        "Average loss :  2110.029296875\n",
                        "\n",
                        "\n",
                        "Epoch 166/5000\n",
                        "Learning rate :  0.001\n",
                        "2391.75537109375\n",
                        "2123.92724609375\n",
                        "1989.229248046875\n",
                        "2588.721435546875\n",
                        "1916.395751953125\n",
                        "1581.7828369140625\n",
                        "Average loss :  2098.635498046875\n",
                        "\n",
                        "\n",
                        "Epoch 167/5000\n",
                        "Learning rate :  0.001\n",
                        "2381.0908203125\n",
                        "2113.457763671875\n",
                        "1978.404541015625\n",
                        "2573.078125\n",
                        "1904.75634765625\n",
                        "1573.152587890625\n",
                        "Average loss :  2087.323486328125\n",
                        "\n",
                        "\n",
                        "Epoch 168/5000\n",
                        "Learning rate :  0.001\n",
                        "2370.494873046875\n",
                        "2103.057861328125\n",
                        "1967.6591796875\n",
                        "2557.55419921875\n",
                        "1893.206787109375\n",
                        "1564.5830078125\n",
                        "Average loss :  2076.0927734375\n",
                        "\n",
                        "\n",
                        "Epoch 169/5000\n",
                        "Learning rate :  0.001\n",
                        "2359.9677734375\n",
                        "2092.726806640625\n",
                        "1956.99267578125\n",
                        "2542.149169921875\n",
                        "1881.7459716796875\n",
                        "1556.0743408203125\n",
                        "Average loss :  2064.94287109375\n",
                        "\n",
                        "\n",
                        "Epoch 170/5000\n",
                        "Learning rate :  0.001\n",
                        "2349.5087890625\n",
                        "2082.464111328125\n",
                        "1946.404052734375\n",
                        "2526.861083984375\n",
                        "1870.373046875\n",
                        "1547.625732421875\n",
                        "Average loss :  2053.872802734375\n",
                        "\n",
                        "\n",
                        "Epoch 171/5000\n",
                        "Learning rate :  0.001\n",
                        "2339.1171875\n",
                        "2072.26904296875\n",
                        "1935.8929443359375\n",
                        "2511.689453125\n",
                        "1859.08740234375\n",
                        "1539.23681640625\n",
                        "Average loss :  2042.8822021484375\n",
                        "\n",
                        "\n",
                        "Epoch 172/5000\n",
                        "Learning rate :  0.001\n",
                        "2328.79248046875\n",
                        "2062.1416015625\n",
                        "1925.45849609375\n",
                        "2496.63330078125\n",
                        "1847.888671875\n",
                        "1530.9072265625\n",
                        "Average loss :  2031.9703369140625\n",
                        "\n",
                        "\n",
                        "Epoch 173/5000\n",
                        "Learning rate :  0.001\n",
                        "2318.534912109375\n",
                        "2052.0810546875\n",
                        "1915.1004638671875\n",
                        "2481.692138671875\n",
                        "1836.77587890625\n",
                        "1522.63671875\n",
                        "Average loss :  2021.1368408203125\n",
                        "\n",
                        "\n",
                        "Epoch 174/5000\n",
                        "Learning rate :  0.001\n",
                        "2308.34326171875\n",
                        "2042.087158203125\n",
                        "1904.818115234375\n",
                        "2466.864501953125\n",
                        "1825.748291015625\n",
                        "1514.424560546875\n",
                        "Average loss :  2010.3809814453125\n",
                        "\n",
                        "\n",
                        "Epoch 175/5000\n",
                        "Learning rate :  0.001\n",
                        "2298.21728515625\n",
                        "2032.158935546875\n",
                        "1894.61083984375\n",
                        "2452.1494140625\n",
                        "1814.805419921875\n",
                        "1506.2701416015625\n",
                        "Average loss :  1999.7020263671875\n",
                        "\n",
                        "\n",
                        "Epoch 176/5000\n",
                        "Learning rate :  0.001\n",
                        "2288.156494140625\n",
                        "2022.29638671875\n",
                        "1884.477783203125\n",
                        "2437.54638671875\n",
                        "1803.946044921875\n",
                        "1498.17333984375\n",
                        "Average loss :  1989.0992431640625\n",
                        "\n",
                        "\n",
                        "Epoch 177/5000\n",
                        "Learning rate :  0.001\n",
                        "2278.16015625\n",
                        "2012.4989013671875\n",
                        "1874.418701171875\n",
                        "2423.05419921875\n",
                        "1793.17041015625\n",
                        "1490.1339111328125\n",
                        "Average loss :  1978.5726318359375\n",
                        "\n",
                        "\n",
                        "Epoch 178/5000\n",
                        "Learning rate :  0.001\n",
                        "2268.22900390625\n",
                        "2002.76611328125\n",
                        "1864.432861328125\n",
                        "2408.67236328125\n",
                        "1782.47705078125\n",
                        "1482.15087890625\n",
                        "Average loss :  1968.1214599609375\n",
                        "\n",
                        "\n",
                        "Epoch 179/5000\n",
                        "Learning rate :  0.001\n",
                        "2258.361083984375\n",
                        "1993.097412109375\n",
                        "1854.51953125\n",
                        "2394.3994140625\n",
                        "1771.8653564453125\n",
                        "1474.224365234375\n",
                        "Average loss :  1957.74462890625\n",
                        "\n",
                        "\n",
                        "Epoch 180/5000\n",
                        "Learning rate :  0.001\n",
                        "2248.556640625\n",
                        "1983.49267578125\n",
                        "1844.678466796875\n",
                        "2380.234619140625\n",
                        "1761.33544921875\n",
                        "1466.3538818359375\n",
                        "Average loss :  1947.44189453125\n",
                        "\n",
                        "\n",
                        "Epoch 181/5000\n",
                        "Learning rate :  0.001\n",
                        "2238.8154296875\n",
                        "1973.9510498046875\n",
                        "1834.9090576171875\n",
                        "2366.17724609375\n",
                        "1750.8857421875\n",
                        "1458.538818359375\n",
                        "Average loss :  1937.212890625\n",
                        "\n",
                        "\n",
                        "Epoch 182/5000\n",
                        "Learning rate :  0.001\n",
                        "2229.13671875\n",
                        "1964.472412109375\n",
                        "1825.210693359375\n",
                        "2352.2265625\n",
                        "1740.51611328125\n",
                        "1450.7786865234375\n",
                        "Average loss :  1927.0570068359375\n",
                        "\n",
                        "\n",
                        "Epoch 183/5000\n",
                        "Learning rate :  0.001\n",
                        "2219.52001953125\n",
                        "1955.0560302734375\n",
                        "1815.5828857421875\n",
                        "2338.382080078125\n",
                        "1730.2259521484375\n",
                        "1443.073486328125\n",
                        "Average loss :  1916.9732666015625\n",
                        "\n",
                        "\n",
                        "Epoch 184/5000\n",
                        "Learning rate :  0.001\n",
                        "2209.96484375\n",
                        "1945.701904296875\n",
                        "1806.0247802734375\n",
                        "2324.641845703125\n",
                        "1720.014404296875\n",
                        "1435.42236328125\n",
                        "Average loss :  1906.9615478515625\n",
                        "\n",
                        "\n",
                        "Epoch 185/5000\n",
                        "Learning rate :  0.001\n",
                        "2200.47119140625\n",
                        "1936.4091796875\n",
                        "1796.5360107421875\n",
                        "2311.005859375\n",
                        "1709.880615234375\n",
                        "1427.824951171875\n",
                        "Average loss :  1897.0213623046875\n",
                        "\n",
                        "\n",
                        "Epoch 186/5000\n",
                        "Learning rate :  0.001\n",
                        "2191.0380859375\n",
                        "1927.1771240234375\n",
                        "1787.115966796875\n",
                        "2297.47265625\n",
                        "1699.824462890625\n",
                        "1420.28125\n",
                        "Average loss :  1887.1514892578125\n",
                        "\n",
                        "\n",
                        "Epoch 187/5000\n",
                        "Learning rate :  0.001\n",
                        "2181.665771484375\n",
                        "1918.00634765625\n",
                        "1777.76416015625\n",
                        "2284.042236328125\n",
                        "1689.844970703125\n",
                        "1412.790283203125\n",
                        "Average loss :  1877.3521728515625\n",
                        "\n",
                        "\n",
                        "Epoch 188/5000\n",
                        "Learning rate :  0.001\n",
                        "2172.353271484375\n",
                        "1908.8955078125\n",
                        "1768.4803466796875\n",
                        "2270.713623046875\n",
                        "1679.94189453125\n",
                        "1405.3524169921875\n",
                        "Average loss :  1867.6229248046875\n",
                        "\n",
                        "\n",
                        "Epoch 189/5000\n",
                        "Learning rate :  0.001\n",
                        "2163.10009765625\n",
                        "1899.844482421875\n",
                        "1759.263427734375\n",
                        "2257.4853515625\n",
                        "1670.1142578125\n",
                        "1397.96630859375\n",
                        "Average loss :  1857.96240234375\n",
                        "\n",
                        "\n",
                        "Epoch 190/5000\n",
                        "Learning rate :  0.001\n",
                        "2153.90625\n",
                        "1890.852783203125\n",
                        "1750.11328125\n",
                        "2244.35693359375\n",
                        "1660.3614501953125\n",
                        "1390.632568359375\n",
                        "Average loss :  1848.3704833984375\n",
                        "\n",
                        "\n",
                        "Epoch 191/5000\n",
                        "Learning rate :  0.001\n",
                        "2144.77099609375\n",
                        "1881.920166015625\n",
                        "1741.0291748046875\n",
                        "2231.32763671875\n",
                        "1650.6829833984375\n",
                        "1383.35009765625\n",
                        "Average loss :  1838.8470458984375\n",
                        "\n",
                        "\n",
                        "Epoch 192/5000\n",
                        "Learning rate :  0.001\n",
                        "2135.69384765625\n",
                        "1873.0460205078125\n",
                        "1732.010498046875\n",
                        "2218.396728515625\n",
                        "1641.078369140625\n",
                        "1376.11865234375\n",
                        "Average loss :  1829.390625\n",
                        "\n",
                        "\n",
                        "Epoch 193/5000\n",
                        "Learning rate :  0.001\n",
                        "2126.6748046875\n",
                        "1864.23046875\n",
                        "1723.0582275390625\n",
                        "2205.564453125\n",
                        "1631.54931640625\n",
                        "1368.9378662109375\n",
                        "Average loss :  1820.0025634765625\n",
                        "\n",
                        "\n",
                        "Epoch 194/5000\n",
                        "Learning rate :  0.001\n",
                        "2117.71728515625\n",
                        "1855.4737548828125\n",
                        "1714.1737060546875\n",
                        "2192.830078125\n",
                        "1622.09423828125\n",
                        "1361.80712890625\n",
                        "Average loss :  1810.6826171875\n",
                        "\n",
                        "\n",
                        "Epoch 195/5000\n",
                        "Learning rate :  0.001\n",
                        "2108.81640625\n",
                        "1846.774169921875\n",
                        "1705.35302734375\n",
                        "2180.191650390625\n",
                        "1612.711181640625\n",
                        "1354.7265625\n",
                        "Average loss :  1801.4287109375\n",
                        "\n",
                        "\n",
                        "Epoch 196/5000\n",
                        "Learning rate :  0.001\n",
                        "2099.9716796875\n",
                        "1838.1317138671875\n",
                        "1696.595947265625\n",
                        "2167.6484375\n",
                        "1603.3992919921875\n",
                        "1347.6953125\n",
                        "Average loss :  1792.2403564453125\n",
                        "\n",
                        "\n",
                        "Epoch 197/5000\n",
                        "Learning rate :  0.001\n",
                        "2091.18359375\n",
                        "1829.54541015625\n",
                        "1687.901611328125\n",
                        "2155.19921875\n",
                        "1594.158203125\n",
                        "1340.7135009765625\n",
                        "Average loss :  1783.1168212890625\n",
                        "\n",
                        "\n",
                        "Epoch 198/5000\n",
                        "Learning rate :  0.001\n",
                        "2082.45166015625\n",
                        "1821.015625\n",
                        "1679.27001953125\n",
                        "2142.843994140625\n",
                        "1584.9874267578125\n",
                        "1333.780517578125\n",
                        "Average loss :  1774.0582275390625\n",
                        "\n",
                        "\n",
                        "Epoch 199/5000\n",
                        "Learning rate :  0.001\n",
                        "2073.77490234375\n",
                        "1812.541748046875\n",
                        "1670.7005615234375\n",
                        "2130.581787109375\n",
                        "1575.886474609375\n",
                        "1326.896240234375\n",
                        "Average loss :  1765.0635986328125\n",
                        "\n",
                        "\n",
                        "Epoch 200/5000\n",
                        "Learning rate :  0.001\n",
                        "2065.1533203125\n",
                        "1804.122802734375\n",
                        "1662.192626953125\n",
                        "2118.41162109375\n",
                        "1566.8544921875\n",
                        "1320.06005859375\n",
                        "Average loss :  1756.1324462890625\n",
                        "\n",
                        "\n",
                        "Epoch 201/5000\n",
                        "Learning rate :  0.001\n",
                        "2056.58642578125\n",
                        "1795.759033203125\n",
                        "1653.745849609375\n",
                        "2106.333251953125\n",
                        "1557.89111328125\n",
                        "1313.2718505859375\n",
                        "Average loss :  1747.2646484375\n",
                        "\n",
                        "\n",
                        "Epoch 202/5000\n",
                        "Learning rate :  0.001\n",
                        "2048.073974609375\n",
                        "1787.4498291015625\n",
                        "1645.3597412109375\n",
                        "2094.34521484375\n",
                        "1548.9959716796875\n",
                        "1306.53125\n",
                        "Average loss :  1738.4593505859375\n",
                        "\n",
                        "\n",
                        "Epoch 203/5000\n",
                        "Learning rate :  0.001\n",
                        "2039.6153564453125\n",
                        "1779.1949462890625\n",
                        "1637.03369140625\n",
                        "2082.447265625\n",
                        "1540.168212890625\n",
                        "1299.83740234375\n",
                        "Average loss :  1729.7161865234375\n",
                        "\n",
                        "\n",
                        "Epoch 204/5000\n",
                        "Learning rate :  0.001\n",
                        "2031.210205078125\n",
                        "1770.99365234375\n",
                        "1628.767333984375\n",
                        "2070.638671875\n",
                        "1531.4072265625\n",
                        "1293.190185546875\n",
                        "Average loss :  1721.0345458984375\n",
                        "\n",
                        "\n",
                        "Epoch 205/5000\n",
                        "Learning rate :  0.001\n",
                        "2022.8583984375\n",
                        "1762.8460693359375\n",
                        "1620.56005859375\n",
                        "2058.918212890625\n",
                        "1522.712646484375\n",
                        "1286.589599609375\n",
                        "Average loss :  1712.4140625\n",
                        "\n",
                        "\n",
                        "Epoch 206/5000\n",
                        "Learning rate :  0.001\n",
                        "2014.5592041015625\n",
                        "1754.75146484375\n",
                        "1612.41162109375\n",
                        "2047.2857666015625\n",
                        "1514.083984375\n",
                        "1280.0350341796875\n",
                        "Average loss :  1703.8544921875\n",
                        "\n",
                        "\n",
                        "Epoch 207/5000\n",
                        "Learning rate :  0.001\n",
                        "2006.312744140625\n",
                        "1746.70947265625\n",
                        "1604.321533203125\n",
                        "2035.740478515625\n",
                        "1505.5206298828125\n",
                        "1273.5262451171875\n",
                        "Average loss :  1695.3551025390625\n",
                        "\n",
                        "\n",
                        "Epoch 208/5000\n",
                        "Learning rate :  0.001\n",
                        "1998.1181640625\n",
                        "1738.7197265625\n",
                        "1596.2890625\n",
                        "2024.281494140625\n",
                        "1497.0218505859375\n",
                        "1267.0626220703125\n",
                        "Average loss :  1686.91552734375\n",
                        "\n",
                        "\n",
                        "Epoch 209/5000\n",
                        "Learning rate :  0.001\n",
                        "1989.9752197265625\n",
                        "1730.78173828125\n",
                        "1588.3138427734375\n",
                        "2012.908203125\n",
                        "1488.587646484375\n",
                        "1260.6441650390625\n",
                        "Average loss :  1678.53515625\n",
                        "\n",
                        "\n",
                        "Epoch 210/5000\n",
                        "Learning rate :  0.001\n",
                        "1981.8836669921875\n",
                        "1722.895751953125\n",
                        "1580.3956298828125\n",
                        "2001.6201171875\n",
                        "1480.217041015625\n",
                        "1254.2706298828125\n",
                        "Average loss :  1670.2137451171875\n",
                        "\n",
                        "\n",
                        "Epoch 211/5000\n",
                        "Learning rate :  0.001\n",
                        "1973.84326171875\n",
                        "1715.06103515625\n",
                        "1572.533935546875\n",
                        "1990.416259765625\n",
                        "1471.9097900390625\n",
                        "1247.941162109375\n",
                        "Average loss :  1661.9508056640625\n",
                        "\n",
                        "\n",
                        "Epoch 212/5000\n",
                        "Learning rate :  0.001\n",
                        "1965.8533935546875\n",
                        "1707.27685546875\n",
                        "1564.728515625\n",
                        "1979.29638671875\n",
                        "1463.665283203125\n",
                        "1241.65625\n",
                        "Average loss :  1653.74609375\n",
                        "\n",
                        "\n",
                        "Epoch 213/5000\n",
                        "Learning rate :  0.001\n",
                        "1957.913818359375\n",
                        "1699.54345703125\n",
                        "1556.978271484375\n",
                        "1968.25927734375\n",
                        "1455.483154296875\n",
                        "1235.414794921875\n",
                        "Average loss :  1645.5986328125\n",
                        "\n",
                        "\n",
                        "Epoch 214/5000\n",
                        "Learning rate :  0.001\n",
                        "1950.024169921875\n",
                        "1691.860107421875\n",
                        "1549.283447265625\n",
                        "1957.3043212890625\n",
                        "1447.362548828125\n",
                        "1229.2166748046875\n",
                        "Average loss :  1637.5086669921875\n",
                        "\n",
                        "\n",
                        "Epoch 215/5000\n",
                        "Learning rate :  0.001\n",
                        "1942.18408203125\n",
                        "1684.2266845703125\n",
                        "1541.643310546875\n",
                        "1946.431396484375\n",
                        "1439.303466796875\n",
                        "1223.06201171875\n",
                        "Average loss :  1629.4752197265625\n",
                        "\n",
                        "\n",
                        "Epoch 216/5000\n",
                        "Learning rate :  0.001\n",
                        "1934.393310546875\n",
                        "1676.6429443359375\n",
                        "1534.0576171875\n",
                        "1935.639404296875\n",
                        "1431.3050537109375\n",
                        "1216.9498291015625\n",
                        "Average loss :  1621.498046875\n",
                        "\n",
                        "\n",
                        "Epoch 217/5000\n",
                        "Learning rate :  0.001\n",
                        "1926.6513671875\n",
                        "1669.10791015625\n",
                        "1526.525634765625\n",
                        "1924.927978515625\n",
                        "1423.3668212890625\n",
                        "1210.8802490234375\n",
                        "Average loss :  1613.57666015625\n",
                        "\n",
                        "\n",
                        "Epoch 218/5000\n",
                        "Learning rate :  0.001\n",
                        "1918.958251953125\n",
                        "1661.6219482421875\n",
                        "1519.0472412109375\n",
                        "1914.2962646484375\n",
                        "1415.48876953125\n",
                        "1204.8529052734375\n",
                        "Average loss :  1605.7109375\n",
                        "\n",
                        "\n",
                        "Epoch 219/5000\n",
                        "Learning rate :  0.001\n",
                        "1911.3131103515625\n",
                        "1654.184326171875\n",
                        "1511.621826171875\n",
                        "1903.74365234375\n",
                        "1407.6697998046875\n",
                        "1198.8671875\n",
                        "Average loss :  1597.9000244140625\n",
                        "\n",
                        "\n",
                        "Epoch 220/5000\n",
                        "Learning rate :  0.001\n",
                        "1903.716064453125\n",
                        "1646.794921875\n",
                        "1504.2490234375\n",
                        "1893.2694091796875\n",
                        "1399.90966796875\n",
                        "1192.923095703125\n",
                        "Average loss :  1590.1436767578125\n",
                        "\n",
                        "\n",
                        "Epoch 221/5000\n",
                        "Learning rate :  0.001\n",
                        "1896.166259765625\n",
                        "1639.4527587890625\n",
                        "1496.9283447265625\n",
                        "1882.873046875\n",
                        "1392.208740234375\n",
                        "1187.021484375\n",
                        "Average loss :  1582.4417724609375\n",
                        "\n",
                        "\n",
                        "Epoch 222/5000\n",
                        "Learning rate :  0.001\n",
                        "1888.6656494140625\n",
                        "1632.161376953125\n",
                        "1489.6629638671875\n",
                        "1872.5595703125\n",
                        "1384.570068359375\n",
                        "1181.162841796875\n",
                        "Average loss :  1574.7969970703125\n",
                        "\n",
                        "\n",
                        "Epoch 223/5000\n",
                        "Learning rate :  0.001\n",
                        "1881.2138671875\n",
                        "1624.91845703125\n",
                        "1482.4500732421875\n",
                        "1862.3232421875\n",
                        "1376.989013671875\n",
                        "1175.3447265625\n",
                        "Average loss :  1567.2066650390625\n",
                        "\n",
                        "\n",
                        "Epoch 224/5000\n",
                        "Learning rate :  0.001\n",
                        "1873.80859375\n",
                        "1617.72265625\n",
                        "1475.2882080078125\n",
                        "1852.1627197265625\n",
                        "1369.46484375\n",
                        "1169.56689453125\n",
                        "Average loss :  1559.6689453125\n",
                        "\n",
                        "\n",
                        "Epoch 225/5000\n",
                        "Learning rate :  0.001\n",
                        "1866.44970703125\n",
                        "1610.572998046875\n",
                        "1468.1767578125\n",
                        "1842.07763671875\n",
                        "1361.997314453125\n",
                        "1163.829345703125\n",
                        "Average loss :  1552.1839599609375\n",
                        "\n",
                        "\n",
                        "Epoch 226/5000\n",
                        "Learning rate :  0.001\n",
                        "1859.136962890625\n",
                        "1603.4697265625\n",
                        "1461.115966796875\n",
                        "1832.067626953125\n",
                        "1354.5858154296875\n",
                        "1158.13134765625\n",
                        "Average loss :  1544.7510986328125\n",
                        "\n",
                        "\n",
                        "Epoch 227/5000\n",
                        "Learning rate :  0.001\n",
                        "1851.869384765625\n",
                        "1596.411865234375\n",
                        "1454.1044921875\n",
                        "1822.1317138671875\n",
                        "1347.22998046875\n",
                        "1152.472900390625\n",
                        "Average loss :  1537.3701171875\n",
                        "\n",
                        "\n",
                        "Epoch 228/5000\n",
                        "Learning rate :  0.001\n",
                        "1844.6475830078125\n",
                        "1589.39990234375\n",
                        "1447.142822265625\n",
                        "1812.269287109375\n",
                        "1339.929443359375\n",
                        "1146.8536376953125\n",
                        "Average loss :  1530.04052734375\n",
                        "\n",
                        "\n",
                        "Epoch 229/5000\n",
                        "Learning rate :  0.001\n",
                        "1837.470458984375\n",
                        "1582.43310546875\n",
                        "1440.230224609375\n",
                        "1802.48046875\n",
                        "1332.68359375\n",
                        "1141.273193359375\n",
                        "Average loss :  1522.7618408203125\n",
                        "\n",
                        "\n",
                        "Epoch 230/5000\n",
                        "Learning rate :  0.001\n",
                        "1830.33837890625\n",
                        "1575.51123046875\n",
                        "1433.366455078125\n",
                        "1792.763671875\n",
                        "1325.4921875\n",
                        "1135.7314453125\n",
                        "Average loss :  1515.5338134765625\n",
                        "\n",
                        "\n",
                        "Epoch 231/5000\n",
                        "Learning rate :  0.001\n",
                        "1823.2503662109375\n",
                        "1568.6334228515625\n",
                        "1426.5506591796875\n",
                        "1783.11865234375\n",
                        "1318.354736328125\n",
                        "1130.227783203125\n",
                        "Average loss :  1508.35595703125\n",
                        "\n",
                        "\n",
                        "Epoch 232/5000\n",
                        "Learning rate :  0.001\n",
                        "1816.20654296875\n",
                        "1561.8004150390625\n",
                        "1419.782958984375\n",
                        "1773.545166015625\n",
                        "1311.2705078125\n",
                        "1124.76220703125\n",
                        "Average loss :  1501.2279052734375\n",
                        "\n",
                        "\n",
                        "Epoch 233/5000\n",
                        "Learning rate :  0.001\n",
                        "1809.2064208984375\n",
                        "1555.0108642578125\n",
                        "1413.0628662109375\n",
                        "1764.0423583984375\n",
                        "1304.2393798828125\n",
                        "1119.33447265625\n",
                        "Average loss :  1494.1494140625\n",
                        "\n",
                        "\n",
                        "Epoch 234/5000\n",
                        "Learning rate :  0.001\n",
                        "1802.249755859375\n",
                        "1548.26513671875\n",
                        "1406.389892578125\n",
                        "1754.6097412109375\n",
                        "1297.260986328125\n",
                        "1113.944091796875\n",
                        "Average loss :  1487.1199951171875\n",
                        "\n",
                        "\n",
                        "Epoch 235/5000\n",
                        "Learning rate :  0.001\n",
                        "1795.336181640625\n",
                        "1541.5626220703125\n",
                        "1399.763671875\n",
                        "1745.246826171875\n",
                        "1290.334716796875\n",
                        "1108.5908203125\n",
                        "Average loss :  1480.13916015625\n",
                        "\n",
                        "\n",
                        "Epoch 236/5000\n",
                        "Learning rate :  0.001\n",
                        "1788.465576171875\n",
                        "1534.9031982421875\n",
                        "1393.18408203125\n",
                        "1735.952880859375\n",
                        "1283.460205078125\n",
                        "1103.274658203125\n",
                        "Average loss :  1473.2066650390625\n",
                        "\n",
                        "\n",
                        "Epoch 237/5000\n",
                        "Learning rate :  0.001\n",
                        "1781.637451171875\n",
                        "1528.286376953125\n",
                        "1386.650390625\n",
                        "1726.7274169921875\n",
                        "1276.6368408203125\n",
                        "1097.9947509765625\n",
                        "Average loss :  1466.322265625\n",
                        "\n",
                        "\n",
                        "Epoch 238/5000\n",
                        "Learning rate :  0.001\n",
                        "1774.8514404296875\n",
                        "1521.7119140625\n",
                        "1380.16259765625\n",
                        "1717.570068359375\n",
                        "1269.86474609375\n",
                        "1092.751708984375\n",
                        "Average loss :  1459.4853515625\n",
                        "\n",
                        "\n",
                        "Epoch 239/5000\n",
                        "Learning rate :  0.001\n",
                        "1768.1077880859375\n",
                        "1515.1796875\n",
                        "1373.7203369140625\n",
                        "1708.480224609375\n",
                        "1263.143310546875\n",
                        "1087.544677734375\n",
                        "Average loss :  1452.6959228515625\n",
                        "\n",
                        "\n",
                        "Epoch 240/5000\n",
                        "Learning rate :  0.001\n",
                        "1761.405517578125\n",
                        "1508.689453125\n",
                        "1367.3231201171875\n",
                        "1699.457275390625\n",
                        "1256.4720458984375\n",
                        "1082.373291015625\n",
                        "Average loss :  1445.9534912109375\n",
                        "\n",
                        "\n",
                        "Epoch 241/5000\n",
                        "Learning rate :  0.001\n",
                        "1754.744873046875\n",
                        "1502.240478515625\n",
                        "1360.970458984375\n",
                        "1690.5009765625\n",
                        "1249.850341796875\n",
                        "1077.2379150390625\n",
                        "Average loss :  1439.2574462890625\n",
                        "\n",
                        "\n",
                        "Epoch 242/5000\n",
                        "Learning rate :  0.001\n",
                        "1748.12548828125\n",
                        "1495.8331298828125\n",
                        "1354.662353515625\n",
                        "1681.6103515625\n",
                        "1243.2783203125\n",
                        "1072.137451171875\n",
                        "Average loss :  1432.60791015625\n",
                        "\n",
                        "\n",
                        "Epoch 243/5000\n",
                        "Learning rate :  0.001\n",
                        "1741.546875\n",
                        "1489.4666748046875\n",
                        "1348.3983154296875\n",
                        "1672.78515625\n",
                        "1236.755126953125\n",
                        "1067.072509765625\n",
                        "Average loss :  1426.0042724609375\n",
                        "\n",
                        "\n",
                        "Epoch 244/5000\n",
                        "Learning rate :  0.001\n",
                        "1735.0087890625\n",
                        "1483.140869140625\n",
                        "1342.177734375\n",
                        "1664.024658203125\n",
                        "1230.28076171875\n",
                        "1062.0421142578125\n",
                        "Average loss :  1419.44580078125\n",
                        "\n",
                        "\n",
                        "Epoch 245/5000\n",
                        "Learning rate :  0.001\n",
                        "1728.510986328125\n",
                        "1476.85546875\n",
                        "1336.000732421875\n",
                        "1655.32861328125\n",
                        "1223.854248046875\n",
                        "1057.046142578125\n",
                        "Average loss :  1412.9326171875\n",
                        "\n",
                        "\n",
                        "Epoch 246/5000\n",
                        "Learning rate :  0.001\n",
                        "1722.05322265625\n",
                        "1470.6099853515625\n",
                        "1329.8665771484375\n",
                        "1646.6962890625\n",
                        "1217.4755859375\n",
                        "1052.0845947265625\n",
                        "Average loss :  1406.46435546875\n",
                        "\n",
                        "\n",
                        "Epoch 247/5000\n",
                        "Learning rate :  0.001\n",
                        "1715.635009765625\n",
                        "1464.404296875\n",
                        "1323.775146484375\n",
                        "1638.1273193359375\n",
                        "1211.14453125\n",
                        "1047.156982421875\n",
                        "Average loss :  1400.04052734375\n",
                        "\n",
                        "\n",
                        "Epoch 248/5000\n",
                        "Learning rate :  0.001\n",
                        "1709.25634765625\n",
                        "1458.23828125\n",
                        "1317.72607421875\n",
                        "1629.620849609375\n",
                        "1204.8602294921875\n",
                        "1042.26318359375\n",
                        "Average loss :  1393.6607666015625\n",
                        "\n",
                        "\n",
                        "Epoch 249/5000\n",
                        "Learning rate :  0.001\n",
                        "1702.916748046875\n",
                        "1452.1114501953125\n",
                        "1311.718994140625\n",
                        "1621.177001953125\n",
                        "1198.622802734375\n",
                        "1037.40283203125\n",
                        "Average loss :  1387.3248291015625\n",
                        "\n",
                        "\n",
                        "Epoch 250/5000\n",
                        "Learning rate :  0.001\n",
                        "1696.6162109375\n",
                        "1446.023681640625\n",
                        "1305.7535400390625\n",
                        "1612.794677734375\n",
                        "1192.431640625\n",
                        "1032.575927734375\n",
                        "Average loss :  1381.0325927734375\n",
                        "\n",
                        "\n",
                        "Epoch 251/5000\n",
                        "Learning rate :  0.001\n",
                        "1690.354248046875\n",
                        "1439.9747314453125\n",
                        "1299.82958984375\n",
                        "1604.4739990234375\n",
                        "1186.286376953125\n",
                        "1027.781982421875\n",
                        "Average loss :  1374.7835693359375\n",
                        "\n",
                        "\n",
                        "Epoch 252/5000\n",
                        "Learning rate :  0.001\n",
                        "1684.130615234375\n",
                        "1433.964111328125\n",
                        "1293.946533203125\n",
                        "1596.214111328125\n",
                        "1180.1868896484375\n",
                        "1023.02099609375\n",
                        "Average loss :  1368.5771484375\n",
                        "\n",
                        "\n",
                        "Epoch 253/5000\n",
                        "Learning rate :  0.001\n",
                        "1677.945068359375\n",
                        "1427.9915771484375\n",
                        "1288.1043701171875\n",
                        "1588.014404296875\n",
                        "1174.132568359375\n",
                        "1018.2924194335938\n",
                        "Average loss :  1362.4134521484375\n",
                        "\n",
                        "\n",
                        "Epoch 254/5000\n",
                        "Learning rate :  0.001\n",
                        "1671.79736328125\n",
                        "1422.05712890625\n",
                        "1282.302490234375\n",
                        "1579.87451171875\n",
                        "1168.123046875\n",
                        "1013.5961303710938\n",
                        "Average loss :  1356.291748046875\n",
                        "\n",
                        "\n",
                        "Epoch 255/5000\n",
                        "Learning rate :  0.001\n",
                        "1665.6871337890625\n",
                        "1416.1602783203125\n",
                        "1276.5408935546875\n",
                        "1571.794189453125\n",
                        "1162.1580810546875\n",
                        "1008.93212890625\n",
                        "Average loss :  1350.2120361328125\n",
                        "\n",
                        "\n",
                        "Epoch 256/5000\n",
                        "Learning rate :  0.001\n",
                        "1659.614501953125\n",
                        "1410.30078125\n",
                        "1270.8192138671875\n",
                        "1563.772705078125\n",
                        "1156.2373046875\n",
                        "1004.2998046875\n",
                        "Average loss :  1344.1739501953125\n",
                        "\n",
                        "\n",
                        "Epoch 257/5000\n",
                        "Learning rate :  0.001\n",
                        "1653.57861328125\n",
                        "1404.478515625\n",
                        "1265.13671875\n",
                        "1555.8096923828125\n",
                        "1150.3602294921875\n",
                        "999.6991577148438\n",
                        "Average loss :  1338.1771240234375\n",
                        "\n",
                        "\n",
                        "Epoch 258/5000\n",
                        "Learning rate :  0.001\n",
                        "1647.5797119140625\n",
                        "1398.6929931640625\n",
                        "1259.49365234375\n",
                        "1547.904541015625\n",
                        "1144.526611328125\n",
                        "995.130126953125\n",
                        "Average loss :  1332.2213134765625\n",
                        "\n",
                        "\n",
                        "Epoch 259/5000\n",
                        "Learning rate :  0.001\n",
                        "1641.617431640625\n",
                        "1392.9444580078125\n",
                        "1253.889404296875\n",
                        "1540.0570068359375\n",
                        "1138.736083984375\n",
                        "990.5919189453125\n",
                        "Average loss :  1326.3060302734375\n",
                        "\n",
                        "\n",
                        "Epoch 260/5000\n",
                        "Learning rate :  0.001\n",
                        "1635.6912841796875\n",
                        "1387.2318115234375\n",
                        "1248.3236083984375\n",
                        "1532.2664794921875\n",
                        "1132.988037109375\n",
                        "986.0846557617188\n",
                        "Average loss :  1320.4310302734375\n",
                        "\n",
                        "\n",
                        "Epoch 261/5000\n",
                        "Learning rate :  0.001\n",
                        "1629.80126953125\n",
                        "1381.555419921875\n",
                        "1242.7962646484375\n",
                        "1524.53271484375\n",
                        "1127.2828369140625\n",
                        "981.6080932617188\n",
                        "Average loss :  1314.5960693359375\n",
                        "\n",
                        "\n",
                        "Epoch 262/5000\n",
                        "Learning rate :  0.001\n",
                        "1623.94677734375\n",
                        "1375.914794921875\n",
                        "1237.306884765625\n",
                        "1516.8551025390625\n",
                        "1121.6195068359375\n",
                        "977.1619262695312\n",
                        "Average loss :  1308.8009033203125\n",
                        "\n",
                        "\n",
                        "Epoch 263/5000\n",
                        "Learning rate :  0.001\n",
                        "1618.128173828125\n",
                        "1370.309814453125\n",
                        "1231.85498046875\n",
                        "1509.233154296875\n",
                        "1115.998046875\n",
                        "972.746337890625\n",
                        "Average loss :  1303.0450439453125\n",
                        "\n",
                        "\n",
                        "Epoch 264/5000\n",
                        "Learning rate :  0.001\n",
                        "1612.3447265625\n",
                        "1364.740234375\n",
                        "1226.44091796875\n",
                        "1501.6666259765625\n",
                        "1110.41796875\n",
                        "968.3605346679688\n",
                        "Average loss :  1297.3284912109375\n",
                        "\n",
                        "\n",
                        "Epoch 265/5000\n",
                        "Learning rate :  0.001\n",
                        "1606.596435546875\n",
                        "1359.205810546875\n",
                        "1221.06396484375\n",
                        "1494.155029296875\n",
                        "1104.879150390625\n",
                        "964.0045776367188\n",
                        "Average loss :  1291.65087890625\n",
                        "\n",
                        "\n",
                        "Epoch 266/5000\n",
                        "Learning rate :  0.001\n",
                        "1600.8828125\n",
                        "1353.7061767578125\n",
                        "1215.7236328125\n",
                        "1486.69775390625\n",
                        "1099.381103515625\n",
                        "959.6784057617188\n",
                        "Average loss :  1286.0115966796875\n",
                        "\n",
                        "\n",
                        "Epoch 267/5000\n",
                        "Learning rate :  0.001\n",
                        "1595.2041015625\n",
                        "1348.2413330078125\n",
                        "1210.420166015625\n",
                        "1479.294677734375\n",
                        "1093.92333984375\n",
                        "955.38134765625\n",
                        "Average loss :  1280.4107666015625\n",
                        "\n",
                        "\n",
                        "Epoch 268/5000\n",
                        "Learning rate :  0.001\n",
                        "1589.5594482421875\n",
                        "1342.810791015625\n",
                        "1205.1527099609375\n",
                        "1471.9449462890625\n",
                        "1088.5057373046875\n",
                        "951.1135864257812\n",
                        "Average loss :  1274.8477783203125\n",
                        "\n",
                        "\n",
                        "Epoch 269/5000\n",
                        "Learning rate :  0.001\n",
                        "1583.948974609375\n",
                        "1337.414306640625\n",
                        "1199.92138671875\n",
                        "1464.6483154296875\n",
                        "1083.1279296875\n",
                        "946.8748168945312\n",
                        "Average loss :  1269.3226318359375\n",
                        "\n",
                        "\n",
                        "Epoch 270/5000\n",
                        "Learning rate :  0.001\n",
                        "1578.37255859375\n",
                        "1332.052001953125\n",
                        "1194.7259521484375\n",
                        "1457.40478515625\n",
                        "1077.789794921875\n",
                        "942.6649780273438\n",
                        "Average loss :  1263.8350830078125\n",
                        "\n",
                        "\n",
                        "Epoch 271/5000\n",
                        "Learning rate :  0.001\n",
                        "1572.829833984375\n",
                        "1326.723388671875\n",
                        "1189.5660400390625\n",
                        "1450.21337890625\n",
                        "1072.49072265625\n",
                        "938.4834594726562\n",
                        "Average loss :  1258.3843994140625\n",
                        "\n",
                        "\n",
                        "Epoch 272/5000\n",
                        "Learning rate :  0.001\n",
                        "1567.3203125\n",
                        "1321.4281005859375\n",
                        "1184.441162109375\n",
                        "1443.073974609375\n",
                        "1067.2305908203125\n",
                        "934.3302612304688\n",
                        "Average loss :  1252.970703125\n",
                        "\n",
                        "\n",
                        "Epoch 273/5000\n",
                        "Learning rate :  0.001\n",
                        "1561.84423828125\n",
                        "1316.166015625\n",
                        "1179.351318359375\n",
                        "1435.9859619140625\n",
                        "1062.009033203125\n",
                        "930.2052001953125\n",
                        "Average loss :  1247.5936279296875\n",
                        "\n",
                        "\n",
                        "Epoch 274/5000\n",
                        "Learning rate :  0.001\n",
                        "1556.40087890625\n",
                        "1310.93701171875\n",
                        "1174.2960205078125\n",
                        "1428.94921875\n",
                        "1056.82568359375\n",
                        "926.1079711914062\n",
                        "Average loss :  1242.2528076171875\n",
                        "\n",
                        "\n",
                        "Epoch 275/5000\n",
                        "Learning rate :  0.001\n",
                        "1550.990478515625\n",
                        "1305.740478515625\n",
                        "1169.275146484375\n",
                        "1421.962890625\n",
                        "1051.6802978515625\n",
                        "922.0386352539062\n",
                        "Average loss :  1236.9481201171875\n",
                        "\n",
                        "\n",
                        "Epoch 276/5000\n",
                        "Learning rate :  0.001\n",
                        "1545.612548828125\n",
                        "1300.5767822265625\n",
                        "1164.28857421875\n",
                        "1415.0272216796875\n",
                        "1046.57275390625\n",
                        "917.9967041015625\n",
                        "Average loss :  1231.6790771484375\n",
                        "\n",
                        "\n",
                        "Epoch 277/5000\n",
                        "Learning rate :  0.001\n",
                        "1540.266845703125\n",
                        "1295.4451904296875\n",
                        "1159.335693359375\n",
                        "1408.1412353515625\n",
                        "1041.50244140625\n",
                        "913.98193359375\n",
                        "Average loss :  1226.445556640625\n",
                        "\n",
                        "\n",
                        "Epoch 278/5000\n",
                        "Learning rate :  0.001\n",
                        "1534.953125\n",
                        "1290.345703125\n",
                        "1154.41650390625\n",
                        "1401.3048095703125\n",
                        "1036.4691162109375\n",
                        "909.9942626953125\n",
                        "Average loss :  1221.2471923828125\n",
                        "\n",
                        "\n",
                        "Epoch 279/5000\n",
                        "Learning rate :  0.001\n",
                        "1529.671142578125\n",
                        "1285.2779541015625\n",
                        "1149.5306396484375\n",
                        "1394.517333984375\n",
                        "1031.47265625\n",
                        "906.03369140625\n",
                        "Average loss :  1216.083984375\n",
                        "\n",
                        "\n",
                        "Epoch 280/5000\n",
                        "Learning rate :  0.001\n",
                        "1524.421142578125\n",
                        "1280.2420654296875\n",
                        "1144.677978515625\n",
                        "1387.77880859375\n",
                        "1026.5126953125\n",
                        "902.099609375\n",
                        "Average loss :  1210.955322265625\n",
                        "\n",
                        "\n",
                        "Epoch 281/5000\n",
                        "Learning rate :  0.001\n",
                        "1519.2022705078125\n",
                        "1275.2373046875\n",
                        "1139.85791015625\n",
                        "1381.08837890625\n",
                        "1021.5887451171875\n",
                        "898.1919555664062\n",
                        "Average loss :  1205.861083984375\n",
                        "\n",
                        "\n",
                        "Epoch 282/5000\n",
                        "Learning rate :  0.001\n",
                        "1514.0146484375\n",
                        "1270.263916015625\n",
                        "1135.0706787109375\n",
                        "1374.446044921875\n",
                        "1016.700927734375\n",
                        "894.3106689453125\n",
                        "Average loss :  1200.8011474609375\n",
                        "\n",
                        "\n",
                        "Epoch 283/5000\n",
                        "Learning rate :  0.001\n",
                        "1508.858154296875\n",
                        "1265.3212890625\n",
                        "1130.315673828125\n",
                        "1367.851318359375\n",
                        "1011.8485107421875\n",
                        "890.4556274414062\n",
                        "Average loss :  1195.7750244140625\n",
                        "\n",
                        "\n",
                        "Epoch 284/5000\n",
                        "Learning rate :  0.001\n",
                        "1503.7322998046875\n",
                        "1260.4097900390625\n",
                        "1125.593017578125\n",
                        "1361.3040771484375\n",
                        "1007.0318603515625\n",
                        "886.62646484375\n",
                        "Average loss :  1190.782958984375\n",
                        "\n",
                        "\n",
                        "Epoch 285/5000\n",
                        "Learning rate :  0.001\n",
                        "1498.6373291015625\n",
                        "1255.5286865234375\n",
                        "1120.9022216796875\n",
                        "1354.803466796875\n",
                        "1002.25\n",
                        "882.8231201171875\n",
                        "Average loss :  1185.82421875\n",
                        "\n",
                        "\n",
                        "Epoch 286/5000\n",
                        "Learning rate :  0.001\n",
                        "1493.572265625\n",
                        "1250.6778564453125\n",
                        "1116.242919921875\n",
                        "1348.3494873046875\n",
                        "997.5030517578125\n",
                        "879.0452880859375\n",
                        "Average loss :  1180.8984375\n",
                        "\n",
                        "\n",
                        "Epoch 287/5000\n",
                        "Learning rate :  0.001\n",
                        "1488.537841796875\n",
                        "1245.8572998046875\n",
                        "1111.615234375\n",
                        "1341.941650390625\n",
                        "992.7905883789062\n",
                        "875.29296875\n",
                        "Average loss :  1176.005859375\n",
                        "\n",
                        "\n",
                        "Epoch 288/5000\n",
                        "Learning rate :  0.001\n",
                        "1483.533203125\n",
                        "1241.066650390625\n",
                        "1107.0185546875\n",
                        "1335.5794677734375\n",
                        "988.1124877929688\n",
                        "871.5657348632812\n",
                        "Average loss :  1171.1461181640625\n",
                        "\n",
                        "\n",
                        "Epoch 289/5000\n",
                        "Learning rate :  0.001\n",
                        "1478.55810546875\n",
                        "1236.3056640625\n",
                        "1102.45263671875\n",
                        "1329.2626953125\n",
                        "983.4681396484375\n",
                        "867.8633422851562\n",
                        "Average loss :  1166.3184814453125\n",
                        "\n",
                        "\n",
                        "Epoch 290/5000\n",
                        "Learning rate :  0.001\n",
                        "1473.61279296875\n",
                        "1231.5740966796875\n",
                        "1097.9176025390625\n",
                        "1322.9908447265625\n",
                        "978.8575439453125\n",
                        "864.185791015625\n",
                        "Average loss :  1161.5230712890625\n",
                        "\n",
                        "\n",
                        "Epoch 291/5000\n",
                        "Learning rate :  0.001\n",
                        "1468.696533203125\n",
                        "1226.871826171875\n",
                        "1093.4127197265625\n",
                        "1316.763671875\n",
                        "974.2802124023438\n",
                        "860.5328369140625\n",
                        "Average loss :  1156.7596435546875\n",
                        "\n",
                        "\n",
                        "Epoch 292/5000\n",
                        "Learning rate :  0.001\n",
                        "1463.8094482421875\n",
                        "1222.198486328125\n",
                        "1088.938232421875\n",
                        "1310.5809326171875\n",
                        "969.7364501953125\n",
                        "856.9044189453125\n",
                        "Average loss :  1152.0279541015625\n",
                        "\n",
                        "\n",
                        "Epoch 293/5000\n",
                        "Learning rate :  0.001\n",
                        "1458.951416015625\n",
                        "1217.554443359375\n",
                        "1084.4937744140625\n",
                        "1304.4422607421875\n",
                        "965.2254028320312\n",
                        "853.3002319335938\n",
                        "Average loss :  1147.327880859375\n",
                        "\n",
                        "\n",
                        "Epoch 294/5000\n",
                        "Learning rate :  0.001\n",
                        "1454.1221923828125\n",
                        "1212.938720703125\n",
                        "1080.0791015625\n",
                        "1298.34716796875\n",
                        "960.7471313476562\n",
                        "849.7202758789062\n",
                        "Average loss :  1142.6590576171875\n",
                        "\n",
                        "\n",
                        "Epoch 295/5000\n",
                        "Learning rate :  0.001\n",
                        "1449.3214111328125\n",
                        "1208.351806640625\n",
                        "1075.6939697265625\n",
                        "1292.29541015625\n",
                        "956.3012084960938\n",
                        "846.164306640625\n",
                        "Average loss :  1138.0213623046875\n",
                        "\n",
                        "\n",
                        "Epoch 296/5000\n",
                        "Learning rate :  0.001\n",
                        "1444.54931640625\n",
                        "1203.793212890625\n",
                        "1071.338134765625\n",
                        "1286.286865234375\n",
                        "951.887451171875\n",
                        "842.6318359375\n",
                        "Average loss :  1133.41455078125\n",
                        "\n",
                        "\n",
                        "Epoch 297/5000\n",
                        "Learning rate :  0.001\n",
                        "1439.80517578125\n",
                        "1199.2625732421875\n",
                        "1067.011474609375\n",
                        "1280.320556640625\n",
                        "947.5055541992188\n",
                        "839.1229858398438\n",
                        "Average loss :  1128.8380126953125\n",
                        "\n",
                        "\n",
                        "Epoch 298/5000\n",
                        "Learning rate :  0.001\n",
                        "1435.0887451171875\n",
                        "1194.759765625\n",
                        "1062.7135009765625\n",
                        "1274.396728515625\n",
                        "943.1553344726562\n",
                        "835.6375732421875\n",
                        "Average loss :  1124.2919921875\n",
                        "\n",
                        "\n",
                        "Epoch 299/5000\n",
                        "Learning rate :  0.001\n",
                        "1430.400390625\n",
                        "1190.284912109375\n",
                        "1058.444091796875\n",
                        "1268.5150146484375\n",
                        "938.8364868164062\n",
                        "832.17529296875\n",
                        "Average loss :  1119.776123046875\n",
                        "\n",
                        "\n",
                        "Epoch 300/5000\n",
                        "Learning rate :  0.001\n",
                        "1425.7393798828125\n",
                        "1185.8372802734375\n",
                        "1054.203369140625\n",
                        "1262.6748046875\n",
                        "934.548828125\n",
                        "828.7362060546875\n",
                        "Average loss :  1115.2900390625\n",
                        "\n",
                        "\n",
                        "Epoch 301/5000\n",
                        "Learning rate :  0.001\n",
                        "1421.10595703125\n",
                        "1181.417236328125\n",
                        "1049.990966796875\n",
                        "1256.8760986328125\n",
                        "930.292236328125\n",
                        "825.3201904296875\n",
                        "Average loss :  1110.8338623046875\n",
                        "\n",
                        "\n",
                        "Epoch 302/5000\n",
                        "Learning rate :  0.001\n",
                        "1416.5\n",
                        "1177.0244140625\n",
                        "1045.8065185546875\n",
                        "1251.118408203125\n",
                        "926.0662231445312\n",
                        "821.9268798828125\n",
                        "Average loss :  1106.4071044921875\n",
                        "\n",
                        "\n",
                        "Epoch 303/5000\n",
                        "Learning rate :  0.001\n",
                        "1411.9208984375\n",
                        "1172.658447265625\n",
                        "1041.649658203125\n",
                        "1245.4013671875\n",
                        "921.8706665039062\n",
                        "818.5560302734375\n",
                        "Average loss :  1102.0093994140625\n",
                        "\n",
                        "\n",
                        "Epoch 304/5000\n",
                        "Learning rate :  0.001\n",
                        "1407.36865234375\n",
                        "1168.3193359375\n",
                        "1037.520751953125\n",
                        "1239.7247314453125\n",
                        "917.7054443359375\n",
                        "815.2075805664062\n",
                        "Average loss :  1097.64111328125\n",
                        "\n",
                        "\n",
                        "Epoch 305/5000\n",
                        "Learning rate :  0.001\n",
                        "1402.8431396484375\n",
                        "1164.0068359375\n",
                        "1033.4190673828125\n",
                        "1234.0880126953125\n",
                        "913.5698852539062\n",
                        "811.8814086914062\n",
                        "Average loss :  1093.3013916015625\n",
                        "\n",
                        "\n",
                        "Epoch 306/5000\n",
                        "Learning rate :  0.001\n",
                        "1398.3441162109375\n",
                        "1159.7205810546875\n",
                        "1029.344482421875\n",
                        "1228.4912109375\n",
                        "909.4641723632812\n",
                        "808.5771484375\n",
                        "Average loss :  1088.990234375\n",
                        "\n",
                        "\n",
                        "Epoch 307/5000\n",
                        "Learning rate :  0.001\n",
                        "1393.8712158203125\n",
                        "1155.460693359375\n",
                        "1025.2969970703125\n",
                        "1222.93359375\n",
                        "905.3878784179688\n",
                        "805.2948608398438\n",
                        "Average loss :  1084.70751953125\n",
                        "\n",
                        "\n",
                        "Epoch 308/5000\n",
                        "Learning rate :  0.001\n",
                        "1389.4246826171875\n",
                        "1151.2265625\n",
                        "1021.276123046875\n",
                        "1217.4151611328125\n",
                        "901.3408813476562\n",
                        "802.0343017578125\n",
                        "Average loss :  1080.4530029296875\n",
                        "\n",
                        "\n",
                        "Epoch 309/5000\n",
                        "Learning rate :  0.001\n",
                        "1385.003662109375\n",
                        "1147.018310546875\n",
                        "1017.28173828125\n",
                        "1211.935546875\n",
                        "897.3228759765625\n",
                        "798.79541015625\n",
                        "Average loss :  1076.226318359375\n",
                        "\n",
                        "\n",
                        "Epoch 310/5000\n",
                        "Learning rate :  0.001\n",
                        "1380.608642578125\n",
                        "1142.8359375\n",
                        "1013.3138427734375\n",
                        "1206.49462890625\n",
                        "893.3336791992188\n",
                        "795.5779418945312\n",
                        "Average loss :  1072.0274658203125\n",
                        "\n",
                        "\n",
                        "Epoch 311/5000\n",
                        "Learning rate :  0.001\n",
                        "1376.239501953125\n",
                        "1138.6790771484375\n",
                        "1009.3721313476562\n",
                        "1201.0916748046875\n",
                        "889.3731079101562\n",
                        "792.3818359375\n",
                        "Average loss :  1067.856201171875\n",
                        "\n",
                        "\n",
                        "Epoch 312/5000\n",
                        "Learning rate :  0.001\n",
                        "1371.8955078125\n",
                        "1134.547607421875\n",
                        "1005.4564208984375\n",
                        "1195.72705078125\n",
                        "885.4409790039062\n",
                        "789.206787109375\n",
                        "Average loss :  1063.71240234375\n",
                        "\n",
                        "\n",
                        "Epoch 313/5000\n",
                        "Learning rate :  0.001\n",
                        "1367.5770263671875\n",
                        "1130.4412841796875\n",
                        "1001.566650390625\n",
                        "1190.39990234375\n",
                        "881.536865234375\n",
                        "786.052734375\n",
                        "Average loss :  1059.5958251953125\n",
                        "\n",
                        "\n",
                        "Epoch 314/5000\n",
                        "Learning rate :  0.001\n",
                        "1363.2835693359375\n",
                        "1126.3599853515625\n",
                        "997.7021484375\n",
                        "1185.10986328125\n",
                        "877.66064453125\n",
                        "782.9195556640625\n",
                        "Average loss :  1055.5059814453125\n",
                        "\n",
                        "\n",
                        "Epoch 315/5000\n",
                        "Learning rate :  0.001\n",
                        "1359.014892578125\n",
                        "1122.3033447265625\n",
                        "993.8632202148438\n",
                        "1179.8568115234375\n",
                        "873.8121337890625\n",
                        "779.8070068359375\n",
                        "Average loss :  1051.4429931640625\n",
                        "\n",
                        "\n",
                        "Epoch 316/5000\n",
                        "Learning rate :  0.001\n",
                        "1354.771240234375\n",
                        "1118.271484375\n",
                        "990.049560546875\n",
                        "1174.640869140625\n",
                        "869.990966796875\n",
                        "776.71484375\n",
                        "Average loss :  1047.4063720703125\n",
                        "\n",
                        "\n",
                        "Epoch 317/5000\n",
                        "Learning rate :  0.001\n",
                        "1350.5518798828125\n",
                        "1114.2637939453125\n",
                        "986.2605590820312\n",
                        "1169.4609375\n",
                        "866.197021484375\n",
                        "773.64306640625\n",
                        "Average loss :  1043.396240234375\n",
                        "\n",
                        "\n",
                        "Epoch 318/5000\n",
                        "Learning rate :  0.001\n",
                        "1346.35693359375\n",
                        "1110.280517578125\n",
                        "982.4967041015625\n",
                        "1164.3173828125\n",
                        "862.4302368164062\n",
                        "770.591552734375\n",
                        "Average loss :  1039.4122314453125\n",
                        "\n",
                        "\n",
                        "Epoch 319/5000\n",
                        "Learning rate :  0.001\n",
                        "1342.186279296875\n",
                        "1106.32177734375\n",
                        "978.75732421875\n",
                        "1159.2099609375\n",
                        "858.6902465820312\n",
                        "767.5601806640625\n",
                        "Average loss :  1035.4542236328125\n",
                        "\n",
                        "\n",
                        "Epoch 320/5000\n",
                        "Learning rate :  0.001\n",
                        "1338.0396728515625\n",
                        "1102.3863525390625\n",
                        "975.0423583984375\n",
                        "1154.1376953125\n",
                        "854.976806640625\n",
                        "764.548583984375\n",
                        "Average loss :  1031.52197265625\n",
                        "\n",
                        "\n",
                        "Epoch 321/5000\n",
                        "Learning rate :  0.001\n",
                        "1333.9169921875\n",
                        "1098.47509765625\n",
                        "971.351806640625\n",
                        "1149.10107421875\n",
                        "851.289794921875\n",
                        "761.556884765625\n",
                        "Average loss :  1027.6153564453125\n",
                        "\n",
                        "\n",
                        "Epoch 322/5000\n",
                        "Learning rate :  0.001\n",
                        "1329.818115234375\n",
                        "1094.58740234375\n",
                        "967.685302734375\n",
                        "1144.099609375\n",
                        "847.6290283203125\n",
                        "758.584716796875\n",
                        "Average loss :  1023.7340698242188\n",
                        "\n",
                        "\n",
                        "Epoch 323/5000\n",
                        "Learning rate :  0.001\n",
                        "1325.742919921875\n",
                        "1090.7232666015625\n",
                        "964.042724609375\n",
                        "1139.1328125\n",
                        "843.994384765625\n",
                        "755.6322021484375\n",
                        "Average loss :  1019.8781127929688\n",
                        "\n",
                        "\n",
                        "Epoch 324/5000\n",
                        "Learning rate :  0.001\n",
                        "1321.691162109375\n",
                        "1086.8824462890625\n",
                        "960.4239501953125\n",
                        "1134.2005615234375\n",
                        "840.3854370117188\n",
                        "752.6990966796875\n",
                        "Average loss :  1016.047119140625\n",
                        "\n",
                        "\n",
                        "Epoch 325/5000\n",
                        "Learning rate :  0.001\n",
                        "1317.662841796875\n",
                        "1083.06494140625\n",
                        "956.82861328125\n",
                        "1129.302734375\n",
                        "836.8021240234375\n",
                        "749.78515625\n",
                        "Average loss :  1012.2410278320312\n",
                        "\n",
                        "\n",
                        "Epoch 326/5000\n",
                        "Learning rate :  0.001\n",
                        "1313.657470703125\n",
                        "1079.270263671875\n",
                        "953.2568359375\n",
                        "1124.438720703125\n",
                        "833.244140625\n",
                        "746.89013671875\n",
                        "Average loss :  1008.4596557617188\n",
                        "\n",
                        "\n",
                        "Epoch 327/5000\n",
                        "Learning rate :  0.001\n",
                        "1309.6751708984375\n",
                        "1075.498291015625\n",
                        "949.7080078125\n",
                        "1119.608642578125\n",
                        "829.7114868164062\n",
                        "744.0142822265625\n",
                        "Average loss :  1004.70263671875\n",
                        "\n",
                        "\n",
                        "Epoch 328/5000\n",
                        "Learning rate :  0.001\n",
                        "1305.7158203125\n",
                        "1071.749267578125\n",
                        "946.1824951171875\n",
                        "1114.81201171875\n",
                        "826.2037353515625\n",
                        "741.1570434570312\n",
                        "Average loss :  1000.9700317382812\n",
                        "\n",
                        "\n",
                        "Epoch 329/5000\n",
                        "Learning rate :  0.001\n",
                        "1301.779052734375\n",
                        "1068.0225830078125\n",
                        "942.6796264648438\n",
                        "1110.048583984375\n",
                        "822.7208251953125\n",
                        "738.3184814453125\n",
                        "Average loss :  997.2615356445312\n",
                        "\n",
                        "\n",
                        "Epoch 330/5000\n",
                        "Learning rate :  0.001\n",
                        "1297.864501953125\n",
                        "1064.318359375\n",
                        "939.1995849609375\n",
                        "1105.318115234375\n",
                        "819.2625732421875\n",
                        "735.4985961914062\n",
                        "Average loss :  993.5769653320312\n",
                        "\n",
                        "\n",
                        "Epoch 331/5000\n",
                        "Learning rate :  0.001\n",
                        "1293.97265625\n",
                        "1060.6363525390625\n",
                        "935.7420654296875\n",
                        "1100.620361328125\n",
                        "815.8287353515625\n",
                        "732.6971435546875\n",
                        "Average loss :  989.9161987304688\n",
                        "\n",
                        "\n",
                        "Epoch 332/5000\n",
                        "Learning rate :  0.001\n",
                        "1290.10302734375\n",
                        "1056.9764404296875\n",
                        "932.3069458007812\n",
                        "1095.955078125\n",
                        "812.4190673828125\n",
                        "729.9139404296875\n",
                        "Average loss :  986.2791137695312\n",
                        "\n",
                        "\n",
                        "Epoch 333/5000\n",
                        "Learning rate :  0.001\n",
                        "1286.2554931640625\n",
                        "1053.3385009765625\n",
                        "928.893798828125\n",
                        "1091.322021484375\n",
                        "809.0335083007812\n",
                        "727.1488037109375\n",
                        "Average loss :  982.6653442382812\n",
                        "\n",
                        "\n",
                        "Epoch 334/5000\n",
                        "Learning rate :  0.001\n",
                        "1282.4298095703125\n",
                        "1049.72216796875\n",
                        "925.5027465820312\n",
                        "1086.720703125\n",
                        "805.671630859375\n",
                        "724.4014282226562\n",
                        "Average loss :  979.0747680664062\n",
                        "\n",
                        "\n",
                        "Epoch 335/5000\n",
                        "Learning rate :  0.001\n",
                        "1278.625732421875\n",
                        "1046.12744140625\n",
                        "922.1334228515625\n",
                        "1082.151123046875\n",
                        "802.33349609375\n",
                        "721.6719970703125\n",
                        "Average loss :  975.5071411132812\n",
                        "\n",
                        "\n",
                        "Epoch 336/5000\n",
                        "Learning rate :  0.001\n",
                        "1274.843505859375\n",
                        "1042.55419921875\n",
                        "918.7861328125\n",
                        "1077.61328125\n",
                        "799.0189208984375\n",
                        "718.96044921875\n",
                        "Average loss :  971.9627075195312\n",
                        "\n",
                        "\n",
                        "Epoch 337/5000\n",
                        "Learning rate :  0.001\n",
                        "1271.0826416015625\n",
                        "1039.00244140625\n",
                        "915.4601440429688\n",
                        "1073.1065673828125\n",
                        "795.7274780273438\n",
                        "716.2664184570312\n",
                        "Average loss :  968.44091796875\n",
                        "\n",
                        "\n",
                        "Epoch 338/5000\n",
                        "Learning rate :  0.001\n",
                        "1267.3431396484375\n",
                        "1035.4715576171875\n",
                        "912.1555786132812\n",
                        "1068.630615234375\n",
                        "792.4594116210938\n",
                        "713.5899658203125\n",
                        "Average loss :  964.9417114257812\n",
                        "\n",
                        "\n",
                        "Epoch 339/5000\n",
                        "Learning rate :  0.001\n",
                        "1263.624755859375\n",
                        "1031.9619140625\n",
                        "908.872314453125\n",
                        "1064.185546875\n",
                        "789.2140502929688\n",
                        "710.9306640625\n",
                        "Average loss :  961.46484375\n",
                        "\n",
                        "\n",
                        "Epoch 340/5000\n",
                        "Learning rate :  0.001\n",
                        "1259.927490234375\n",
                        "1028.4730224609375\n",
                        "905.6099853515625\n",
                        "1059.7708740234375\n",
                        "785.99169921875\n",
                        "708.2888793945312\n",
                        "Average loss :  958.0103149414062\n",
                        "\n",
                        "\n",
                        "Epoch 341/5000\n",
                        "Learning rate :  0.001\n",
                        "1256.25146484375\n",
                        "1025.0052490234375\n",
                        "902.3688354492188\n",
                        "1055.38671875\n",
                        "782.7918701171875\n",
                        "705.6640625\n",
                        "Average loss :  954.5780639648438\n",
                        "\n",
                        "\n",
                        "Epoch 342/5000\n",
                        "Learning rate :  0.001\n",
                        "1252.595947265625\n",
                        "1021.5576171875\n",
                        "899.1481323242188\n",
                        "1051.0325927734375\n",
                        "779.6143798828125\n",
                        "703.0562133789062\n",
                        "Average loss :  951.16748046875\n",
                        "\n",
                        "\n",
                        "Epoch 343/5000\n",
                        "Learning rate :  0.001\n",
                        "1248.9610595703125\n",
                        "1018.1307373046875\n",
                        "895.9481201171875\n",
                        "1046.7081298828125\n",
                        "776.4591064453125\n",
                        "700.4652709960938\n",
                        "Average loss :  947.7787475585938\n",
                        "\n",
                        "\n",
                        "Epoch 344/5000\n",
                        "Learning rate :  0.001\n",
                        "1245.3466796875\n",
                        "1014.72412109375\n",
                        "892.7684936523438\n",
                        "1042.413330078125\n",
                        "773.325927734375\n",
                        "697.89111328125\n",
                        "Average loss :  944.41162109375\n",
                        "\n",
                        "\n",
                        "Epoch 345/5000\n",
                        "Learning rate :  0.001\n",
                        "1241.7528076171875\n",
                        "1011.337646484375\n",
                        "889.6093139648438\n",
                        "1038.14794921875\n",
                        "770.2147216796875\n",
                        "695.3333740234375\n",
                        "Average loss :  941.06591796875\n",
                        "\n",
                        "\n",
                        "Epoch 346/5000\n",
                        "Learning rate :  0.001\n",
                        "1238.178955078125\n",
                        "1007.9712524414062\n",
                        "886.4701538085938\n",
                        "1033.91162109375\n",
                        "767.1250610351562\n",
                        "692.792236328125\n",
                        "Average loss :  937.7415161132812\n",
                        "\n",
                        "\n",
                        "Epoch 347/5000\n",
                        "Learning rate :  0.001\n",
                        "1234.625244140625\n",
                        "1004.6245727539062\n",
                        "883.3509521484375\n",
                        "1029.7039794921875\n",
                        "764.056884765625\n",
                        "690.2674560546875\n",
                        "Average loss :  934.438232421875\n",
                        "\n",
                        "\n",
                        "Epoch 348/5000\n",
                        "Learning rate :  0.001\n",
                        "1231.0914306640625\n",
                        "1001.2977905273438\n",
                        "880.2515869140625\n",
                        "1025.525390625\n",
                        "761.0103759765625\n",
                        "687.7589721679688\n",
                        "Average loss :  931.1559448242188\n",
                        "\n",
                        "\n",
                        "Epoch 349/5000\n",
                        "Learning rate :  0.001\n",
                        "1227.57763671875\n",
                        "997.99072265625\n",
                        "877.172119140625\n",
                        "1021.375\n",
                        "757.9849243164062\n",
                        "685.2667846679688\n",
                        "Average loss :  927.89453125\n",
                        "\n",
                        "\n",
                        "Epoch 350/5000\n",
                        "Learning rate :  0.001\n",
                        "1224.0836181640625\n",
                        "994.7032470703125\n",
                        "874.1119995117188\n",
                        "1017.2529296875\n",
                        "754.9805908203125\n",
                        "682.79052734375\n",
                        "Average loss :  924.65380859375\n",
                        "\n",
                        "\n",
                        "Epoch 351/5000\n",
                        "Learning rate :  0.001\n",
                        "1220.609130859375\n",
                        "991.43505859375\n",
                        "871.0714111328125\n",
                        "1013.1588745117188\n",
                        "751.9970703125\n",
                        "680.3301391601562\n",
                        "Average loss :  921.43359375\n",
                        "\n",
                        "\n",
                        "Epoch 352/5000\n",
                        "Learning rate :  0.001\n",
                        "1217.15380859375\n",
                        "988.1860961914062\n",
                        "868.050048828125\n",
                        "1009.0926513671875\n",
                        "749.0343017578125\n",
                        "677.8855590820312\n",
                        "Average loss :  918.2337036132812\n",
                        "\n",
                        "\n",
                        "Epoch 353/5000\n",
                        "Learning rate :  0.001\n",
                        "1213.718017578125\n",
                        "984.9562377929688\n",
                        "865.0479736328125\n",
                        "1005.0540161132812\n",
                        "746.0921630859375\n",
                        "675.4564819335938\n",
                        "Average loss :  915.05419921875\n",
                        "\n",
                        "\n",
                        "Epoch 354/5000\n",
                        "Learning rate :  0.001\n",
                        "1210.30126953125\n",
                        "981.7451171875\n",
                        "862.0645141601562\n",
                        "1001.04248046875\n",
                        "743.1702880859375\n",
                        "673.043212890625\n",
                        "Average loss :  911.8944702148438\n",
                        "\n",
                        "\n",
                        "Epoch 355/5000\n",
                        "Learning rate :  0.001\n",
                        "1206.903564453125\n",
                        "978.5530395507812\n",
                        "859.10009765625\n",
                        "997.0584716796875\n",
                        "740.2687377929688\n",
                        "670.6452026367188\n",
                        "Average loss :  908.7548828125\n",
                        "\n",
                        "\n",
                        "Epoch 356/5000\n",
                        "Learning rate :  0.001\n",
                        "1203.52490234375\n",
                        "975.379638671875\n",
                        "856.154296875\n",
                        "993.1011962890625\n",
                        "737.38720703125\n",
                        "668.2626342773438\n",
                        "Average loss :  905.635009765625\n",
                        "\n",
                        "\n",
                        "Epoch 357/5000\n",
                        "Learning rate :  0.001\n",
                        "1200.164794921875\n",
                        "972.2249145507812\n",
                        "853.2271728515625\n",
                        "989.170654296875\n",
                        "734.525634765625\n",
                        "665.8951416015625\n",
                        "Average loss :  902.53466796875\n",
                        "\n",
                        "\n",
                        "Epoch 358/5000\n",
                        "Learning rate :  0.001\n",
                        "1196.823486328125\n",
                        "969.08837890625\n",
                        "850.3182373046875\n",
                        "985.2667846679688\n",
                        "731.683837890625\n",
                        "663.5428466796875\n",
                        "Average loss :  899.4539184570312\n",
                        "\n",
                        "\n",
                        "Epoch 359/5000\n",
                        "Learning rate :  0.001\n",
                        "1193.5006103515625\n",
                        "965.97021484375\n",
                        "847.4276733398438\n",
                        "981.3890991210938\n",
                        "728.861572265625\n",
                        "661.2055053710938\n",
                        "Average loss :  896.3923950195312\n",
                        "\n",
                        "\n",
                        "Epoch 360/5000\n",
                        "Learning rate :  0.001\n",
                        "1190.1962890625\n",
                        "962.870361328125\n",
                        "844.555419921875\n",
                        "977.53759765625\n",
                        "726.0589599609375\n",
                        "658.88330078125\n",
                        "Average loss :  893.350341796875\n",
                        "\n",
                        "\n",
                        "Epoch 361/5000\n",
                        "Learning rate :  0.001\n",
                        "1186.910400390625\n",
                        "959.7888793945312\n",
                        "841.7010498046875\n",
                        "973.7122802734375\n",
                        "723.275634765625\n",
                        "656.5758056640625\n",
                        "Average loss :  890.3273315429688\n",
                        "\n",
                        "\n",
                        "Epoch 362/5000\n",
                        "Learning rate :  0.001\n",
                        "1183.642578125\n",
                        "956.7250366210938\n",
                        "838.8646850585938\n",
                        "969.9124145507812\n",
                        "720.511474609375\n",
                        "654.2828369140625\n",
                        "Average loss :  887.3232421875\n",
                        "\n",
                        "\n",
                        "Epoch 363/5000\n",
                        "Learning rate :  0.001\n",
                        "1180.392822265625\n",
                        "953.6790771484375\n",
                        "836.0460205078125\n",
                        "966.13818359375\n",
                        "717.7662353515625\n",
                        "652.0045166015625\n",
                        "Average loss :  884.3378295898438\n",
                        "\n",
                        "\n",
                        "Epoch 364/5000\n",
                        "Learning rate :  0.001\n",
                        "1177.1610107421875\n",
                        "950.6506958007812\n",
                        "833.2450561523438\n",
                        "962.389404296875\n",
                        "715.0400390625\n",
                        "649.7406616210938\n",
                        "Average loss :  881.37109375\n",
                        "\n",
                        "\n",
                        "Epoch 365/5000\n",
                        "Learning rate :  0.001\n",
                        "1173.947021484375\n",
                        "947.6400756835938\n",
                        "830.4613647460938\n",
                        "958.66552734375\n",
                        "712.3323974609375\n",
                        "647.4911499023438\n",
                        "Average loss :  878.4229125976562\n",
                        "\n",
                        "\n",
                        "Epoch 366/5000\n",
                        "Learning rate :  0.001\n",
                        "1170.7503662109375\n",
                        "944.646728515625\n",
                        "827.695068359375\n",
                        "954.9666748046875\n",
                        "709.643310546875\n",
                        "645.2557983398438\n",
                        "Average loss :  875.4929809570312\n",
                        "\n",
                        "\n",
                        "Epoch 367/5000\n",
                        "Learning rate :  0.001\n",
                        "1167.571533203125\n",
                        "941.6707763671875\n",
                        "824.946044921875\n",
                        "951.2927856445312\n",
                        "706.9727783203125\n",
                        "643.0347290039062\n",
                        "Average loss :  872.58154296875\n",
                        "\n",
                        "\n",
                        "Epoch 368/5000\n",
                        "Learning rate :  0.001\n",
                        "1164.41015625\n",
                        "938.7120971679688\n",
                        "822.21435546875\n",
                        "947.6433715820312\n",
                        "704.3204956054688\n",
                        "640.8277587890625\n",
                        "Average loss :  869.6881713867188\n",
                        "\n",
                        "\n",
                        "Epoch 369/5000\n",
                        "Learning rate :  0.001\n",
                        "1161.2662353515625\n",
                        "935.7706298828125\n",
                        "819.4993286132812\n",
                        "944.0181884765625\n",
                        "701.6864013671875\n",
                        "638.634765625\n",
                        "Average loss :  866.8125610351562\n",
                        "\n",
                        "\n",
                        "Epoch 370/5000\n",
                        "Learning rate :  0.001\n",
                        "1158.139404296875\n",
                        "932.8462524414062\n",
                        "816.8013916015625\n",
                        "940.4175415039062\n",
                        "699.0702514648438\n",
                        "636.45556640625\n",
                        "Average loss :  863.955078125\n",
                        "\n",
                        "\n",
                        "Epoch 371/5000\n",
                        "Learning rate :  0.001\n",
                        "1155.02978515625\n",
                        "929.9385375976562\n",
                        "814.1201171875\n",
                        "936.840576171875\n",
                        "696.4720458984375\n",
                        "634.2902221679688\n",
                        "Average loss :  861.115234375\n",
                        "\n",
                        "\n",
                        "Epoch 372/5000\n",
                        "Learning rate :  0.001\n",
                        "1151.937255859375\n",
                        "927.0477905273438\n",
                        "811.4554443359375\n",
                        "933.2876586914062\n",
                        "693.8916015625\n",
                        "632.1385498046875\n",
                        "Average loss :  858.2930297851562\n",
                        "\n",
                        "\n",
                        "Epoch 373/5000\n",
                        "Learning rate :  0.001\n",
                        "1148.861572265625\n",
                        "924.173583984375\n",
                        "808.807373046875\n",
                        "929.7584228515625\n",
                        "691.3287353515625\n",
                        "630.0003662109375\n",
                        "Average loss :  855.4883422851562\n",
                        "\n",
                        "\n",
                        "Epoch 374/5000\n",
                        "Learning rate :  0.001\n",
                        "1145.802490234375\n",
                        "921.3159790039062\n",
                        "806.1755981445312\n",
                        "926.2526245117188\n",
                        "688.7833251953125\n",
                        "627.8756103515625\n",
                        "Average loss :  852.700927734375\n",
                        "\n",
                        "\n",
                        "Epoch 375/5000\n",
                        "Learning rate :  0.001\n",
                        "1142.7603759765625\n",
                        "918.474853515625\n",
                        "803.5601806640625\n",
                        "922.7702026367188\n",
                        "686.2552490234375\n",
                        "625.7642822265625\n",
                        "Average loss :  849.9308471679688\n",
                        "\n",
                        "\n",
                        "Epoch 376/5000\n",
                        "Learning rate :  0.001\n",
                        "1139.734619140625\n",
                        "915.6499633789062\n",
                        "800.9607543945312\n",
                        "919.3107299804688\n",
                        "683.7443237304688\n",
                        "623.666259765625\n",
                        "Average loss :  847.177734375\n",
                        "\n",
                        "\n",
                        "Epoch 377/5000\n",
                        "Learning rate :  0.001\n",
                        "1136.7255859375\n",
                        "912.8413696289062\n",
                        "798.37744140625\n",
                        "915.8743896484375\n",
                        "681.2506713867188\n",
                        "621.581298828125\n",
                        "Average loss :  844.4418334960938\n",
                        "\n",
                        "\n",
                        "Epoch 378/5000\n",
                        "Learning rate :  0.001\n",
                        "1133.7327880859375\n",
                        "910.048828125\n",
                        "795.8101196289062\n",
                        "912.4607543945312\n",
                        "678.7737426757812\n",
                        "619.5093994140625\n",
                        "Average loss :  841.72265625\n",
                        "\n",
                        "\n",
                        "Epoch 379/5000\n",
                        "Learning rate :  0.001\n",
                        "1130.7559814453125\n",
                        "907.272216796875\n",
                        "793.2584228515625\n",
                        "909.0697021484375\n",
                        "676.3135986328125\n",
                        "617.4505615234375\n",
                        "Average loss :  839.0200805664062\n",
                        "\n",
                        "\n",
                        "Epoch 380/5000\n",
                        "Learning rate :  0.001\n",
                        "1127.79541015625\n",
                        "904.511474609375\n",
                        "790.7222900390625\n",
                        "905.7008666992188\n",
                        "673.870361328125\n",
                        "615.4046020507812\n",
                        "Average loss :  836.3341674804688\n",
                        "\n",
                        "\n",
                        "Epoch 381/5000\n",
                        "Learning rate :  0.001\n",
                        "1124.85107421875\n",
                        "901.7665405273438\n",
                        "788.2020263671875\n",
                        "902.3544921875\n",
                        "671.4434204101562\n",
                        "613.37158203125\n",
                        "Average loss :  833.6648559570312\n",
                        "\n",
                        "\n",
                        "Epoch 382/5000\n",
                        "Learning rate :  0.001\n",
                        "1121.9224853515625\n",
                        "899.0371704101562\n",
                        "785.6969604492188\n",
                        "899.0301513671875\n",
                        "669.032958984375\n",
                        "611.35107421875\n",
                        "Average loss :  831.0117797851562\n",
                        "\n",
                        "\n",
                        "Epoch 383/5000\n",
                        "Learning rate :  0.001\n",
                        "1119.009765625\n",
                        "896.3236083984375\n",
                        "783.207275390625\n",
                        "895.727783203125\n",
                        "666.638916015625\n",
                        "609.3432006835938\n",
                        "Average loss :  828.3750610351562\n",
                        "\n",
                        "\n",
                        "Epoch 384/5000\n",
                        "Learning rate :  0.001\n",
                        "1116.11279296875\n",
                        "893.6253662109375\n",
                        "780.73291015625\n",
                        "892.4471435546875\n",
                        "664.260986328125\n",
                        "607.347900390625\n",
                        "Average loss :  825.7545776367188\n",
                        "\n",
                        "\n",
                        "Epoch 385/5000\n",
                        "Learning rate :  0.001\n",
                        "1113.2313232421875\n",
                        "890.9423828125\n",
                        "778.2736206054688\n",
                        "889.18798828125\n",
                        "661.8988647460938\n",
                        "605.364990234375\n",
                        "Average loss :  823.14990234375\n",
                        "\n",
                        "\n",
                        "Epoch 386/5000\n",
                        "Learning rate :  0.001\n",
                        "1110.365478515625\n",
                        "888.2747802734375\n",
                        "775.8292846679688\n",
                        "885.9503173828125\n",
                        "659.5526733398438\n",
                        "603.3944091796875\n",
                        "Average loss :  820.5612182617188\n",
                        "\n",
                        "\n",
                        "Epoch 387/5000\n",
                        "Learning rate :  0.001\n",
                        "1107.5147705078125\n",
                        "885.6223754882812\n",
                        "773.3999633789062\n",
                        "882.7340087890625\n",
                        "657.2220458984375\n",
                        "601.43603515625\n",
                        "Average loss :  817.9882202148438\n",
                        "\n",
                        "\n",
                        "Epoch 388/5000\n",
                        "Learning rate :  0.001\n",
                        "1104.67919921875\n",
                        "882.9852294921875\n",
                        "770.9854125976562\n",
                        "879.5386962890625\n",
                        "654.906982421875\n",
                        "599.48974609375\n",
                        "Average loss :  815.4308471679688\n",
                        "\n",
                        "\n",
                        "Epoch 389/5000\n",
                        "Learning rate :  0.001\n",
                        "1101.8587646484375\n",
                        "880.3629150390625\n",
                        "768.5855102539062\n",
                        "876.3643798828125\n",
                        "652.6075439453125\n",
                        "597.5557861328125\n",
                        "Average loss :  812.8890991210938\n",
                        "\n",
                        "\n",
                        "Epoch 390/5000\n",
                        "Learning rate :  0.001\n",
                        "1099.0537109375\n",
                        "877.7555541992188\n",
                        "766.2002563476562\n",
                        "873.2110595703125\n",
                        "650.323486328125\n",
                        "595.6337890625\n",
                        "Average loss :  810.3629760742188\n",
                        "\n",
                        "\n",
                        "Epoch 391/5000\n",
                        "Learning rate :  0.001\n",
                        "1096.2635498046875\n",
                        "875.1630249023438\n",
                        "763.8294677734375\n",
                        "870.0784301757812\n",
                        "648.0546264648438\n",
                        "593.7235717773438\n",
                        "Average loss :  807.8521118164062\n",
                        "\n",
                        "\n",
                        "Epoch 392/5000\n",
                        "Learning rate :  0.001\n",
                        "1093.488037109375\n",
                        "872.5853271484375\n",
                        "761.47314453125\n",
                        "866.9661254882812\n",
                        "645.8010864257812\n",
                        "591.8253784179688\n",
                        "Average loss :  805.3565063476562\n",
                        "\n",
                        "\n",
                        "Epoch 393/5000\n",
                        "Learning rate :  0.001\n",
                        "1090.727783203125\n",
                        "870.0220336914062\n",
                        "759.1309204101562\n",
                        "863.8740234375\n",
                        "643.5623779296875\n",
                        "589.9385986328125\n",
                        "Average loss :  802.8759765625\n",
                        "\n",
                        "\n",
                        "Epoch 394/5000\n",
                        "Learning rate :  0.001\n",
                        "1087.981689453125\n",
                        "867.4730224609375\n",
                        "756.802978515625\n",
                        "860.80224609375\n",
                        "641.3389282226562\n",
                        "588.0637817382812\n",
                        "Average loss :  800.4104614257812\n",
                        "\n",
                        "\n",
                        "Epoch 395/5000\n",
                        "Learning rate :  0.001\n",
                        "1085.25048828125\n",
                        "864.9384765625\n",
                        "754.489013671875\n",
                        "857.75048828125\n",
                        "639.130126953125\n",
                        "586.2003173828125\n",
                        "Average loss :  797.9597778320312\n",
                        "\n",
                        "\n",
                        "Epoch 396/5000\n",
                        "Learning rate :  0.001\n",
                        "1082.5338134765625\n",
                        "862.4180908203125\n",
                        "752.1888427734375\n",
                        "854.71826171875\n",
                        "636.9359741210938\n",
                        "584.3483276367188\n",
                        "Average loss :  795.52392578125\n",
                        "\n",
                        "\n",
                        "Epoch 397/5000\n",
                        "Learning rate :  0.001\n",
                        "1079.8314208984375\n",
                        "859.911865234375\n",
                        "749.9026489257812\n",
                        "851.7059326171875\n",
                        "634.7564697265625\n",
                        "582.5078125\n",
                        "Average loss :  793.1027221679688\n",
                        "\n",
                        "\n",
                        "Epoch 398/5000\n",
                        "Learning rate :  0.001\n",
                        "1077.1431884765625\n",
                        "857.4194946289062\n",
                        "747.6300048828125\n",
                        "848.712890625\n",
                        "632.5916137695312\n",
                        "580.6785888671875\n",
                        "Average loss :  790.6959838867188\n",
                        "\n",
                        "\n",
                        "Epoch 399/5000\n",
                        "Learning rate :  0.001\n",
                        "1074.469482421875\n",
                        "854.9413452148438\n",
                        "745.3712158203125\n",
                        "845.7396240234375\n",
                        "630.441162109375\n",
                        "578.8607788085938\n",
                        "Average loss :  788.303955078125\n",
                        "\n",
                        "\n",
                        "Epoch 400/5000\n",
                        "Learning rate :  0.001\n",
                        "1071.81005859375\n",
                        "852.4769287109375\n",
                        "743.1259765625\n",
                        "842.78564453125\n",
                        "628.3049926757812\n",
                        "577.0540161132812\n",
                        "Average loss :  785.92626953125\n",
                        "\n",
                        "\n",
                        "Epoch 401/5000\n",
                        "Learning rate :  0.001\n",
                        "1069.16455078125\n",
                        "850.0264892578125\n",
                        "740.8941650390625\n",
                        "839.8505859375\n",
                        "626.1829833984375\n",
                        "575.25830078125\n",
                        "Average loss :  783.5628051757812\n",
                        "\n",
                        "\n",
                        "Epoch 402/5000\n",
                        "Learning rate :  0.001\n",
                        "1066.5330810546875\n",
                        "847.589599609375\n",
                        "738.6757202148438\n",
                        "836.9345703125\n",
                        "624.0750732421875\n",
                        "573.4736328125\n",
                        "Average loss :  781.213623046875\n",
                        "\n",
                        "\n",
                        "Epoch 403/5000\n",
                        "Learning rate :  0.001\n",
                        "1063.91552734375\n",
                        "845.1663818359375\n",
                        "736.4705200195312\n",
                        "834.037353515625\n",
                        "621.9810791015625\n",
                        "571.699951171875\n",
                        "Average loss :  778.8784790039062\n",
                        "\n",
                        "\n",
                        "Epoch 404/5000\n",
                        "Learning rate :  0.001\n",
                        "1061.3115234375\n",
                        "842.7564697265625\n",
                        "734.2784423828125\n",
                        "831.1587524414062\n",
                        "619.9010009765625\n",
                        "569.93701171875\n",
                        "Average loss :  776.55712890625\n",
                        "\n",
                        "\n",
                        "Epoch 405/5000\n",
                        "Learning rate :  0.001\n",
                        "1058.72119140625\n",
                        "840.3599243164062\n",
                        "732.0993041992188\n",
                        "828.2986450195312\n",
                        "617.83447265625\n",
                        "568.1847534179688\n",
                        "Average loss :  774.249755859375\n",
                        "\n",
                        "\n",
                        "Epoch 406/5000\n",
                        "Learning rate :  0.001\n",
                        "1056.14453125\n",
                        "837.9766845703125\n",
                        "729.9332275390625\n",
                        "825.4569702148438\n",
                        "615.78173828125\n",
                        "566.443359375\n",
                        "Average loss :  771.9560546875\n",
                        "\n",
                        "\n",
                        "Epoch 407/5000\n",
                        "Learning rate :  0.001\n",
                        "1053.5814208984375\n",
                        "835.6068115234375\n",
                        "727.780029296875\n",
                        "822.6336669921875\n",
                        "613.7426147460938\n",
                        "564.7125244140625\n",
                        "Average loss :  769.6762084960938\n",
                        "\n",
                        "\n",
                        "Epoch 408/5000\n",
                        "Learning rate :  0.001\n",
                        "1051.03173828125\n",
                        "833.2500610351562\n",
                        "725.6396484375\n",
                        "819.828369140625\n",
                        "611.716796875\n",
                        "562.9920654296875\n",
                        "Average loss :  767.4098510742188\n",
                        "\n",
                        "\n",
                        "Epoch 409/5000\n",
                        "Learning rate :  0.001\n",
                        "1048.4952392578125\n",
                        "830.906005859375\n",
                        "723.51171875\n",
                        "817.041015625\n",
                        "609.7042846679688\n",
                        "561.2822265625\n",
                        "Average loss :  765.15673828125\n",
                        "\n",
                        "\n",
                        "Epoch 410/5000\n",
                        "Learning rate :  0.001\n",
                        "1045.97216796875\n",
                        "828.5751953125\n",
                        "721.3965454101562\n",
                        "814.271484375\n",
                        "607.705078125\n",
                        "559.582763671875\n",
                        "Average loss :  762.9171752929688\n",
                        "\n",
                        "\n",
                        "Epoch 411/5000\n",
                        "Learning rate :  0.001\n",
                        "1043.4622802734375\n",
                        "826.2572631835938\n",
                        "719.2939453125\n",
                        "811.52001953125\n",
                        "605.7190551757812\n",
                        "557.8936767578125\n",
                        "Average loss :  760.6911010742188\n",
                        "\n",
                        "\n",
                        "Epoch 412/5000\n",
                        "Learning rate :  0.001\n",
                        "1040.9654541015625\n",
                        "823.9521484375\n",
                        "717.2037963867188\n",
                        "808.785888671875\n",
                        "603.74609375\n",
                        "556.21484375\n",
                        "Average loss :  758.47802734375\n",
                        "\n",
                        "\n",
                        "Epoch 413/5000\n",
                        "Learning rate :  0.001\n",
                        "1038.481689453125\n",
                        "821.6598510742188\n",
                        "715.1259765625\n",
                        "806.0693359375\n",
                        "601.7861328125\n",
                        "554.5462646484375\n",
                        "Average loss :  756.2781372070312\n",
                        "\n",
                        "\n",
                        "Epoch 414/5000\n",
                        "Learning rate :  0.001\n",
                        "1036.010986328125\n",
                        "819.3800048828125\n",
                        "713.0604858398438\n",
                        "803.3701171875\n",
                        "599.8389282226562\n",
                        "552.8876953125\n",
                        "Average loss :  754.0913696289062\n",
                        "\n",
                        "\n",
                        "Epoch 415/5000\n",
                        "Learning rate :  0.001\n",
                        "1033.5528564453125\n",
                        "817.11279296875\n",
                        "711.007080078125\n",
                        "800.6880493164062\n",
                        "597.9043579101562\n",
                        "551.2391357421875\n",
                        "Average loss :  751.9174194335938\n",
                        "\n",
                        "\n",
                        "Epoch 416/5000\n",
                        "Learning rate :  0.001\n",
                        "1031.1075439453125\n",
                        "814.8577880859375\n",
                        "708.9655151367188\n",
                        "798.0228881835938\n",
                        "595.9824829101562\n",
                        "549.600341796875\n",
                        "Average loss :  749.756103515625\n",
                        "\n",
                        "\n",
                        "Epoch 417/5000\n",
                        "Learning rate :  0.001\n",
                        "1028.6748046875\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-16-3fbd2d577e11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learning rate : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mxi_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevxi_L\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlossitem\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi_L\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprevxi_L\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mUpsilonR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mUpsilonL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXdot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m<ipython-input-14-d17e8ec1bc13>\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(c, coef, prevcoef, UpsilonR, UpsilonL, xdot, bs, lr, lam, momentum)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtarg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'jkl,k->jl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupsilonR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mlossval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlossval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m<ipython-input-12-6738fbe28c46>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(pred, targ)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "Epoch = 5000\n",
                "i = 0\n",
                "lr = 1e-3\n",
                "lam = 0.1\n",
                "temp = 1000\n",
                "while(i<=Epoch):\n",
                "    print(\"\\n\")\n",
                "    print(\"Epoch \"+str(i) + \"/\" + str(Epoch))\n",
                "    print(\"Learning rate : \", lr)\n",
                "    xi_L, prevxi_L, lossitem= training_loop(c, xi_L,prevxi_L,UpsilonR,UpsilonL,Xdot,128,lr=lr,lam=lam)\n",
                "    temp = lossitem\n",
                "    i+=1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Rescale\n",
                "for i in range(UpsilonL.shape[1]):\n",
                "    xi_L[i] = xi_L[i]/scale[i]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Thresholding\n",
                "threshold = 1e-2\n",
                "surv_index = ((torch.abs(xi_L) >= threshold)).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
                "expr = np.array(expr)[surv_index].tolist()\n",
                "\n",
                "xi_L =xi_L[surv_index].clone().detach().requires_grad_(True)\n",
                "prevxi_L = xi_L.clone().detach()\n",
                "\n",
                "## obtaining analytical model\n",
                "xi_Lcpu = np.around(xi_L.detach().cpu().numpy(),decimals=2)\n",
                "L = HL.generateExpression(xi_Lcpu,expr,threshold=1e-3)\n",
                "print(\"Result stage 1: \", simplify(L))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Next round selection ##\n",
                "\n",
                "    #Redefine computation after thresholding\n",
                "expr.append(known_expr[0])\n",
                "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)\n",
                "\n",
                "expr = np.array(expr)\n",
                "i1 = np.where(expr == 'x0_t**2')[0]\n",
                "i4 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i5 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i6 = np.where(expr == 'cos(x1)')[0][0]\n",
                "idx = np.arange(0,len(expr))\n",
                "idx = np.delete(idx,i1)\n",
                "known_expr = expr[i1].tolist()\n",
                "expr = np.delete(expr,i1).tolist()\n",
                "nonpenaltyidx = [i4,i5,i6]\n",
                "\n",
                "Zeta_ = Zeta[:,:,i1,:].clone().detach()\n",
                "Eta_ = Eta[:,:,i1,:].clone().detach()\n",
                "Delta_ = Delta[:,i1,:].clone().detach()\n",
                "\n",
                "Zeta = Zeta[:,:,idx,:]\n",
                "Eta = Eta[:,:,idx,:]\n",
                "Delta = Delta[:,idx,:]\n",
                "\n",
                "Zeta = Zeta.to(device)\n",
                "Eta = Eta.to(device)\n",
                "Delta = Delta.to(device)\n",
                "Zeta_ = Zeta_.to(device)\n",
                "Eta_ = Eta_.to(device)\n",
                "Delta_ = Delta_.to(device)\n",
                "\n",
                "Epoch = 20000\n",
                "i = 0\n",
                "lr = 3e-5\n",
                "lam = 5\n",
                "temp = 1000\n",
                "RHS = [Zeta, Eta, Delta]\n",
                "LHS = [Zeta_, Eta_, Delta_]\n",
                "while(i<=Epoch):\n",
                "    print(\"\\n\")\n",
                "    print(\"Epoch \"+str(i) + \"/\" + str(Epoch))\n",
                "    print(\"Learning rate : \", lr)\n",
                "    xi_L, prevxi_L, lossitem= training_loop(c, xi_L,prevxi_L,RHS,LHS,Xdot,128,lr=lr,lam=lam)\n",
                "    i+=1\n",
                "    if(temp <= 1e-3):\n",
                "        break\n",
                "    \n",
                "## Thresholding\n",
                "threshold = 1e-1\n",
                "surv_index = ((torch.abs(xi_L) >= threshold)).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
                "expr = np.array(expr)[surv_index].tolist()\n",
                "\n",
                "xi_L =xi_L[surv_index].clone().detach().requires_grad_(True)\n",
                "prevxi_L = xi_L.clone().detach()\n",
                "\n",
                "## obtaining analytical model\n",
                "xi_Lcpu = np.around(xi_L.detach().cpu().numpy(),decimals=3)\n",
                "L = HL.generateExpression(xi_Lcpu,expr,threshold=1e-1)\n",
                "print(\"Result stage  \" , simplify(L))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Adding known terms\n",
                "L = str(simplify(L)) + \" + \" + known_expr[0]\n",
                "print(L)\n",
                "\n",
                "expr = expr + known_expr\n",
                "xi_L = torch.cat((xi_L, c))\n",
                "mask = torch.ones(len(xi_L),device=device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if(save==True):\n",
                "    #Saving Equation in string\n",
                "    text_file = open(rootdir + \"lagrangian_\" + str(noiselevel)+ \"_noise.txt\", \"w\")\n",
                "    text_file.write(L)\n",
                "    text_file.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Investigation\n",
                "\n",
                "pred2, UpsilonL = ELforward2(xi_L, Zeta, Eta, Delta, Xdot, device)\n",
                "targ2, UpsilonR = ELforward2(c, Zeta_, Eta_, Delta_, Xdot, device)\n",
                "\n",
                "\n",
                "t = np.arange(UpsilonL.shape[2])\n",
                "for i in range(UpsilonL.shape[1]):\n",
                "    plt.plot(t,UpsilonL[0,i,:].detach().cpu().numpy())\n",
                "    plt.plot(t,UpsilonL[1,i,:].detach().cpu().numpy())\n",
                "    print(expr[i])\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Debugging for only known terms\n",
                "\n",
                "expr = np.array(expr)\n",
                "i0 = np.where(expr == 'x0_t**2')[0][0]\n",
                "i1 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i2 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i3 = np.where(expr == 'cos(x1)')[0][0]\n",
                "i4 = np.where(expr == 'x0_t*x1_t*cos(x0)*cos(x1)')[0][0]\n",
                "i5 = np.where(expr == 'x0_t*x1_t*sin(x0)*sin(x1)')[0][0]\n",
                "\n",
                "expr = [expr[i0],expr[i1],expr[i2],expr[i3],expr[i4],expr[i5]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "d5784be8b0ed123205c521437a438df309f2d2f16cb6cf8124a1b3e0f87bfce1"
        },
        "kernelspec": {
            "display_name": "Python 3.8.10 64-bit ('SystemIdentification': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
