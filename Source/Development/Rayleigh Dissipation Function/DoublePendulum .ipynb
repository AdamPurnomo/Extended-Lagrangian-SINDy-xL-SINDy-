{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import sys \n",
                "sys.path.append(r'../../Python Script/')\n",
                "\n",
                "from sympy import symbols, simplify, derive_by_array\n",
                "from scipy.integrate import solve_ivp\n",
                "from xLSINDy import *\n",
                "from sympy.physics.mechanics import *\n",
                "from sympy import *\n",
                "import sympy\n",
                "import torch\n",
                "import HLsearch as HL\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System parameters\n",
                "L1, L2 = 1, 1\n",
                "m1, m2 = 1, 1\n",
                "k1, k2 = 0.5, 0.5\n",
                "g = 9.8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "states are: (x0, x1, x0_t, x1_t)\n",
                        "states derivatives are:  (x0_t, x1_t, x0_tt, x1_tt)\n"
                    ]
                }
            ],
            "source": [
                "states_dim = 4\n",
                "states = ()\n",
                "states_dot = ()\n",
                "for i in range(states_dim):\n",
                "    if(i<states_dim//2):\n",
                "        states = states + (symbols('x{}'.format(i)),)\n",
                "        states_dot = states_dot + (symbols('x{}_t'.format(i)),)\n",
                "    else:\n",
                "        states = states + (symbols('x{}_t'.format(i-states_dim//2)),)\n",
                "        states_dot = states_dot + (symbols('x{}_tt'.format(i-states_dim//2)),)\n",
                "print('states are:',states)\n",
                "print('states derivatives are: ', states_dot)\n",
                "\n",
                "#Turn from sympy to str\n",
                "states_sym = states\n",
                "states_dot_sym = states_dot\n",
                "states = list(str(descr) for descr in states)\n",
                "states_dot = list(str(descr) for descr in states_dot)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#For friction force\n",
                "x0 = Symbol(states[0], real=True)\n",
                "x1 = Symbol(states[1], real=True)\n",
                "x0_t = Symbol(states[2],real=True)\n",
                "x1_t = Symbol(states[3],real=True)\n",
                "q = sympy.Array([x0, x1])\n",
                "qdot = sympy.Array([x0_t, x1_t])\n",
                "\n",
                "#True Rayleigh Dissipation function\n",
                "dummy = Symbol('a', real = True)\n",
                "R = dummy #0.5*k1*x0_t**2 + 0.5*k2*(x1_t - x0_t)**2 #+ k1*Abs(x0_t) + k2*Abs(x1_t - x0_t)\n",
                "\n",
                "#friction force\n",
                "f_forcing = sympy.Matrix(derive_by_array(R, qdot)) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "#for lagrangian\n",
                "x0 = dynamicsymbols(states[0], real=True)\n",
                "x1 = dynamicsymbols(states[1], real=True)\n",
                "x0_t = dynamicsymbols(states[0],1, real=True)\n",
                "x1_t = dynamicsymbols(states[1],1, real=True)\n",
                "tau0 = symbols('tau0')\n",
                "tau1 = symbols('tau1')\n",
                "\n",
                "#True Lagrangian\n",
                "L = 0.5*(m1+m2)*L1**2*x0_t**2 + 0.5*m2*L2**2*x1_t**2 + m2*L2**2*x0_t*x1_t*cos(x0)*cos(x1) + m2*L2**2*x0_t*x1_t*sin(x0)*sin(x1) + (m1+m2)*g*L1*cos(x0) + m2*g*L2*cos(x1)\n",
                "\n",
                "# Lagrange's method\n",
                "LM = LagrangesMethod(L, [x0,x1])\n",
                "LM.form_lagranges_equations()\n",
                "i_forcing = LM.forcing #internal forcing and gravity\n",
                "e_forcing = sympy.Matrix([tau0-tau1, tau1]) #external generalized force"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Substituting dynamic symbols\n",
                "\n",
                "i_forcing = i_forcing.subs(x0_t, states_sym[2])\n",
                "i_forcing = i_forcing.subs(x1_t, states_sym[3])\n",
                "i_forcing = i_forcing.subs(x0, states_sym[0])\n",
                "i_forcing = i_forcing.subs(x1, states_sym[1])\n",
                "\n",
                "M = LM.mass_matrix\n",
                "M = M.subs(x0, states_sym[0])\n",
                "M = M.subs(x1, states_sym[1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generating equation of motion\n",
                "t_forcing = i_forcing + e_forcing - f_forcing\n",
                "eom = M.inv()*sympy.Matrix(t_forcing)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Equation 0: (2.0*sin(x0)*sin(x1) + 2.0*cos(x0)*cos(x1))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) - 9.8*sin(x1))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) - 2.0*(tau0 - tau1 - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0)\n",
                        "\n",
                        "\n",
                        "Equation 1: (1.0*sin(x0)*sin(x1) + 1.0*cos(x0)*cos(x1))*(tau0 - tau1 - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) - 2.0*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) - 9.8*sin(x1))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0)\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "''' Please copy the string shown to the definition of equation in the function of double pendulum'''\n",
                "for i in range(len(eom)):\n",
                "    print('Equation ' + str(i) +': ' + str(eom[i]))\n",
                "    print('\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "def torque(t,omega):\n",
                "    return 1*np.cos(omega*t), 1*np.sin(omega*t)\n",
                "\n",
                "def doublePendulum(t,y,omega):\n",
                "    from numpy import sin, cos, sign\n",
                "    x0,x1,x0_t,x1_t = y\n",
                "    tau0, tau1 = torque(t, omega)\n",
                "    x0_tt = (2.0*sin(x0)*sin(x1) + 2.0*cos(x0)*cos(x1))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) - 9.8*sin(x1))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) - 2.0*(tau0 - tau1 - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0)\n",
                "    x1_tt =  (1.0*sin(x0)*sin(x1) + 1.0*cos(x0)*cos(x1))*(tau0 - tau1 - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) - 2.0*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) - 9.8*sin(x1))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0)\n",
                "    return x0_t,x1_t,x0_tt,x1_tt\n",
                "\n",
                "\n",
                "def generate_data(func, time, init_values, omega):\n",
                "    sol = solve_ivp(func,[time[0],time[-1]],init_values,t_eval=time, method='LSODA', rtol=1e-10,atol=1e-10, args=[omega])\n",
                "    return sol.y.T, np.array([func(time[i],sol.y.T[i,:], omega = omega) for i in range(sol.y.T.shape[0])],dtype=np.float64)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Saving Directory\n",
                "rootdir = \"../../Double Pendulum/Data/Active/\"\n",
                "\n",
                "num_sample = 100\n",
                "create_data = False\n",
                "training = True\n",
                "save = False\n",
                "noiselevel = 6e-2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Create training data\n",
                "if(create_data):\n",
                "    print(\"Creating Data . . .\")\n",
                "    num_sample = 100\n",
                "    X, Xdot = [], []\n",
                "    Tau = []\n",
                "    Omega = []\n",
                "    for i in range(num_sample):\n",
                "        t = np.arange(0,5,0.01)\n",
                "        theta1 = np.random.uniform(-np.pi, np.pi)\n",
                "        theta2 = np.random.uniform(-np.pi, np.pi)\n",
                "        thetadot = np.random.uniform(0,0)\n",
                "        omega = np.random.uniform(np.pi/2, np.pi)\n",
                "        \n",
                "        tau0, tau1 = torque(t, omega)\n",
                "        tau = np.array([tau0 - tau1, tau1]).T    \n",
                "        y0=np.array([theta1, theta2, thetadot, thetadot])\n",
                "        x,xdot = generate_data(doublePendulum,t,y0,omega=omega)\n",
                "        \n",
                "        Omega.append(omega)\n",
                "        Tau.append(tau)\n",
                "        X.append(x)\n",
                "        Xdot.append(xdot)\n",
                "\n",
                "    X = np.vstack(X)\n",
                "    Xdot = np.vstack(Xdot)\n",
                "    Tau = np.vstack(Tau)\n",
                "    if(save==True):\n",
                "        np.save(rootdir + \"X.npy\", X)\n",
                "        np.save(rootdir + \"Xdot.npy\",Xdot)\n",
                "        np.save(rootdir + \"Tau.npy\", Tau)\n",
                "else:\n",
                "    X = np.load(rootdir + \"X.npy\")\n",
                "    Xdot = np.load(rootdir + \"Xdot.npy\")\n",
                "    Tau = np.load(rootdir + \"Tau.npy\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "#adding noise\n",
                "mu, sigma = 0, noiselevel\n",
                "noise = np.random.normal(mu, sigma, X.shape[0])\n",
                "for i in range(X.shape[1]):\n",
                "    X[:,i] = X[:,i]+noise\n",
                "    Xdot[:,i] = Xdot[:,i]+noise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "states are: (x0, x1, x0_t, x1_t)\n",
                        "states derivatives are:  (x0_t, x1_t, x0_tt, x1_tt)\n"
                    ]
                }
            ],
            "source": [
                "states_dim = 4\n",
                "states = ()\n",
                "states_dot = ()\n",
                "for i in range(states_dim):\n",
                "    if(i<states_dim//2):\n",
                "        states = states + (symbols('x{}'.format(i)),)\n",
                "        states_dot = states_dot + (symbols('x{}_t'.format(i)),)\n",
                "    else:\n",
                "        states = states + (symbols('x{}_t'.format(i-states_dim//2)),)\n",
                "        states_dot = states_dot + (symbols('x{}_tt'.format(i-states_dim//2)),)\n",
                "print('states are:',states)\n",
                "print('states derivatives are: ', states_dot)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Turn from sympy to str\n",
                "states_sym = states\n",
                "states_dot_sym = states_dot\n",
                "states = list(str(descr) for descr in states)\n",
                "states_dot = list(str(descr) for descr in states_dot)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "#build function expression for the library in str\n",
                "exprdummy = HL.buildFunctionExpressions(1,states_dim,states,use_sine=True)\n",
                "polynom = exprdummy[2:4]\n",
                "trig = exprdummy[4:]\n",
                "polynom = HL.buildFunctionExpressions(2,len(polynom),polynom)\n",
                "trig = HL.buildFunctionExpressions(2, len(trig),trig)\n",
                "product = []\n",
                "for p in polynom:\n",
                "    for t in trig:\n",
                "        product.append(p + '*' + t)\n",
                "expr = polynom + trig + product"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Boundaries for debugging with only the correct terms ###"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creating library tensor\n",
                "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Case I, input torque provided##\n",
                "expr = np.array(expr)\n",
                "\n",
                "\n",
                "## Garbage terms ##\n",
                "\n",
                "'''\n",
                "Explanation :\n",
                "x0_t, x1_t terms are not needed and will always satisfy EL's equation.\n",
                "Since x0_t, x1_t are garbages, we want to avoid (x0_t*sin()**2 + x0_t*cos()**2), thus we remove\n",
                "one of them, either  x0_t*sin()**2 or x0_t*cos()**2. \n",
                "Since the known term is x0_t**2, we also want to avoid the solution of (x0_t**2*sin()**2 + x0_t**2*cos()**2),\n",
                "so we remove either one of x0_t**2*sin()**2 or x0_t**2*cos()**2.\n",
                "'''\n",
                "\n",
                "i7 = np.where(expr == 'x1_t*cos(x0)**2')[0]\n",
                "i8 = np.where(expr == 'x1_t*cos(x1)**2')[0]\n",
                "i9 = np.where(expr == 'x1_t')[0]\n",
                "i10 = np.where(expr == 'x0_t*cos(x0)**2')[0]\n",
                "i11 = np.where(expr == 'x0_t*cos(x1)**2')[0]\n",
                "i12 = np.where(expr == 'x0_t')[0]\n",
                "i13 = np.where(expr == 'cos(x0)**2')[0]\n",
                "i14 = np.where(expr == 'cos(x1)**2')[0]\n",
                "\n",
                "#Deleting unused terms \n",
                "idx = np.arange(0,len(expr))\n",
                "idx = np.delete(idx,[i7,i8,i9,i10,i11,i12,i13,i14])\n",
                "expr = np.delete(expr,[i7,i8,i9,i10,i11,i12,i13,i14])\n",
                "\n",
                "#non-penalty index from prev knowledge\n",
                "i1 = np.where(expr == 'x0_t**2')[0][0]\n",
                "i4 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i5 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i6 = np.where(expr == 'cos(x1)')[0][0]\n",
                "nonpenaltyidx = [i1, i4, i5, i6]\n",
                "\n",
                "expr = expr.tolist()\n",
                "\n",
                "Zeta = Zeta[:,:,idx,:]\n",
                "Eta = Eta[:,:,idx,:]\n",
                "Delta = Delta[:,idx,:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Moving to Cuda\n",
                "device = 'cuda:0'\n",
                "\n",
                "Zeta = Zeta.to(device)\n",
                "Eta = Eta.to(device)\n",
                "Delta = Delta.to(device)\n",
                "\n",
                "#computing upsilon\n",
                "UpsilonR = Upsilonforward(Zeta, Eta, Delta, Xdot, device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "xi_L = torch.ones(len(expr), device=device).data.uniform_(-10,10)\n",
                "prevxi_L = xi_L.clone().detach()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "def loss(pred, targ):\n",
                "    loss = torch.mean((pred - targ)**2) \n",
                "    return loss "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clip(w, alpha):\n",
                "    clipped = torch.minimum(w,alpha)\n",
                "    clipped = torch.maximum(clipped,-alpha)\n",
                "    return clipped\n",
                "\n",
                "def proxL1norm(w_hat, alpha, nonpenaltyidx):\n",
                "    if(torch.is_tensor(alpha)==False):\n",
                "        alpha = torch.tensor(alpha)\n",
                "    w = w_hat - clip(w_hat,alpha)\n",
                "    for idx in nonpenaltyidx:\n",
                "        w[idx] = w_hat[idx]\n",
                "    return w"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "def training_loop(coef, prevcoef, UpsilonR, Tau, xdot, bs, lr, lam, momentum=True):\n",
                "    loss_list = []\n",
                "    tl = xdot.shape[0]\n",
                "    n = xdot.shape[1]\n",
                "\n",
                "    if(torch.is_tensor(xdot)==False):\n",
                "        xdot = torch.from_numpy(xdot).to(device).float()\n",
                "    if(torch.is_tensor(Tau)==False):\n",
                "        Tau = torch.from_numpy(Tau).to(device).float()\n",
                "\n",
                "    v = coef.clone().detach().requires_grad_(True)\n",
                "    prev = v\n",
                "    \n",
                "    for i in range(tl//bs):\n",
                "                \n",
                "        #computing acceleration with momentum\n",
                "        if(momentum==True):\n",
                "            vhat = (v + ((i-1)/(i+2))*(v - prev)).clone().detach().requires_grad_(True)\n",
                "        else:\n",
                "            vhat = v.requires_grad_(True).clone().detach().requires_grad_(True)\n",
                "   \n",
                "        prev = v\n",
                "\n",
                "        #Computing loss\n",
                "        upsilonR = UpsilonR[:,:,i*bs:(i+1)*bs]\n",
                "        tau = Tau[i*bs:(i+1)*bs]\n",
                "\n",
                "\n",
                "        #forward\n",
                "        pred = torch.einsum('jkl,k->jl', upsilonR, vhat)\n",
                "        targ = tau.T\n",
                "        \n",
                "        lossval = loss(pred, targ)\n",
                "        \n",
                "        #Backpropagation\n",
                "        lossval.backward()\n",
                "\n",
                "        with torch.no_grad():\n",
                "            v = vhat - lr*vhat.grad\n",
                "            v = (proxL1norm(v,lr*lam,nonpenaltyidx))\n",
                "            \n",
                "            # Manually zero the gradients after updating weights\n",
                "            vhat.grad = None\n",
                "        \n",
                "        \n",
                "    \n",
                "        \n",
                "        loss_list.append(lossval.item())\n",
                "    print(\"Average loss : \" , torch.tensor(loss_list).mean().item())\n",
                "    return v, prevcoef, torch.tensor(loss_list).mean().item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.6560953855514526\n",
                        "Epoch 1/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.6579225063323975\n",
                        "Epoch 2/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.6133261919021606\n",
                        "Epoch 3/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.5766985416412354\n",
                        "Epoch 4/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.5436044931411743\n",
                        "Epoch 5/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.5158085823059082\n",
                        "Epoch 6/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.4921083450317383\n",
                        "Epoch 7/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.4684590101242065\n",
                        "Epoch 8/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.4501997232437134\n",
                        "Epoch 9/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.4317104816436768\n",
                        "Epoch 10/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.4161936044692993\n",
                        "Epoch 11/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.403862476348877\n",
                        "Epoch 12/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3904545307159424\n",
                        "Epoch 13/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.379702091217041\n",
                        "Epoch 14/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3687924146652222\n",
                        "Epoch 15/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3618749380111694\n",
                        "Epoch 16/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3519816398620605\n",
                        "Epoch 17/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3455315828323364\n",
                        "Epoch 18/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3393760919570923\n",
                        "Epoch 19/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3331512212753296\n",
                        "Epoch 20/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3281093835830688\n",
                        "Epoch 21/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3205275535583496\n",
                        "Epoch 22/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3168349266052246\n",
                        "Epoch 23/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.31296968460083\n",
                        "Epoch 24/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.308661699295044\n",
                        "Epoch 25/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3040995597839355\n",
                        "Epoch 26/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.3015968799591064\n",
                        "Epoch 27/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2975976467132568\n",
                        "Epoch 28/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2949488162994385\n",
                        "Epoch 29/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2910250425338745\n",
                        "Epoch 30/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2886484861373901\n",
                        "Epoch 31/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.285570502281189\n",
                        "Epoch 32/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2816871404647827\n",
                        "Epoch 33/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2793200016021729\n",
                        "Epoch 34/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2774074077606201\n",
                        "Epoch 35/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2739832401275635\n",
                        "Epoch 36/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2714672088623047\n",
                        "Epoch 37/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.270079493522644\n",
                        "Epoch 38/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2665693759918213\n",
                        "Epoch 39/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2651690244674683\n",
                        "Epoch 40/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2613695859909058\n",
                        "Epoch 41/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.25948965549469\n",
                        "Epoch 42/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2578709125518799\n",
                        "Epoch 43/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2550214529037476\n",
                        "Epoch 44/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.251955509185791\n",
                        "Epoch 45/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2509677410125732\n",
                        "Epoch 46/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2489285469055176\n",
                        "Epoch 47/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2463054656982422\n",
                        "Epoch 48/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2442729473114014\n",
                        "Epoch 49/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2414882183074951\n",
                        "Epoch 50/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.239448070526123\n",
                        "Epoch 51/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2365752458572388\n",
                        "Epoch 52/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2357183694839478\n",
                        "Epoch 53/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2325595617294312\n",
                        "Epoch 54/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.231375813484192\n",
                        "Epoch 55/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2284209728240967\n",
                        "Epoch 56/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2272210121154785\n",
                        "Epoch 57/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2257987260818481\n",
                        "Epoch 58/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2221758365631104\n",
                        "Epoch 59/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2215176820755005\n",
                        "Epoch 60/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2177437543869019\n",
                        "Epoch 61/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2167609930038452\n",
                        "Epoch 62/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2141437530517578\n",
                        "Epoch 63/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2126009464263916\n",
                        "Epoch 64/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2101753950119019\n",
                        "Epoch 65/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2090058326721191\n",
                        "Epoch 66/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2063119411468506\n",
                        "Epoch 67/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2046345472335815\n",
                        "Epoch 68/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2021390199661255\n",
                        "Epoch 69/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.2009316682815552\n",
                        "Epoch 70/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.197733998298645\n",
                        "Epoch 71/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1964974403381348\n",
                        "Epoch 72/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1938625574111938\n",
                        "Epoch 73/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1925772428512573\n",
                        "Epoch 74/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1901899576187134\n",
                        "Epoch 75/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1874737739562988\n",
                        "Epoch 76/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1856814622879028\n",
                        "Epoch 77/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1843606233596802\n",
                        "Epoch 78/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1819156408309937\n",
                        "Epoch 79/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1806824207305908\n",
                        "Epoch 80/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.178354263305664\n",
                        "Epoch 81/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1761701107025146\n",
                        "Epoch 82/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.175150752067566\n",
                        "Epoch 83/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1722278594970703\n",
                        "Epoch 84/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1709681749343872\n",
                        "Epoch 85/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1692754030227661\n",
                        "Epoch 86/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1664577722549438\n",
                        "Epoch 87/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1642279624938965\n",
                        "Epoch 88/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.162922978401184\n",
                        "Epoch 89/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.161076307296753\n",
                        "Epoch 90/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1591300964355469\n",
                        "Epoch 91/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1575913429260254\n",
                        "Epoch 92/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1536401510238647\n",
                        "Epoch 93/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1532838344573975\n",
                        "Epoch 94/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1517319679260254\n",
                        "Epoch 95/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1490994691848755\n",
                        "Epoch 96/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1476348638534546\n",
                        "Epoch 97/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1459170579910278\n",
                        "Epoch 98/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1429492235183716\n",
                        "Epoch 99/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1417200565338135\n",
                        "Epoch 100/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1391366720199585\n",
                        "Epoch 101/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1380585432052612\n",
                        "Epoch 102/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.136905550956726\n",
                        "Epoch 103/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1344207525253296\n",
                        "Epoch 104/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.13267183303833\n",
                        "Epoch 105/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.130731463432312\n",
                        "Epoch 106/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1293370723724365\n",
                        "Epoch 107/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1268839836120605\n",
                        "Epoch 108/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1248358488082886\n",
                        "Epoch 109/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.123593807220459\n",
                        "Epoch 110/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.122029423713684\n",
                        "Epoch 111/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1202375888824463\n",
                        "Epoch 112/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.117207646369934\n",
                        "Epoch 113/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1151397228240967\n",
                        "Epoch 114/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1135700941085815\n",
                        "Epoch 115/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1125203371047974\n",
                        "Epoch 116/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.110817313194275\n",
                        "Epoch 117/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1086798906326294\n",
                        "Epoch 118/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.106355905532837\n",
                        "Epoch 119/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1053829193115234\n",
                        "Epoch 120/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.102864146232605\n",
                        "Epoch 121/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.1016706228256226\n",
                        "Epoch 122/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.099930763244629\n",
                        "Epoch 123/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0976494550704956\n",
                        "Epoch 124/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0959393978118896\n",
                        "Epoch 125/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.09439218044281\n",
                        "Epoch 126/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.092280387878418\n",
                        "Epoch 127/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0899065732955933\n",
                        "Epoch 128/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0894137620925903\n",
                        "Epoch 129/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0871928930282593\n",
                        "Epoch 130/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0852012634277344\n",
                        "Epoch 131/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0833183526992798\n",
                        "Epoch 132/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0821236371994019\n",
                        "Epoch 133/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0801390409469604\n",
                        "Epoch 134/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.077972173690796\n",
                        "Epoch 135/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.07677161693573\n",
                        "Epoch 136/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0751768350601196\n",
                        "Epoch 137/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0726479291915894\n",
                        "Epoch 138/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0715446472167969\n",
                        "Epoch 139/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0698095560073853\n",
                        "Epoch 140/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0679733753204346\n",
                        "Epoch 141/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.066401481628418\n",
                        "Epoch 142/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.064167857170105\n",
                        "Epoch 143/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0627495050430298\n",
                        "Epoch 144/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0611462593078613\n",
                        "Epoch 145/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0590606927871704\n",
                        "Epoch 146/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0573409795761108\n",
                        "Epoch 147/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.055310845375061\n",
                        "Epoch 148/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0545296669006348\n",
                        "Epoch 149/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0527667999267578\n",
                        "Epoch 150/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0514596700668335\n",
                        "Epoch 151/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0489448308944702\n",
                        "Epoch 152/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0472339391708374\n",
                        "Epoch 153/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0459110736846924\n",
                        "Epoch 154/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.044501781463623\n",
                        "Epoch 155/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0421509742736816\n",
                        "Epoch 156/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0404869318008423\n",
                        "Epoch 157/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0392951965332031\n",
                        "Epoch 158/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0379241704940796\n",
                        "Epoch 159/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.036390781402588\n",
                        "Epoch 160/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.034179449081421\n",
                        "Epoch 161/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0325698852539062\n",
                        "Epoch 162/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0315120220184326\n",
                        "Epoch 163/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0290281772613525\n",
                        "Epoch 164/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0272316932678223\n",
                        "Epoch 165/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0253850221633911\n",
                        "Epoch 166/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0239657163619995\n",
                        "Epoch 167/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0233012437820435\n",
                        "Epoch 168/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0217088460922241\n",
                        "Epoch 169/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0191433429718018\n",
                        "Epoch 170/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0181702375411987\n",
                        "Epoch 171/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.017042636871338\n",
                        "Epoch 172/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0139814615249634\n",
                        "Epoch 173/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0134810209274292\n",
                        "Epoch 174/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.012122631072998\n",
                        "Epoch 175/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0105074644088745\n",
                        "Epoch 176/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0082629919052124\n",
                        "Epoch 177/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0072388648986816\n",
                        "Epoch 178/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.005339503288269\n",
                        "Epoch 179/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0041402578353882\n",
                        "Epoch 180/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0021220445632935\n",
                        "Epoch 181/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  1.0008070468902588\n",
                        "Epoch 182/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9988730549812317\n",
                        "Epoch 183/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9972845911979675\n",
                        "Epoch 184/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9960812330245972\n",
                        "Epoch 185/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9940888285636902\n",
                        "Epoch 186/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9931285381317139\n",
                        "Epoch 187/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9912621974945068\n",
                        "Epoch 188/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9898627400398254\n",
                        "Epoch 189/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9882156848907471\n",
                        "Epoch 190/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9868373870849609\n",
                        "Epoch 191/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9854399561882019\n",
                        "Epoch 192/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9841235876083374\n",
                        "Epoch 193/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9820066690444946\n",
                        "Epoch 194/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9807181358337402\n",
                        "Epoch 195/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9790558815002441\n",
                        "Epoch 196/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9779043197631836\n",
                        "Epoch 197/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9761520624160767\n",
                        "Epoch 198/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9750491380691528\n",
                        "Epoch 199/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9731863141059875\n",
                        "Epoch 200/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9718629717826843\n",
                        "Epoch 201/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9703240990638733\n",
                        "Epoch 202/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9691964387893677\n",
                        "Epoch 203/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9677616357803345\n",
                        "Epoch 204/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9657275080680847\n",
                        "Epoch 205/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9641571640968323\n",
                        "Epoch 206/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9627002477645874\n",
                        "Epoch 207/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9613264203071594\n",
                        "Epoch 208/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9600650668144226\n",
                        "Epoch 209/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9581919312477112\n",
                        "Epoch 210/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9571017026901245\n",
                        "Epoch 211/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9555738568305969\n",
                        "Epoch 212/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9545339941978455\n",
                        "Epoch 213/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9529145359992981\n",
                        "Epoch 214/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9513326287269592\n",
                        "Epoch 215/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9496802687644958\n",
                        "Epoch 216/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9480085372924805\n",
                        "Epoch 217/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9467023015022278\n",
                        "Epoch 218/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9457011818885803\n",
                        "Epoch 219/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9440867900848389\n",
                        "Epoch 220/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9425942301750183\n",
                        "Epoch 221/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9416103959083557\n",
                        "Epoch 222/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9400736689567566\n",
                        "Epoch 223/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9385102987289429\n",
                        "Epoch 224/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9371404647827148\n",
                        "Epoch 225/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9359676837921143\n",
                        "Epoch 226/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9345670342445374\n",
                        "Epoch 227/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9328458309173584\n",
                        "Epoch 228/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9313814043998718\n",
                        "Epoch 229/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9301779866218567\n",
                        "Epoch 230/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9285467863082886\n",
                        "Epoch 231/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.927399218082428\n",
                        "Epoch 232/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9257715344429016\n",
                        "Epoch 233/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9243806600570679\n",
                        "Epoch 234/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9233261346817017\n",
                        "Epoch 235/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9222360253334045\n",
                        "Epoch 236/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9206415414810181\n",
                        "Epoch 237/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9196873307228088\n",
                        "Epoch 238/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9180601239204407\n",
                        "Epoch 239/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9167202115058899\n",
                        "Epoch 240/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.915452778339386\n",
                        "Epoch 241/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9138239026069641\n",
                        "Epoch 242/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9125655889511108\n",
                        "Epoch 243/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9116175174713135\n",
                        "Epoch 244/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9103226661682129\n",
                        "Epoch 245/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9088811874389648\n",
                        "Epoch 246/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9071142077445984\n",
                        "Epoch 247/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9059120416641235\n",
                        "Epoch 248/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9047645926475525\n",
                        "Epoch 249/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9034674167633057\n",
                        "Epoch 250/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9020354151725769\n",
                        "Epoch 251/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.9004201889038086\n",
                        "Epoch 252/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.899304986000061\n",
                        "Epoch 253/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8982575535774231\n",
                        "Epoch 254/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8968696594238281\n",
                        "Epoch 255/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8954499363899231\n",
                        "Epoch 256/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8940445184707642\n",
                        "Epoch 257/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8925433158874512\n",
                        "Epoch 258/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8918808102607727\n",
                        "Epoch 259/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8902668356895447\n",
                        "Epoch 260/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8888736963272095\n",
                        "Epoch 261/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8877438902854919\n",
                        "Epoch 262/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8866660594940186\n",
                        "Epoch 263/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8852679133415222\n",
                        "Epoch 264/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8838845491409302\n",
                        "Epoch 265/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8828627467155457\n",
                        "Epoch 266/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.881595253944397\n",
                        "Epoch 267/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8805603981018066\n",
                        "Epoch 268/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8791074156761169\n",
                        "Epoch 269/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8776213526725769\n",
                        "Epoch 270/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8763432502746582\n",
                        "Epoch 271/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8753847479820251\n",
                        "Epoch 272/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.873923122882843\n",
                        "Epoch 273/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8728487491607666\n",
                        "Epoch 274/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8716385960578918\n",
                        "Epoch 275/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8703972697257996\n",
                        "Epoch 276/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8689855933189392\n",
                        "Epoch 277/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8678348660469055\n",
                        "Epoch 278/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8666877150535583\n",
                        "Epoch 279/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8654001951217651\n",
                        "Epoch 280/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8641418218612671\n",
                        "Epoch 281/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8631246089935303\n",
                        "Epoch 282/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8618651032447815\n",
                        "Epoch 283/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8605562448501587\n",
                        "Epoch 284/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8592268228530884\n",
                        "Epoch 285/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.858212411403656\n",
                        "Epoch 286/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8566609025001526\n",
                        "Epoch 287/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8559107184410095\n",
                        "Epoch 288/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8545725345611572\n",
                        "Epoch 289/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8533300757408142\n",
                        "Epoch 290/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8522616028785706\n",
                        "Epoch 291/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8510812520980835\n",
                        "Epoch 292/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8497200012207031\n",
                        "Epoch 293/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8487225770950317\n",
                        "Epoch 294/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8474082946777344\n",
                        "Epoch 295/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8465290069580078\n",
                        "Epoch 296/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8451048135757446\n",
                        "Epoch 297/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8440238237380981\n",
                        "Epoch 298/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8429047465324402\n",
                        "Epoch 299/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8415659070014954\n",
                        "Epoch 300/300\n",
                        "Learning rate :  1e-05\n",
                        "Average loss :  0.8405179381370544\n"
                    ]
                }
            ],
            "source": [
                "Epoch = 300\n",
                "i = 0\n",
                "lr = 1e-5\n",
                "lam = 0.1\n",
                "temp = 200\n",
                "while(i<=Epoch):\n",
                "    print(\"Epoch \"+str(i) + \"/\" + str(Epoch))\n",
                "    print(\"Learning rate : \", lr)\n",
                "    xi_L, prevxi_L, lossitem= training_loop(xi_L,prevxi_L,UpsilonR,Tau,Xdot,128,lr=lr,lam=lam)\n",
                "    temp = lossitem\n",
                "    i+=1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Result stage 1:  -0.04*x0_t**2 - 0.04*x0_t*x1_t*sin(x0)*sin(x1) - 0.05*x0_t*x1_t*cos(x0)*cos(x1) - 0.77*cos(x0) - 0.35*cos(x1)\n"
                    ]
                }
            ],
            "source": [
                "## Thresholding\n",
                "threshold = 1e-2\n",
                "surv_index = ((torch.abs(xi_L) >= threshold)).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
                "expr = np.array(expr)[surv_index].tolist()\n",
                "\n",
                "xi_L =xi_L[surv_index].clone().detach().requires_grad_(True)\n",
                "prevxi_L = xi_L.clone().detach()\n",
                "\n",
                "## obtaining analytical model\n",
                "xi_Lcpu = np.around(xi_L.detach().cpu().numpy(),decimals=2)\n",
                "L = HL.generateExpression(xi_Lcpu,expr,threshold=1e-3)\n",
                "print(\"Result stage 1: \", simplify(L))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "ename": "IndexError",
                    "evalue": "index 0 is out of bounds for axis 0 with size 0",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-48-4b059dea0233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mexpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'x0_t**2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mi4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'x1_t**2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mi5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cos(x0)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mi6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cos(x1)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
                    ]
                }
            ],
            "source": [
                "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)\n",
                "\n",
                "expr = np.array(expr)\n",
                "i1 = np.where(expr == 'x0_t**2')[0]\n",
                "i4 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i5 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i6 = np.where(expr == 'cos(x1)')[0][0]\n",
                "\n",
                "nonpenaltyidx = [i1,i4,i5,i6]\n",
                "\n",
                "\n",
                "Zeta = Zeta.to(device)\n",
                "Eta = Eta.to(device)\n",
                "Delta = Delta.to(device)\n",
                "\n",
                "#computing upsilon\n",
                "UpsilonR = Upsilonforward(Zeta, Eta, Delta, Xdot, device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Debugging for training with only known terms\n",
                "expr = np.array(expr)\n",
                "i0 = np.where(expr == 'x0_t**2')[0][0]\n",
                "i1 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i2 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i3 = np.where(expr == 'cos(x1)')[0][0]\n",
                "i4 = np.where(expr == 'x0_t*x1_t*cos(x0)*cos(x1)')[0][0]\n",
                "i5 = np.where(expr == 'x0_t*x1_t*sin(x0)*sin(x1)')[0][0]\n",
                "\n",
                "expr = [expr[i0],expr[i1],expr[i2],expr[i3],expr[i4],expr[i5]]\n",
                "\n",
                "#non-penalty index from prev knowledge\n",
                "expr = np.array(expr)\n",
                "i6 = np.where(expr == 'x0_t**2')[0][0]\n",
                "i7 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i8 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i9 = np.where(expr == 'cos(x1)')[0][0]\n",
                "nonpenaltyidx = [i6, i7, i8, i9]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creating library tensor\n",
                "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Moving to Cuda\n",
                "device = 'cuda:0'\n",
                "\n",
                "Zeta = Zeta.to(device)\n",
                "Eta = Eta.to(device)\n",
                "Delta = Delta.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#initialize coefficient\n",
                "xi_L = torch.ones(len(expr), device=device).data.uniform_(-10,10)\n",
                "prevxi_L = xi_L.clone().detach()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#compute Upsilon\n",
                "xdot = torch.from_numpy(Xdot).to(device).float()\n",
                "UpsilonR = Upsilonforward(Zeta, Eta, Delta, Xdot, device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Debugging for checking the computation\n",
                "\n",
                "expr = np.array(expr)\n",
                "i0 = np.where(expr == 'x0_t**2')[0][0]\n",
                "i1 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i2 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i3 = np.where(expr == 'cos(x1)')[0][0]\n",
                "i4 = np.where(expr == 'x0_t*x1_t*cos(x0)*cos(x1)')[0][0]\n",
                "i5 = np.where(expr == 'x0_t*x1_t*sin(x0)*sin(x1)')[0][0]\n",
                "\n",
                "expr = [expr[i0],expr[i1],expr[i2],expr[i3],expr[i4],expr[i5]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creating library tensor\n",
                "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "#define the true coefficient\n",
                "xi_True = torch.ones(len(expr))\n",
                "xi_True[0] = 1\n",
                "xi_True[1] = 0.5\n",
                "xi_True[2] = 19.62\n",
                "xi_True[3] = 9.81\n",
                "xi_True[4] = 1\n",
                "xi_True[5] = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Moving to Cuda\n",
                "device = 'cuda:0'\n",
                "\n",
                "Zeta = Zeta.to(device)\n",
                "Eta = Eta.to(device)\n",
                "Delta = Delta.to(device)\n",
                "\n",
                "xi_True = xi_True.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "#compute tau prediction\n",
                "xdot = torch.from_numpy(Xdot).to(device).float()\n",
                "UpsilonL = Upsilonforward(Zeta, Eta, Delta, Xdot, device)\n",
                "TauPred = torch.einsum('jkl,k->jl', UpsilonL, xi_True).detach().cpu().numpy().T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABGB0lEQVR4nO2deZwcVbXHf7e32TLZJyH7JCSEJGyBCGjCvssuqKBifD7huSAiIODjqeBzey4ICopBQECURUAwIBggrAIhCSELIZCQkD2ZLDOZfaa77/vj1u26dbuqurq7qqer53w/n/50d1V1bV33d88999xzGeccBEEQRHiJ9PUJEARBEMVBQk4QBBFySMgJgiBCDgk5QRBEyCEhJwiCCDmxvjjo8OHDeWNjY18cmiAIIrQsWbJkF+e8QV/eJ0Le2NiIxYsX98WhCYIgQgtj7CO75eRaIQiCCDkk5ARBECGHhJwgCCLkFC3kjLFqxtgixtg7jLFVjLGb/DgxgiAIwht+dHZ2AziRc97GGIsDeJUx9k/O+Rs+7JsgCILIQdFCzkXWrTbja9x4USYugiCIEuGLj5wxFmWMLQOwE8ACzvmbfuyXIAiCyI0vQs45T3HODwMwFsCRjLGD9G0YY5cxxhYzxhY3NTX5cdhwsOrvQPvuvj4LgiAqGF+jVjjnzQBeBHC6zbp5nPNZnPNZDQ1ZA5Mqk7adwCNzgYc+39dnQhBEBeNH1EoDY2yw8bkGwMkA3it2vxVBb6d4b9nct+dBEERF40fUyigA9zLGohAVw8Oc8/k+7Df88LR4ZxSuTxBEcPgRtbIcwEwfzqXyICEnCKIEkMIEiRTySLRvz4MgiIqGhDxIyCInCKIEkMIECQk5QRAlgBQmSNIp8U5CThBEgJDCBEnGIicfOUEQwUFCHiRcWuSsb8+DIIiKhoQ8SNLkIycIInhIYYKEk4+cIIjgIYUJknRSvFMcOUEQAUJCHiRSyMkiJwgiQEhhgoSEnCCIEkAKEyQUR04QRAkghQkSEnKCIEoAKUyQkGuFIIgSQAoTJBS1QhBECSAhDxKyyAmCKAGkMEFCPnKCIEoAKUyQ0MhOgiBKAClMkGRcK+QjJwgiOEjIgyQj5JT9kCCI4CAhDxLykRMEUQJIYYKEhJwgiBJAChMkFEdOEEQJICEPEoojJwiiBJDCBAlFrRAEUQJIyIOEfOQEQZQAUpggkQOCCIIgAoSEPEikawW8T0+DIIjKpmghZ4yNY4wtZIytZoytYox9y48TqwikkHMS8oLo6QAe+Aywe11fnwlBlDUxH/aRBHA153wpY6wewBLG2ALO+bs+7DvcSB85T/fteYSVdS8AHzwLRGLAxX/p67MhiLKlaIucc76Nc77U+NwKYDWAMcXutyIg10pxyAqQUhwQhCu++sgZY40AZgJ402bdZYyxxYyxxU1NTX4etjxJJYFlhhVJFnlhZIScunIIwg3fSghjbACARwFcyTnfp6/nnM/jnM/inM9qaGjw67Dly5J7gG7jNpCPvDDIIicIT/gi5IyxOISIP8A5f8yPfYYeVbzJIi8Q4x6SRU4QrvgRtcIA3AVgNef85uJPqUIYOEr5QhZ5QXAScoLwgh9RK7MBXAJgBWNsmbHsvznnT/uw7/Cxej7Q2wlUDTCX6RY55+Qu8ELmvtG9Igg3ihZyzvmroJJm8tDnxftFfzWXqW6W3euA3x4OfPbPwLSzS3tuYYMscoLwBJWQoFCtcFXIty8X78sfLu35hJH+Mucp5+J5SPX29ZkQIaXCS0hfwu0/RxPinQptbmRlWOn53Fc9Bjx2KfDqr/v6TIiQQkIeFBkRilmt81iVeE91l/6cwkZ/8ZF37BHvrdv79jyI0EJCHhQZ/27U6lqJGkKeJCHPSeYeVriQZ6DoJqIwSMiDQnULqBZ5xOhfJiHPTdhGdnY2Aw9dArTv7uszIfoZISkhYUSxyO385eRayU3YhHzxXcDqJ4HXb+vrMyH6GSEpISFEugUiEatFLjMiJntKf05hI2xD9GWFk++EIvL6KJUDUSAk5EGRESHNRy4LOVnk3gmLRZ4RcuO/f/IK4MZBfXc+RL8hJCUkhGQscs1HLj+TRZ6bsLlWMkJu/PdL7/X6Q+OdLHKiMEJSQkKCXaIs3UeeNpaTRZ6bsIUfMiPePV2ga4UgCoSE3E/UQT6WqBUbgSeLPDehtcgLzHZJPvLwsvEN4Of7i8ilPiAkJSQkqFZ2yhDqLCEnH7lnwjay00nIcwo0WeSh56X/Azp2AZvf6pPDk5D7iWplS+ucRe2jVlJkkeckbFErEYeoFc+uFrLIQ0usWrwnu/rk8CTkfuJkkcPGtULkphQ+8q594uUHThZ5OkdeHQo/DD+xvh2xTULuJ+qfKEVdt8jzjTHuz5Qije3PxomXH8jOziwhT2ZvS4SbnnYzRw7gnHqjtxNY+NPA+8RIyP1E7eyUn3Ufeb4RDf2Z0HV2SstaE/KcmS4p/DB03HEM8POJ5veYzGqqCfmrtwAv/QxYfHegpxOSEhIS1D8x6WSRc/vPRDZhS5olzzdNFnnFs2ed9bv0kfd0WJcnO8V7r7bcZ0jI/cTS2Sl95BFYfeSKRR7wnxt++nCGoI49wL6t7tt0t9pHJOVrkWcs+fxOkSgj5DwD3Vp/S+bZDfbPJSH3E7vOTqeoFaDPYk5DQ1+6Vn59EHDzNOf1LZuBn44F3vi9uSztIOS5Ojsp/DC89HYCz90IdBgZL7tbtQ0c3G0+Q0LOObBuoT9ujqSNa8VpQBAAdLUUf8xKpi+FvLfdff3eDeJ99ZPmsoyQa/0gqVyuFa69E2WNWp6X3CtmdnrHmKNXWuSL7xbLM5FMwZ4SCfmyvwD3nwcsf6i4/Tx1tdiPxCmOXC3kJOTuBBV+eP+ngL9+DmhaU/g+MoVZOTcn10oui5xCUsNFj1LJP3OddZ20yOd/W1jqTh3gPhMLdO/lSleL6JyIVQFblohlxbo53vqj9buXOPKuIo9Z6WTulc/mzLrnxfuap4rfl9oRKzs18/WRy+2p87u8+fAloHMvMHqm8zb6mATykQfIz8YD95whPrftEO81g/09RsZHHjELaHcbsHq+uQ1Z5O6Uo8B9sAB46holEkUV8pT1PbM8h5Bnti+j6ySyue8c4JG5wK4PnLfp2KUtIIs8WKQl3rZTvPd2+rt/u1wr/7jCtAYBEvJclIvAcQ7cNBj4xBXA0vtES2rgKLGO2blWtPPN5SMvp4qKyM0DFziv0yfQ1lMbB0T/tMhV2gsU8ievAF78P+f1dlErez+ybkNRK+5kLPICrZm3/iiy0hXDG3eYrpF//wZomCo+v2P0qTAbizxvHzkNEqsY2pusrrQS+chJyKW11NsOrPmn8IN5Yem9wIs/cV6ftPGR61n89JhTwkrawcL1ylNXA3efZn5PJZ1n7OEc6O0C7pgDbHjVXP7MdebgDzV6ZpdNR2nGtaJZ4LkGBFFnZ2Wxfbn5mYQ8IJxEobcT+OtFwg8madkMvHIz0PR+7n1ENC+VnUXOFCGP1fjvzqk0uM+ulaTL/U6ngD0fAttXiIgDy+/kKN0I0O7gAwWUFMVaXo1crpViKyyibxn/Cev3O09UvpQm/UL/E3Knjih9aC0ALLoTeP4m4Nn/ti5Xw48yU7rFrdukbOLIVYs8UeefkCd7KlME/BY4OWjDjlSP8ixoMeTSomaR7H2oVrrcLssip/DDUMM5sGe9/bpoFXDIp11+W6R70CO+CDlj7G7G2E7G2Eo/9hcoWdaSUcjsBoDI8MAPF5qZztJp4L5zzW0694r3qC7kMo48Yp9XO1HnbiF6pacd+FEDsNDFzRNWnOKyC2HdC8CthzqvT/eaMcC6kEuLnKfFM1E7zFxn5yN3esacCCrMkvCH128HfnNY9vJYDXD2rUDVQON7dfY28lkISWfnnwCc7tO+imf3OuELlZEpKk6FTC283a3A+peB94w443QS+Og18blzD7BlsbmtzMfh5FqJxGDmDFEt8gH+WOQy8mXpfcXvq1xoWiP6K/yMWsnV6ZnqNWOAdSGX/5O0tEcfbq5TrW8pyLpwS4u8a5+ocGX/SSoJ/H4OsOZp4/ccaN0hnt31r+S+JqI0NG+0X/7dzcBhFwPVRr+LnVhn9CYEQs45fxnAnpwblooP/iXelz+cvU4N/wPMQrbyUXNZ63bg3rOB9iakRhyEVCSB5MNfxvr/m42f/c3aGZpadCfQssVMmpNZoYYf2kxZ5odr5f5PAS//UnwOS6pXL9x+pOiv8DOOPFeHY6rHtMg1V0hrqzVM9IU9pkXe1t6BdFpmPTSOoQu59JG/+msxJZgczp3sBHasALYuM7fd9KZ4f/MO9/MlSodDUML357+H+9/4COtbZbm2eU6TpbHISxZHzhi7DMBlADB+/PhgD+Y0tHvne8DfvmxdZjPlGm/Zkvnl69uBOCbhqMh7mNi5EqM2P2PZNrr0T2he8TQGVMetNzNpMyBIFdtErfDLL7oTOPhCoGZIPlcoUCulShJySUZ8CygEesHxJOT2BfYHj76FmxXP2VttwyC7swbsXIyzf/oQ5hxxGK7o7kGN3Jfl2EpuekB0ogNKlIsUfh6+6e0qka3LgHgNkh3N6H7oy2juSmOMzWaPL92C1u4kprDNWFAFpNJpZM0uK122IXGt5IRzPo9zPotzPquhoSHog4l3Xdz0IfHptK3/9b2Hv5/5PGxYA6rO/y16z/glwKKYG39B/HTg2Mw2g3t3Yus+3QpTIh24jWslVgNsXgQ8fQ3wTy1fQyFUpJAX0dmZ1amdI1b79qMdhfyMAwdbvl930amW7w+mrsEfXlqHJ9/eZBzKwX2XGCDe25vsz8nyLJKQ9wnNm4B5xwG3H4nUPWeirmMzxqTNdMbpmV/MfF5+46l47foT8Y3TxZD9TMtMJdPqrhAhLylOVo0udg7RBNO63zE/j23AYTOPRPyoS4FDL8oMwY1c/BfLb+qrtLo41SuOx5R85KprJV5jfnaLpvBKJVpwTiMlvZBvLHeyE+md9km0Tplcb10gO7cM6tKtWHDVcRg/REz31dm8E8s3N2cfW7pu5Og/20maQzaZRoXRu9Ac5FeFbH2I1JotZ8YYxgyuwXlHi3THcWZjLMhouDBErZQdjs1T7buNW6WD1VkXqAIwXYlWUSxyADDKMJ5InCV23dsFDiaOaZeOVRXyZHfxc/rpg40qgWI6O7NEMvcsPU2rXrRfoU8AkqjL2mT/gcDHGwcDAOrQibl3KG4vaZFLi192nmVZ5KngMj4SOVm/bg3wzl/xRtolD33N0OxlsqU19mNZq/Y0G1FtAU/x6Ff44V8BvA5gKmNsM2PsP/3Yb0Eku4Fty+SZWdc5NHnfiR2SWVQz9xHga/8GLrwn+zfqH6Un2Ur1AB/7Ck779p0AgChPIsUZUmD2ceSqkG94BXjo87mvzY1KdK0UE4Obr0UOYGR6h/0KfYxBvBYYpE3Y/NMxwDtmK+3UMebxuBRyGWG0c5WITMnypacVNxwJeeC89cdMdNDbq1Zjyf3fBUMaVRf+AbjuI2DOVcCkE6y/sUuuxxjw1VeBz/8ta9WH24wBZAFP9+dX1MrFnPNRnPM453ws5/wuP/ZbEE9/B1j1uPisF5Rkl+Xrzr2iYD3RMwsfzBSDftiIacDIGSLFLWD9A2qV2li3gJM9QLQK1VVmLGmKM7y6dhe4nUWux5zKSJtCqUQh99VHXkRB0qOLEnXAFcuAeLZlLvnJiYMznxes3Cz8p3qKU32/llYECXlgrJ4vItqeuhq49yxsfPBqzHzkaFyI55EcfwxmHnKoEOyTfwDMON/6W2l96+x3sK3Ij6gSz92azTsC7fCsvNK/+S3zs9PADoPv/EXEhn/pmAMw5Zxrgf/ZaYp1Vb31PRe9HWJQUCSSEdVoNIItLd1o6exBbypt7eyM11p/H63ydhwnKlHIixmin2WRF9G01V0r8VogGgOmn5O9rfzv15thquktb+OH898F1zvb9QFh6RRZ5H7AOfDSz7NTa7z2G+C2I0Xr97FLM4vHv2fOJVDdeKT1NzJGvEDGGfIxdcfTWHa/D0ENDlRe6Vf9l7rFo1nknfuaAQDjGwaJghNTxHTCHOCUHwJn/Ny6j6veA77+ZvZxecqMJTeG68eiUcxqHIbeZBLffWwFeET1kWsW+SC7ACcHUsnsWOVKFPISWOS/iVxiXTDQ5n9QhZxFzOfk7N8Ak0+2bjvI6Dt54/bMotOjb2HIol+CbXxd26+dRW4z85Ab3W0i0oIwadsBLPwx8ODF1uULvmef7ExllhaerLpAgbxbdkz5j4evexSPv705r997pfJKv0XINUtKs8gfjt4gPuiDeQBhWc/+ltWdAog81CMOtD92TAq5jChnOGDkQNQlovjbks1YsbUt+zfy2PnU/E9dBTw817rMkvMjDfz7NpuJYENGMUP0PVjkj+IknHPeZ6wLB43N2s4iuPE601qOJYDBE6zbVg0Cpp6ZtYtvxR6z2a/2fKZT9h3jbtx9GnDLQd627S/I8M58n5tLFwIDR1uX7XeweJflVBpQucZ9TDFCVJX+lVgsgWseWY6X32/K77w8UHlCrvots1wrVos8gz68vlDknx019sciAGOoiTF8/qjxWLVNOR8ZgnbSD0Q0jH6uOk1rzJlJWjZnDxtWm+LvPwP86wbgX/9T+LWUA8VErXhIXHXwceejcaBWBBqPyd6XKrgJzSWmR7BEImKAl2Ta2ZbV96TOUParPY+q8Hh1rewo//RGJUeWLa9uUWlEDZ+SvW7gaODGFmCm0nK7ciXwzaXu+zz2OwAY0G2OCh4xuA6fPWIUDhpTnLvGjsoTcrUAa03Xt9Zus/+NnvDKK3UjtP0YTW6ZCZExgEXAwHHjOTMwfKDiTpGdncMPABL1oonsxu1HArfNEp95KrsjV7XgpPDonWthI8ABQUunXoUDTrjEDCc77jrghh2mBaaiRq3ofRu6kLOotTk+0txf2yX/wlP1SqY83bBQfeTU2Wny5wvFRMZeyQi5Ee/fvNE5HcYpPwSuWQtcv9Fd+E/6HnDkfwEHfxoYPC67pa5T1wA0zrEsiuz+AD9ZeSKGbnnR23XkQeUJuepOkIK28U2s3LQHC1c5+BLtXCte+PrrwAVKgI6sEKKKkBtx5PFoBHOmjMxsuvdjVwHn/wGYcgpQNSC3Ra7C0+bIUcmOVSKfNuA8sjVs+Ola0Sq+w6dOEh9GTge++hpw3PWi38KuUrdY5Lpwa/c4ErNGJA0YoXycgJ/OPRU3pz8HAEh2a64Vrow0ps5Ok7ULRJ4ar0ghTwwQZeGWg4F7bTqmv/S0cJ/GErldmzVDgE/+PLtvy4lYlX3rjqet2TN9IuQl3YaeVmFVTTpBiOOWJcDdp2LJfddhcMJBEAp1rdQNB8YpvdxaZyfAjCH64ltNlVlhXD9/HfghnxUFNlEnztur5ZlOZw8gSieB3xize1eKGOSbOY5z0fGXSmYNCOru1CpKNXx0v4OESwSwfxZUy1m3yLV+F0Q0i1z9XDcCU0bW47hjjgUAPL9Cm/qvkM7O/o5dNFKr0fJO95r/3eZFlk34ub8DGmcHd16xamfRr9/P98NVnpB3twINBwJDJwKde8CNeTGndq/AWdOV5pDq4yrUIgesw7VlNIPmI7ebIejZVTvw4FtGCyExQGzjNRsiT+fIZV4hFrnsWPJawb12q+j4e+0Wi0WeTKXx0U4tOadT5W03QladW1X3kWe5uKJWi1w9jlFZHDFJtMwWr90KC8WEH1bixCJ2cC5SNvd2idmafjgUWHyPdRs5D29Pu/2EMQBYIUnq8iGacAgpZsCAkTbLiyPkJd1g+0phobbvAvZuEL6uUYcCXS1YvmIZAGByfRKjByiXqzZvCvWRA1a/mnw4Mj5y51wrcyYPxw//8S7WNbWZ+/DqXuGpbEvQsr5ChnlnrtGjSDUbFm57k0XIb1+4DqlureJzSmmgz/QEmMIAZDfB9TDQSNRqtdsdxzAcRutjS3SLnHPgzT+Yk5pYzmmX9dgBDwEvG9Y8DTz5TWDhj8z78sx3rdu0G7mLetqBHoe+pyLjw3MSq7LXlQEjTEPPR8Iv5M0bgTtmiyiN+88Ty2LVwLijAQC73hFpZ4dFO61NZNUKLyZqRS2oQydZ9+cy8eqvPnMoquMRfPuhZUjFjILf4zFcMJf1HuZBJaog5Tu7ihT+VK9lnszfvvABhlVp/wFzEnKHZ2HEdPFePdi6/LDPyR0av49am9SRGHDdBvGSGM/e2dM0q7CnHVjzjLm77cuBf14LPP5f1u3SKeAX+wNPXG4u03PLVCpq4jH5fOut0w5FyPUQT0n1QPvlfhGJ2bf0A3CrAJUg5K1GfowtS8XEuQCwZz348CnYE23ASRC+MdbVbBVydfBPMa4VFZl/w+JaidgK0ciB1fjf8w7C8s0teO5DwxLPFbkiUbPk2RJiP6va0shbyI3/d/FdwN1mqtnBtQk0MOvkEM6uFYflcmi2bsmNOkSEpw2bLL6zqEhRLKkaKFpqalPesNSGV2niu3stsMaYlWrPBuCPp4jP+oTP8h6pk6EEnMujbJAVsNoxDFifESNDKXrasyYFyRCrsV9eLAcY4aX6AEPJABJye2ThjVUBE48Tn4+/Hk+8sx13dCmj7nrarCKhWtLFuFZUYnadnYqPXBOkMw8ehVOnj8SD7xgZ0jy7VnJEcYTZIld9zvl2djq4m3529kQwvbWTr5DLe+nUJJfPkG6R2/lipeHg1qr66FUzMkn/v9XZpyT9xbWitnLVa5Y6kE6Z8+j2tOP+l9+130/MJ+NN5zP3AdcaEzXb6Ypd0i0fCL+Qy4c9mhB/4oTZaKqfhh88uQrR4ZOt2ya7gIZpwoJSKVbI43UiFlzfn+4j1wokYww/Ou8g9EaFayXd5dW1kqvQhtgiV4U832myHAZ8nTzGpuJz8pE7+S/leTnFGssKIBKzWntuQu40QE3HSchV91B/scgzrTTNIpeVYmezWF41ELy3HUs+cBgSX2xuIydiCTPG3K6l75R0q0jCL+TSCotVi4IRq8KPn3oXnT0pfOGEQ7O3VZs7siDYdXDlw3fWAtcoCXosPnLVIs8WlBEDq/GFY2cAAF59d7234+UStkqzyN1aIDtXA+8bmSOdOoD3bc1e5tjZ6SDkslLRww/137GItTIo1CJX0f9veZ2WtAz9xCKXrVY1nQFg+sIN/3hq0Dgwnsa0QUqHsNq/EZRFrqJWFiONNAo2uez9IPxCLsOLYgkg2Y093RH8fdlWfPX4/TFmv1HWbTubrTcyM6S+SCFP1FrD0nSLPFMQ7QX4tJn7AwAWLPsQO1s6ck8ykavQhjmO3OIj9xC18rujgb8YoyWdLNxWmxG9+XZ2ynNxKoiqa0XFbvt8LXL9+jMWuVJ8K7WzU6/EpGBzbr1mWSkaQv5hj6hAL5pmPzgrMItcRdWVwcY8xV7TBuRJBQi54Y6IVoEnu/HO9k6MH1qLrx+/f7Y/at8WMXRWkil8PvnIJY4+cnvLkhl/7pD0XjT/4UzgRw3AA5+x3dZtP8oG5vHDhh7OBxTtWrHNDpivj1xWrk5CLv9zvTltV5nma5HrFXfGR65a5Jpr5ZVfickrip15qq/Rr10abumktRxIS92YhWnxbiHUY6uVe6yWfbuOSL9Rj5HK8fwUSfiFXEZ6xKrQ2t6GPd0R3HTuDFTHo9nNWl3I64aLd78tV9W1YvGROwiS4Te7KvoQDugwBipteMXcXv3djYNyp+IM8xB9PfUAIAps2057F4mKk2ulZWPWPJuehPxEJemYLJROFpV0pzi5XizbGqJfqI8841px8ZG/Ygxpdx04FgL065Kz0vd2WMuFUSlyQw/aosb/rcbgqxZ5KaZGVC3yjJCTj9weI+C/LcnQ1dmBEUMG4YSpxh9mV6hUIb/kceC0n+ROgJMvavihtIo5d7ak7fx1vR1mPGy+HVmhdq3YWZAc+NOZwM3TgNX/AHbYRyJ0dznEDDdvAuo1N5sXH7maovbc20ViLWN8QvbvjELrScjz9ZE7dXZ68ZGH8BlQ0Z99aZF377Nes+FyWbZuCwDg8AONQAd1YnO17JcCtXUmxzWQRa7QukNYpmv+mbHIl65vQhV6MXOSMvzVTsgGKH/mkEbg49/w//y07IcA3IVcYzM3WgpypKKdu8ETISzEdlYq58AuozP5oS8Av/+4uVz+rLcH7e0O4Zstm0UeeRUvQq4WxEFjgRP+2+rOUJHWl8ytwqLAoPHu23oVci8+8iwhd++XCQ16+mHpI+9uy4paaensxfPLReK4mQeKfieLRa63yoImauNaCchH7v9Y0SDhHHjgQtNSWjQvMxHAzpZ21MWTiNXmqPFKUStbOjvV0Z3eClVzzXiM7dqF1ENzER02yT61qhthdq3Yukc4MGKGmLRYpcsMI33kjbX4ZLrbvu5q2ZQ9w7mTa0VtDlfZhJQ6Ie+5FPIbtsGxIo1EhdB7da3sXgu0bDFnkZL3SK2MnDo7w56DJctHblTWPdlCfutzH6C2px2IARHpNlUt8qpg3BqOqM+MrJDIIocokGufEyP3AIDzTOz14ARHLN2dPamxjp5DPAiUGYLMVoF3i3z8FBE2Gd23CVj/EvD6bfkdP9SuFRsrlaftKyWlkM574V1URxzELNmVbZE7Rq0oy9VwtVxpHFJaeGKsyj3ELZpwHj5ux6+nZx+LuXR2ZvpXCkgBXE5k+ciNe9bbZam8mvbswX2vb8CsUXFxb2Ul3KlY5DU+u1BzYXGtSCEnH7kYhm+Bo2mbmCnnkBFGAdR7o6/fCFyoZEfz2x9uh2qRQ7HIPRpHA4eORBrFdMaEOGrFziLnPLtSSqeApvcyX7u6OpDgLhEaegXu1FpRBVvNx5HLIpcWlz7HoxPRRPYMQbnoahEJof56kfiu3hOnfpRKE3KHqJXnlm9AdTyKo8ZUCbGUOtC5V6TOOOV/syZ6CBxL1Eqez0eehEvItxpCbvi6Um27MWzv2wCAhoRxo3SLvHqQGZ0CBFYjWsjlI7/sRfffxxJI65P65kOoLXIHcdOF95WbgQc/l/l6wYxBYG41pV6AnO6NKuSqTzWnRW4IjpfOTkBUDPlGlPxsPHCrMsjNErWiC3aFWuQym2G613Jtm3bsxjdOmIwa3mUIuaIDg8YBs6/wLxWHV+xcK35NK6kRLiEfbUycYDSvojtXIAbxZ7IeMwwxC7XToRR+MicfOU+LgQHyOlSOuVr5fQKxC+/EyzNvwdndPyriREIo5HYdgDyd3Tm5doHl65dn5Whp6RW8k+844uAjzzXWIF+LvNA4ZjVnTMQl/FASeiHX3GUyj0qq11J5jahJ4z9mNwqhT9RZ768crOf3eJFcqK6V464X7/rkzj4RLiGfcT4w9sjsh7ZuhBJPbuMjV32V8WA6GyxkCphikYOLl1OT/qTvm+cWFVNPzT77S4iMmJr/8Suts5NzZFVKQxotX4dGXfKzA96FU41KsUwKkcPVlWk6e7TI/RiQYnHdaYJXqT5yKeTglnXHNtaKsSM97YaQKxWq7GAsuUWu6M5hF4scT+RaMbDr9a0eZOYptisglhlbSnDJEScfeRqerGTjAYhGGL5z1uH5H7/iXCvZFSA3LPf3mJEDvqvZfb+xauC8O6z7zIUq3rnupRQVrwXVEhFTYN6PTFI22FjkxvWlU8Lto49uDUs0i3pdyR5hcRuVZWen2Vk8cVAEWD0fWPe8EGxVB6SBFJBbw5FSDDqShyrZkfyiECH3K9+4V9TJl+XDk04anXYut1yKhXK+c6YMd9jYDaOQvn4bsOjOAn7fh3js7GzasRVvpg/Ertk/EAuUUERbYlXCKvrEFeK7lwlw82nR5NuZpfrfPVjxTyVOz17Ioi5CbsDTwILviSnw2pSZjuZ/W4zFKHfU65IRKEYI8YKVZuXEkt3Agu+LL5vetBpv0rVSaou8hIROyNN2D331ILPjyNa1UoK8CirqEH3p1ln4E2Dl37yJQ7EVj2ptPX1NcfsqBZuXiCn6AOfwQ81F0LtnI3j1EMyeasRWSyF3ur/yuTj5RuCq1dbh2k7k06JJ5+laUYXcQwf8uGPn4rGUFnURUfpgsjo7DXhahOwCYnDMa7cC25YDS+6x377cUIVchpsac17+e42SsiHZBQwxxpcMn6oJubTISchdYYydzhhbwxhbyxi73o99OvFhi9YkjMSsmQdzdXaWArWzUx570TxjmQdxKDbFZtj8on880YzGcBoQpLkCRvEmTG6cACYncTCSJTn+1/K5iESD6XDKWOQ5xjFIVNfKyOnO2xkcsv8YDBiizS7DYVZc25dr6xx85Au+D/zhmOztyhVlyr5Mi8KohKuYcc9ZRAj5vq1CxOc+aVRyhmsj3kc+8hJStJAzxqIAbgdwBoDpAC5mjOV+MgugrTuJNzZpPtR4rdWCTdgMgS25Ra5kP9RbCIVY5HlXRGVeON1wGqKvCVKEcQwf3mDeG2mRO/3XuQaKFYsUcq+tKTVG/eIHgZNvct8+MQBHzDjAuoynzOfp+ZuEpW2uNN6UZ8Gugi/3POaqRW5MebeTC5fQCfsbrqF4nYh2at4ITD7ZbG3JDmBpkfdVn5GdJvmMHxb5kQDWcs4/5Jz3AHgQwLk+7DeL3y1ci929Wq0ar7U2mYbtn/3DUgu5apHr1rWrkGf7yAHk39Pt1MwOA7Y+8mzXCgCRqiHmIOTn/Bb4lNI/EPQzMGKaeC+ks5NFcneMVdVj2Lhp1mXpJCyd53bZIdVoFj1vidOyckIV8se+AgB4znCNf6LRuIeJWpFzvrcDGDwuex8Jj+6uILh8MXDF24Efxg8hHwNA7RLfbCyzwBi7jDG2mDG2uKmpqaADHTlxKGburzWL4zWmcNaNsJ8Tr9SdnbJQMmZjTXuPWsmQr5CHeZIB20RSRuimyjFXA4fPNS1tKeTyflcPAsYdZW6fr0U++ZT8tv/0n4C5/7CfEcgO1UfOmHPKgMz29UDDgZZFPNVrNQzsLE61AkzZdIgWnJCtRGiduHsHTcfiZiHgCSiRQnKCarukVHrIca577SfDp1gT9QWEH/E4dsqU1bbnnM8DMA8AZs2aVVDb//ipI4CWRuAjZWGizhS+4VMczrDETSo1/FC3BAtxreRtkYdYyB2iVjhPZx60njnXInHSDeJLxiLfZ/0OWDsR8xHyG1vy9x3XDAYmHut9e9W1Arhb5IMniPMfOtGyuKu7BzVqOK1lxiAbH7mtRV7mc31qz/If2o7B6GH1QCvMZyVeJ9wqgH1ZUS3yix8CGg7I3ibk+GGRbwagtmfGAsgxA0AR6OGHqkXuJOSSGZ8K5px0oqqPXBdyl9/JCkd3x8Qq2CLPmo/SPo58X4eZRyUxWGmVOblWwKzPSr6ulaArfz2lqlsFf+Vyo3Unnis+eAI2RsYg1bEXXM3XYrmXNkKesslFEzKLfGtnHOcdYUSnZKbfqzWvU40amnYOUD/ammNl6unA0EkBnnDf4IdF/haAKYyxiQC2ALgIwOfcf1IEesRBvNaMIR/uUtP+z87SDQiwTMTrh0Wep1sgTBa5bhHqQh5NIJVOo6m1C5moZ0vO8CoAzIwxlveOaZVo0J2d+ZI1Y5HH5v73doGxKKIPfA0D1j0IqH+13exK6rNw79k268vdIree37QJozF5pOG+spsQW/2fP3t/wCdXPhRtkXPOkwAuB/AsgNUAHuacr3L/VRGos7YA4k/ca/hahrlY5LGq0o20KrizU/5e+82ow/I7fpgsct1KTHZZO6+jCWxr7kAqpVyTZeh8RLgp2o1+F7Ugq1Z1tMSj+nKh9+V49dtG40AkgtFDbXzBTh3Fbs3AMHV2Arjg41PN8mU3IbbXOP4Kw5c4cs7505zzAzjn+3POf+zHPh0xJpLI0LrVHEwyfHKgh/aMmv0wyxIsoLPz9J+KKem8EqaoFV3IU72We5ZmMWxr7kR9lSJ0eoWs5g0vNga/VOgjS/M0MphdTPTCH4s0t4A236uLv9+uA7QceOchkbZaa12OGD7crMjtLPKAcpmUO6Eb2ZkV1L/tHeCUm4Da4c5Ta5UadYh+1qzqBVjksSoRH+tAZ73RSpGde2EaEKT7aNNJixi3pSIA52gYoPzvuuip1m1U8ZGXM3Va6oV8IynshH/Ph8D8K40vHpNmlatF/vhlwJ0ngOvnV1VvCrm0yFXxJiEPETVDRTpYADjqq8DBFwLXriuf5rOa/TCrs9O1t1O82XXMuUxRt7D7QKSP+pqS+7zMXCu3HALcdZr9OtUdkEoKIVcqstZehv0GJhBXn1S9r0Na5JE4cNy1IvRwwid8OfXAKNRHnsHhOdJnHcr1LJRjZ6fMZApgxaY91nWJAaah9O4TxjLVtdI/hbxMlC9PrnkfmWnUSphhzDNu4YdesLPaXWY22tORxPs723GgtL7KrbOz+SNzImkd1bWS7DSE3LS+0yyO0YOqgU5lYmXdepUWeawaGDtLzApV7ugVer4ph+0iUIDs1lwYfeSt2zIfn12+CYeo66rqzfKVyTipulbIRx4eonFhfZejiAOaa0UTcrf45DnfEu95PowN9dVYtKEZXAp4Phb5nScCD38xr+P5imoR9naKSkgRo4EDahFlsLoInCzyUo/g9RP1WdYnirbDduAUkJYiZ4kjD5mP3BihmmZR7OvQU3LUZJf7hEPUSj8inEJe7rha5C6F6pirxWAUpw47tVNP4YjGYWjv5WZkRz4W+ZYlZhO1L1Aty15hkaeVqJWBdbXA5kXA3vXmdrqQqxa5zpf/BXzuEf/ONyhkK4NFvVXkDkL+UbNmqZeTj7x5ozIxhAuGRd6crsX0kdq9UOLpMziFH/YjSMiDIKrEkevWQzEdkd9407aQD6+vxgH7DUI6ncLanW0h6+xUXStdQDqJpg7z/JldegXHqBWbSnL8UcABpxZ+fl/+F/D1Nwv/vRtqv4fqWpHXN/084HptQgiJw3yfK7Z3ormjB9bOThfXSil95LccDPzGw0QphkU+lLXi4j2/y16vp6NVy0QpJo4pQ/rnVQeNmv1Qp5i0ofX7OQwDZ/j45AZEGMf3n1gJXu6DPFQsFnkHUqkktrUqLQq7MDtdyGX/gRwY5ifjjwJGHJh7u0K44m3gmrXis2U2IqNYVg/KHsov6bUbAQt0JhlueVpJ0pSrdVbqZ6VzT85Ntm7dbL9CBjjoLbJSTKhe5pCQB4E6ICiLYlPM2lQOjKE2EUcUHP9etxub97Rlb1OuKELOezrQ09ODFLMOCMpCL8hyIJjMSR4WqurNhErMRsjd8mc7uFamjqjFlSvONxfkMhzKrNLvTaWxfO0G68IpRsTTJ38l3vXotFypOfoB4YxaKXfU7Ic6xSbytw1fFJM8M3AcPHogVm9ptiS/KYh5Jwi/9HUbittPrs40pWm/+P1NODidxKhhAwFpuNla5Npj62FihrLHLvmVW0oJh6iVGSOqEN+tRPjkcrOVWfjhPa+tR2NXMyDrtTGzgIv/CoCZ90h3rTQE1GIKEWSRB0EkSIvcBsYyx/rRudORTPpQOLcu9dYxlQs1d0qqF7jvXOAvFynrzTjyJ95cgxhLYz91+LndPcwKP/SYOracyVyTMq+rWxTO+cpE0uOOznyMp7Vh+uXU2ZmD7S1duOW5D9BYq1RSI6cLw0it6PQKroJn/vEKWeRB4PZgFT21lp1rJZJ50A8dOxCxodVAjrmIS4Yq5L0dwIcvWtcrlmW6qwWxeMoM2WRReyGyCzs969fZg2zChOWa5MAwl8Etw/YHDv4MsOJhoGEqsOkNsVxLOtbc3onBbsfti/DDh74AfPbPlkX8o3/j1b8/ilT6ZDTW9QCyPrL7T/XyxSKiv8Gh36A/QBZ5EOgW+dVrzKm8/HKtOA3952kc0FBGgyJUYdm9Lnu90rQ/dpwhZrKgRuP2nXV2LodZXxYjfMOKtMg5tx96bkfGhRcBjvgP8VkT8gcXOQzEkpTKIlef+9X/MPMB9XQA6RTa/nY5Ltz7R9xwfAMSvUpfhxfXGmMiNW0luNgKhCzyIMiEHxqiW7+fkiTJJ9dKrMa0ZlnEIuRxZnOMeScAM84DZn/Ln+N7RR2Cv0kL43vym8DS+zJfTxgfB7bDrKQiMe8WedhRrynpUciZIuRn3SzitLuaLZss27gXrcOScJw1slQ+cr1TtXUrUD8K+MkopGuGot6IZrlk/fXmbD9Atj8cKF066hBBFnkQ2PnIM0Lrl5ArFrniI7eb3/KDLTuFz3vB9/05dj5sXmx+3rfF/JxOWUQcAKp65HRtipDbRVVUYkFW/f5SXHMNbpF+Y/nfx2uy3AsTh1WjqdXF5ZAramXvBqBli/s2XtArjF0fZFIPRzr3YBMX0Ttsy1tGK8Gh5QmQT9wGEvIgsAs/jCidWcVg61rRhdzqjvjtI8+aX35RwlS/yR6RxU7S2Wx+3rLEum1iALDM8JvK+xeJObhWKtEil89KHq4V1SIHhPBrA4W+eNQ4pN0euVwW+a2HAr+2cVl07cte5obuwln/sqVif+XQXwBffdVcL33jXlwrBAl5IGQeNKVjMuMDLXbUJdOOAatFnk5liV965xrzi5yAAfDWOsi3BbFpEfDSz4H5V2U18y3f79ImN+5RYt9lJRWN2+eNKeXkuaWCFeBaidgJuTVqZdTAKgytc8nR7tVHvn2l+fm9p4CfjbO2tnKhd6q+div2ffQOAODy+ltwwTnnAPsdbK6fZAx8s7sHpZ6DNwSQkAeBnBXdYpH7dKszFrlqqTBrRaFVFmeMboctXgaD5OtDvesUMcHB4ruAPeut61SL3I2cFnkFWmR2PvJcc7UybbxCvDp7oBBPY0iti5B7/X/vmG1+/vAl8Z6XkCshhfufBPAUlr32TwDAVRecgKqYcS1TzwRGzADOuQ342FeAmZd4P0Y/hoQ8KKJxq+Xgt4/ckqeDWfevid8pExwsWE9CbjN9mFf0OPS2nd5+Z/GR9xMht/jI5cw3uXzkuS1y8LT7FBv5jOyU/4WsaPOJeJHbTjoBOPEGAMDY1uVIsTgmTVCmb7zoAeFiqRkMnPkra2ZDlavX2C/vp5CQB0UkrnV2+uxaOXyuaa2wiFlpNL2XlXPEEs4FmDOve7HGkvYjCD2hunEA55zkMy8RI/gklqiV/uIjLyRqRXZ2yrjzbB85eNrFFcGyhbx9t3N+FpkCQZ6rV2t+3zYz9PTQi7CsTUyjPSmyHZEh4zSDh3lrvVZiZV4EJORBEY3B4iP3u7MzllDmL1Us8j99EtixwvobzaXxzOP3ig/rXjAXpnrtC3AxFnm7ZoEnbaInvvAocNYtwJfmm8tyxpFXoJBbLHKPrhXdIo8msg0FnnJuBUbjwMu/AP5hhKT2dIjOzeUP2W8vOziliHpNl3znicD95wEAWnqASx9Zjw6I1gYbVmDnOwm5BRLyoAjMIjfg3CygqmvFDq3T8Yx3r8Wrby0BHplrLvzN4cBPx2VHI9jNzO6VNtMi57Vijsp2rgw7v3yJmIs0GrNanzkt8gosxKoVmvToWtGjVuwiPFyetxQz7uOSP4lnqb0J6Gl1Djfs1oXco0XeujXzcd6rm9DWnUJ0qOFOISH3BRLyoBg8Dhg42vzumxWpNpOlkEfchdymk/Gp+Y9ZF7RsBHrbgdbt1uVOQp7syW5a65afdK18cyk2JkSBjcYVIdcnIJbk8pFXetRKMRa5jouQtyeVZ2nveqBjt/isz/spkZW83KeXSn7XWsvX95o68fMLD0HV2JliQaF5ckjILZCQB8V/PAMcf735XbpE/Mx+mNlXjrlLbZJffTy62n5b3ZXi5Fr55WTgt9okAXrERPtOgEXwp9XAm7uEgFdV1wAzjDSr1YPs9626VvqNRa78f1IovcaRuw2esZvqLV6HZO0I9HLlmC/8WMR2A44pcjMWuVwvQ0a7WoQf3I7bjrB8Pe+IRpx96Gjg498QCw5wmJQ7FzQoyAIJeVDEEtpkAUoujaJQKwRlX3m4VgDg9HqbvCdAduemU2dnV4sYEq6i5wNva0JPbABunP8eBg8bIU4zmgA+dadIj+vUCZczaqXCLXKJ1zhy+RzYTRGYTmffw+s2IHb1uxhQq+x/5d+A534gPnfsEtb2ojutv+vShHzpfUDHHuD2o4CbDwTWPgdsfMPc3qYleNZMY3KIUYeIaQ1HHep+jU7kO1l1hVOBpk2Z4ldnZwbVR57DtWKTuzrRssFhW48WuR2/mmr52tmyE3t6Epg9eRhObGwEXoUQ52jcvUntFEc+6z+B6edWqJDb/H92Frbdb6QF72SRq5EpN5ppMasSVYCd8b3iERErrndWL39I+O1lp3WqB3j2v81Z7/98geUYfO8GMABf7bkSdyRuEaec65q8QoOCLFC1Vir86uy0uFaMfTHktlCmne1t/7rfM9kNNK0BPngO+Oh1scxj6lPWvQ+ReDXu/OIsxKoHWM/Z9gda9kO9s7NuODDpOE/HDh1q5TTuKPGeS6x0d52TkDvdc32mHRVVxI8zXITrngce/qLmQ7c5x9Yd6Emm8ednXgEAzJh+kLnOLgkWUTQk5KXC785Oi2slR9QKABxyEXDDdmCQ+9xBC9/dDJ5WCn53K3D7kcADFwD3nA40b7L63NMpx06vataL/YYOQm0iBiTqjO1dKgG90y4r/LCCrTD1//vCY8CVK5y3NX9kvEshd4hacQoT9CqqVQPMHPGANTGX2qFv0PHsTfjcvNfx0TrRD3P5p042V7pVHkTBFCXkjLFPM8ZWMcbSjLFZuX/Rj/FrZOcYo4NxyATNtZJD5AaOEj7Xb68Uo+scePD1tfive5V0s2qIIgC0bDKjGwDg7tNE2GKT/Ug7Jme5kTOduw0ikZWdk4+8kv2iakVfNcCcaNgNTxZ5yr7DGPDeaRyJWyeB7u0wI2radlg2bRp6BGpXPoDzt9+Kzx8YAeJ1YLWKG80v1wphodiSsRLApwC87MO5VDZ+uVaO+irwtdeB8UcrrhUPFnm9Yjm5dKJ9duYILPqwyXE9mjUh3/wWkOrGE/eKiXF/X3MptsxSonWkkMuh1m6xx7lcK5Us5AWFVOoWuQcfuYpH67gtyawz9fR2AOOPAmqHA6set2x77ta5eLHmZHw+8iwmbnw0uy+EXCuBUFTJ4Jyv5pxT0gMvqGlKi4ExZSYU1bXiIgQsCgwYYX53yXN94uTBeOZLEyzL2pmZ74L//Wti9KhCmjMc2yYSIF160kEYc8KlyrGkkBs+crfRgLpFrrtWKtizUpDrzauPvEjXyo+fWYcPW83z62rehl3dEbSlE9aslQCu/fSxOPaah4EhjULwawZbd0aulUCoYBOnzPB7ZCcAzLkKOOhCMc2Zm7U6YKRVKNzC2lLd2O/+Yy2LtkZMa57ZNNOXzvxfDIEITYtVDbAKSjQP14ruIyeLPMdvtPuRd2enNyE/espI7EubPvJI6za8sbED240+zx5mHve8IyYiEo2aKWn1sQJkkQdCzpLBGHuOMbbS5nVuPgdijF3GGFvMGFvc1OTSdK9UggiZqx0KXHiX8F+6CnmD9bvbzDM2ceNTph2Wtax3UCP4sCnAZ/+MWacrfvREnXX2dxnbnHGteOnsVMMP1e0r2CQv6PmQFrkMP7QRyZd/lR3fnzmmi3U88qCM6J57RCMOGz80syrBUjh66liMHymmL0yMOij79zI7Z/Vg63IayBMIOds5nPOTc23jBc75PADzAGDWrFl+BVOHB7/T2Drt346ENmNjDos8Cz0fxoQ5iF/0gNlsVq8pUWe1DGWlEZdRK3l2dqrWZEVb5AVcmxfXip4NUcVNVM++FXjwc6IzM5rIOr/hI0YDHcagsvpR2b+vM1x5VQO0Y1JnZxBUcMkoM4JwrVj27/JX6smX3CzyXpsMhbqQH3WZ1fepRswk6sT3jJ9b6+x0g9n4yC3rK/hxZQwYPhU493f5/Mh4dxFyN6Sb4xNXAOf81rquaqD5f0Ti2S2G/Q4xxxMMtBFy2QrUW2CVmF6hDCjqrjLGzgfwWwANAJ5ijC3jnBeYPKHC8X1kp4abyOnC7ZZVz64ZPmx/8V47DLjsJZEQzAlpeUerxMg/6VqJexByeY9kYdf9qZU+mu/yRfltr1vkdkP03VBdWDLOX6KmmIjGs5+vUYeYIm1nkUuXiuwTYVHR30GulUAoSsg5548DeDznhkTwrhW3ZPy6K8Utq546KcWpPwYGjQHq9zOXuYk4YApCLAH0wKxEdKGwwzJRgk0isEq2yAuiWIvcKP7RuBle+IkrgPefFeGqauez/Dz8APGMDJucLeRqh63sJ5FCfvglIl0uuVYCgUpGqciIUBlY5G4da6pFPmiMyFQoIw8O/kzu80goFjmguEmMd9cwSSV3SCRmU+gr3CLPFzcf+af/5P33kTjQOAc48XvidfkiwyJXhF7+NyffCHz7XfEMyf4OWdEf/kVz38ONvDv7nyjez7wZuH5jZebJKQPIYVUq5AMcVDevq49cs8Cd4opjNVaLXBbkRB1w7XrntLMqGSE3mtDSMmNMdKDJPCJ2VBmdspwD594OjPsY8MovzfVkkVvRjQPVbTHjfODvX7fmRfna6/b7iUTFM3LsNdnL5X5P/ZF4biYdb7b+5HNUO1Rks1QHDTUcAFz9vjl+IRL19vwQBUFCXir6tLNTE3KnIdtV9dYZgtSOqdqh2durzJ0vsuapESeANRTxiC+57+OiB4C3HwCGTjL98iok5Pa4ZT8ExAjMS18QaR3scPJbq52dw/YHPv+wdb10rVQNtM9mWT/S/byL5YtPIjjLKFyQkJeKPu3s9GiRJ+o0izyPjqmJx4iXRIadqcmWcjGkMTPDui2V3tmZL7nCD2Xe8DlXOos44Pw/53KDSP+3l/6PIKjUTJgFQCZOqfBtYgmn/ecRfigt8o99BRh7pPH7qLCe1SHXxQinbGbH8hByO772b3/OpyLROjuzhNdYntBiuXWcBDvTZ+FQ8R9hDAQjl0mfQ0JeKphW6PzGLT5Xt8gP+wLQMA2Y/S1g6uliWTQuLDrVteI2CjMX0t9drJCPnCH8sgCos1ODaSM7naiqd1ghp4hzsMilS85p/yd+D7hhR+6ZjIjAIddKqYgEbJG7NW91i3zgKOAbxpRcmZnYDYtcjVqxmVnIM1I8/PRrk49cw+M8sGonpB1OrpVP3Qm8eQcw6jCHwzP3MQlEyaCSUSqC7uxUm8//8Yx1nVvcuBTHSNTwZyui4GWW9Fzn09Ne+D4yGIJFQm7FqZU38mDrdz0DoY5Ta27IBOD0n1LIYAggi7xUBN3ZqVrkI2dY17lNUpAZhBPJLrB+uFacEjblgxQs8pFbyfiwlWVXv5+d38RmFh/xexlHTkIddkjIS0XQIztVP6jq8/zM/cCEj+c+r0jUaplNmANMP6/w85FpTAeOKXwfGcgit0WffBmwD/kbsF/2MpWgnkmiZJCQlwrpWnELAysGVbxVQZ54bPa2KtIaYxHr787/fXH+z4MuEEO3J3yi8H3okJBreOxAp8kcKh76h0tFNAZ89s/AmBJMbaoKci7xy7hWNIvcLUOiFxgDGmcXt4/snfq8v5Cjx5ET/RYS8lIy7ezSHEf1JecUcsVPqvpKyym5ESPXij0Bh7QSoYGEvNLpK4s8CKiz08p4I2+NUzKzyxfnDj0kKgIS8konV0RCJo6cWYW8nCxy6uy0Z+gk4MYW5/XDp+TYAVWMlQKVjErHq0WuRq1E4u75zUsNhR8GDLlmwk4ZlVYiEPJyrWhTrZUdJOQEYQcJeaWTl0UuhbzcPG7kWgmEQy8W72NLEElFBEq5lViiGL65FNi31boslzvCLo48n/S1pYRcK/4y5WR3HzsRGkjIK4lh+9tPyOCGXdRKuU2QS+GHBOEKlYz+TiaOPAwWOT2uBGEHlYz+jm1nZ7k11MilQhBukJD3d1gIfOTkGycIV0jI+zuWNLZl6iOXUE4RgrCFhLy/YzcgqOws4HI7H4IoL8rNGUr4xaULgS1Lcm9n5yMn4SSIUEFCXqmMOVy8chGxybVSdha5hFwrBGEHuVb6PWoa25h1WblQthULQZQHRQk5Y+wXjLH3GGPLGWOPM8YG+3ReRMkwrFxWzj5yA+rsJAhbirXIFwA4iHN+CID3AXy3+FMiSoqc7zESBh85CTlB2FGUkHPO/8U5l1OtvwFgbPGnRJSUdEq8q+GH5WaRl9v5EESZ4aeP/MsA/um0kjF2GWNsMWNscVNTk4+HJYqCSyEvYx+5hFwrBGFLzqgVxthzAPazWXUD5/wJY5sbACQBPOC0H875PADzAGDWrFlUIssFaZFHytgiL9eKhSDKhJxCzjk/2W09Y2wugLMAnMQ5mUyhQ/rIw2CREwRhS1Fx5Iyx0wFcB+A4znmHP6dElJSMkEeUwUHlKuRkJxCEHcX6yG8DUA9gAWNsGWPsDh/OiSglGddKGVvksmKhBh9B2FKURc45n+zXiRB9hF1nZ9nl/ZYVCwk5QdhRbiWWKDVDJ4n3sbPKt7Oz3M6HIMoMEvL+zvijga+/CXzsKyEYEEQQhB2UNIsARhwo3tUEWuUI+cgJwhayyIkQUKYVC0GUCSTkhIm0eMvVIicIwhZyrRAK0nVRZkJ+8g+Azj3AAaf19ZkQRFlCQk6YlKtFPqQR+OITfX0WBFG2kGuFUChTi5wgCFdIyAmTjI6TkBNEmCAhJ0wixuMQr+3b8yAIIi/IR06YTDwOmHMVcPTX+/pMCILIAxJywiQSFREiBEGECnKtEARBhBwScoIgiJBDQk4QBBFySMgJgiBCDgk5QRBEyCEhJwiCCDkk5ARBECGHhJwgCCLkMN4Hs64wxpoAfFTgz4cD2OXj6YQBuub+AV1z/6CYa57AOW/QF/aJkBcDY2wx53xWX59HKaFr7h/QNfcPgrhmcq0QBEGEHBJygiCIkBNGIZ/X1yfQB9A19w/omvsHvl9z6HzkBEEQhJUwWuQEQRCEAgk5QRBEyAmVkDPGTmeMrWGMrWWMXd/X5+MXjLG7GWM7GWMrlWVDGWMLGGMfGO9DlHXfNe7BGsbYaX1z1oXDGBvHGFvIGFvNGFvFGPuWsbySr7maMbaIMfaOcc03Gcsr9poljLEoY+xtxth843tFXzNjbANjbAVjbBljbLGxLNhr5pyH4gUgCmAdgEkAEgDeATC9r8/Lp2s7FsDhAFYqy34O4Hrj8/UA/s/4PN249ioAE417Eu3ra8jzekcBONz4XA/gfeO6KvmaGYABxuc4gDcBHF3J16xc+1UA/gJgvvG9oq8ZwAYAw7VlgV5zmCzyIwGs5Zx/yDnvAfAggHP7+Jx8gXP+MoA92uJzAdxrfL4XwHnK8gc5592c8/UA1kLcm9DAOd/GOV9qfG4FsBrAGFT2NXPOeZvxNW68OCr4mgGAMTYWwJkA/qgsruhrdiDQaw6TkI8BsEn5vtlYVqmM5JxvA4TwARhhLK+o+8AYawQwE8JCrehrNlwMywDsBLCAc17x1wzgFgDXAkgryyr9mjmAfzHGljDGLjOWBXrNYZp8mdks64+xkxVzHxhjAwA8CuBKzvk+xuwuTWxqsyx018w5TwE4jDE2GMDjjLGDXDYP/TUzxs4CsJNzvoQxdryXn9gsC9U1G8zmnG9ljI0AsIAx9p7Ltr5cc5gs8s0AxinfxwLY2kfnUgp2MMZGAYDxvtNYXhH3gTEWhxDxBzjnjxmLK/qaJZzzZgAvAjgdlX3NswGcwxjbAOEKPZEx9mdU9jWDc77VeN8J4HEIV0mg1xwmIX8LwBTG2ETGWALARQCe7ONzCpInAcw1Ps8F8ISy/CLGWBVjbCKAKQAW9cH5FQwTpvddAFZzzm9WVlXyNTcYljgYYzUATgbwHir4mjnn3+Wcj+WcN0KU1xc4519ABV8zY6yOMVYvPwM4FcBKBH3Nfd3Dm2dv8CchIhzWAbihr8/Hx+v6K4BtAHohauj/BDAMwPMAPjDehyrb32DcgzUAzujr8y/geudANB+XA1hmvD5Z4dd8CIC3jWteCeD7xvKKvWbt+o+HGbVSsdcMEVX3jvFaJXUq6GumIfoEQRAhJ0yuFYIgCMIGEnKCIIiQQ0JOEAQRckjICYIgQg4JOUEQRMghIScIggg5JOQEQRAh5/8B1OQj8SsBTmUAAAAASUVORK5CYII=",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "#plot the figures\n",
                "left_boundary = 0\n",
                "right_boundary = 500\n",
                "t = np.arange(left_boundary,right_boundary)\n",
                "plt.plot(t,Tau[left_boundary:right_boundary,0])\n",
                "plt.plot(t,TauPred[left_boundary:right_boundary,0])\n",
                "plt.show()\n",
                "\n",
                "plt.plot(t,Tau[left_boundary:right_boundary,1])\n",
                "plt.plot(t,TauPred[left_boundary:right_boundary,1])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "## Computing Jacobian in the case of stiff-ODE\n",
                "states_dot_sym = sympy.Matrix([states_dot_sym[0], states_dot_sym[1], eom[0], eom[1]])\n",
                "Jac = states_dot_sym.jacobian(states_sym)\n",
                "\n",
                "## Please copy the string shown to the definition of equation in the function of Jacobian\n",
                "for i in range(Jac.shape[0]):\n",
                "    for j in range(Jac.shape[1]):\n",
                "        print('Equation ' + str(i) + ',' + str(j) + ': ' + str(Jac[i,j]))\n",
                "        print('\\n')\n",
                "\n",
                "def Jac(t, y):\n",
                "    from numpy import cos, sin, sign\n",
                "    x0, x1, x0_t, x1_t = y\n",
                "    tau0, tau1 = 0, 0 \n",
                "    J = np.zeros((4,4))\n",
                "    J[0,0] = 0\n",
                "    J[0,1] = 0\n",
                "    J[0,2] = 1\n",
                "    J[0,3] = 0\n",
                "\n",
                "    J[1,0] = 0\n",
                "    J[1,1] = 0\n",
                "    J[1,2] = 0\n",
                "    J[1,3] = 1\n",
                "\n",
                "    J[2,0] = 1.0*(2.0*sin(x0)*sin(x1) + 2.0*cos(x0)*cos(x1))*(x0_t**2*sin(x0)*sin(x1) + x0_t**2*cos(x0)*cos(x1))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) + 0.0625*(2.0*sin(x0)*sin(x1) + 2.0*cos(x0)*cos(x1))*(4.0*sin(x0)**2*sin(x1)*cos(x1) - 4.0*sin(x0)*sin(x1)**2*cos(x0) + 4.0*sin(x0)*cos(x0)*cos(x1)**2 - 4.0*sin(x1)*cos(x0)**2*cos(x1))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) + 0.5*x0_t - 0.5*x1_t - 9.8*sin(x1))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2 + 1.0*(-2.0*sin(x0)*cos(x1) + 2.0*sin(x1)*cos(x0))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) + 0.5*x0_t - 0.5*x1_t - 9.8*sin(x1))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) - 2.0*(-x1_t**2*sin(x0)*sin(x1) - x1_t**2*cos(x0)*cos(x1) - 19.6*cos(x0))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) - 0.125*(4.0*sin(x0)**2*sin(x1)*cos(x1) - 4.0*sin(x0)*sin(x1)**2*cos(x0) + 4.0*sin(x0)*cos(x0)*cos(x1)**2 - 4.0*sin(x1)*cos(x0)**2*cos(x1))*(tau0 - tau1 - 1.0*x0_t + 0.5*x1_t - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2\n",
                "    J[2,1] = 1.0*(2.0*sin(x0)*sin(x1) + 2.0*cos(x0)*cos(x1))*(-x0_t**2*sin(x0)*sin(x1) - x0_t**2*cos(x0)*cos(x1) - 9.8*cos(x1))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) + 0.0625*(2.0*sin(x0)*sin(x1) + 2.0*cos(x0)*cos(x1))*(-4.0*sin(x0)**2*sin(x1)*cos(x1) + 4.0*sin(x0)*sin(x1)**2*cos(x0) - 4.0*sin(x0)*cos(x0)*cos(x1)**2 + 4.0*sin(x1)*cos(x0)**2*cos(x1))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) + 0.5*x0_t - 0.5*x1_t - 9.8*sin(x1))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2 + 1.0*(2.0*sin(x0)*cos(x1) - 2.0*sin(x1)*cos(x0))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) + 0.5*x0_t - 0.5*x1_t - 9.8*sin(x1))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) - 2.0*(x1_t**2*sin(x0)*sin(x1) + x1_t**2*cos(x0)*cos(x1))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0) - 0.125*(-4.0*sin(x0)**2*sin(x1)*cos(x1) + 4.0*sin(x0)*sin(x1)**2*cos(x0) - 4.0*sin(x0)*cos(x0)*cos(x1)**2 + 4.0*sin(x1)*cos(x0)**2*cos(x1))*(tau0 - tau1 - 1.0*x0_t + 0.5*x1_t - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2\n",
                "    J[2,2] = 1.0*(2.0*sin(x0)*sin(x1) + 2.0*cos(x0)*cos(x1))*(2*x0_t*sin(x0)*cos(x1) - 2*x0_t*sin(x1)*cos(x0))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0)\n",
                "    J[2,3] = -2.0*(-2*x1_t*sin(x0)*cos(x1) + 2*x1_t*sin(x1)*cos(x0))/(2.0*sin(x0)**2*sin(x1)**2 + 4.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 2.0*cos(x0)**2*cos(x1)**2 - 4.0)\n",
                "\n",
                "    J[3,0] = 1.0*(1.0*sin(x0)*sin(x1) + 1.0*cos(x0)*cos(x1))*(-x1_t**2*sin(x0)*sin(x1) - x1_t**2*cos(x0)*cos(x1) - 19.6*cos(x0))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) + 0.25*(1.0*sin(x0)*sin(x1) + 1.0*cos(x0)*cos(x1))*(2.0*sin(x0)**2*sin(x1)*cos(x1) - 2.0*sin(x0)*sin(x1)**2*cos(x0) + 2.0*sin(x0)*cos(x0)*cos(x1)**2 - 2.0*sin(x1)*cos(x0)**2*cos(x1))*(tau0 - tau1 - 1.0*x0_t + 0.5*x1_t - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2 + 1.0*(-1.0*sin(x0)*cos(x1) + 1.0*sin(x1)*cos(x0))*(tau0 - tau1 - 1.0*x0_t + 0.5*x1_t - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) - 2.0*(x0_t**2*sin(x0)*sin(x1) + x0_t**2*cos(x0)*cos(x1))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) - 0.5*(2.0*sin(x0)**2*sin(x1)*cos(x1) - 2.0*sin(x0)*sin(x1)**2*cos(x0) + 2.0*sin(x0)*cos(x0)*cos(x1)**2 - 2.0*sin(x1)*cos(x0)**2*cos(x1))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) + 0.5*x0_t - 0.5*x1_t - 9.8*sin(x1))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2\n",
                "    J[3,1] = 1.0*(1.0*sin(x0)*sin(x1) + 1.0*cos(x0)*cos(x1))*(x1_t**2*sin(x0)*sin(x1) + x1_t**2*cos(x0)*cos(x1))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) + 0.25*(1.0*sin(x0)*sin(x1) + 1.0*cos(x0)*cos(x1))*(-2.0*sin(x0)**2*sin(x1)*cos(x1) + 2.0*sin(x0)*sin(x1)**2*cos(x0) - 2.0*sin(x0)*cos(x0)*cos(x1)**2 + 2.0*sin(x1)*cos(x0)**2*cos(x1))*(tau0 - tau1 - 1.0*x0_t + 0.5*x1_t - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2 + 1.0*(1.0*sin(x0)*cos(x1) - 1.0*sin(x1)*cos(x0))*(tau0 - tau1 - 1.0*x0_t + 0.5*x1_t - x1_t**2*sin(x0)*cos(x1) + x1_t**2*sin(x1)*cos(x0) - 19.6*sin(x0))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) - 2.0*(-x0_t**2*sin(x0)*sin(x1) - x0_t**2*cos(x0)*cos(x1) - 9.8*cos(x1))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0) - 0.5*(-2.0*sin(x0)**2*sin(x1)*cos(x1) + 2.0*sin(x0)*sin(x1)**2*cos(x0) - 2.0*sin(x0)*cos(x0)*cos(x1)**2 + 2.0*sin(x1)*cos(x0)**2*cos(x1))*(tau1 + x0_t**2*sin(x0)*cos(x1) - x0_t**2*sin(x1)*cos(x0) + 0.5*x0_t - 0.5*x1_t - 9.8*sin(x1))/(0.5*sin(x0)**2*sin(x1)**2 + sin(x0)*sin(x1)*cos(x0)*cos(x1) + 0.5*cos(x0)**2*cos(x1)**2 - 1)**2\n",
                "    J[3,2] = -2.0*(2*x0_t*sin(x0)*cos(x1) - 2*x0_t*sin(x1)*cos(x0))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0)\n",
                "    J[3,3] = 1.0*(1.0*sin(x0)*sin(x1) + 1.0*cos(x0)*cos(x1))*(-2*x1_t*sin(x0)*cos(x1) + 2*x1_t*sin(x1)*cos(x0))/(1.0*sin(x0)**2*sin(x1)**2 + 2.0*sin(x0)*sin(x1)*cos(x0)*cos(x1) + 1.0*cos(x0)**2*cos(x1)**2 - 2.0)\n",
                "    return J\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Debugging odeint vs solve_ivp\n",
                "\n",
                "t = np.arange(0,5,0.01)\n",
                "theta1 = np.random.uniform(-np.pi, np.pi)\n",
                "theta2 = np.random.uniform(-np.pi, np.pi)\n",
                "thetadot = np.random.uniform(0,0)\n",
                "omega = np.random.uniform(-np.pi, np.pi)\n",
                "  \n",
                "y0=np.array([theta1, theta2, thetadot, thetadot])\n",
                "\n",
                "from scipy.integrate import odeint\n",
                "X = odeint(doublePendulum, y0, t, args=(omega,))\n",
                "Xdot = doublePendulum(X,t,omega)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Debugging\n",
                "device = 'cuda:0'\n",
                "expr = np.array(expr)\n",
                "\n",
                "i1 = np.where(expr == 'x0_t**2')[0][0]\n",
                "i2 = np.where(expr == 'x1_t**2')[0][0]\n",
                "i3 = np.where(expr == 'cos(x0)')[0][0]\n",
                "i4 = np.where(expr == 'cos(x1)')[0][0]\n",
                "i5 = np.where(expr == 'x0_t*x1_t*cos(x0)*cos(x1)')[0][0]\n",
                "i6 = np.where(expr == 'x0_t*x1_t*sin(x0)*sin(x1)')[0][0]\n",
                "\n",
                "xi_L = torch.zeros(len(expr), device=device)\n",
                "\n",
                "#Creating library tensor\n",
                "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)\n",
                "Zeta = Zeta.to(device)\n",
                "Eta = Eta.to(device)\n",
                "Delta = Delta.to(device)\n",
                "\n",
                "xi_L[i1] = 1.0\n",
                "xi_L[i2] = 0.5\n",
                "xi_L[i3] = 19.62\n",
                "xi_L[i4] = 9.81\n",
                "xi_L[i5] = 1.0\n",
                "xi_L[i6] = 1.0\n",
                "\n",
                "xdot = torch.from_numpy(Xdot).to(device).float()\n",
                "TauPred = ELforward(xi_L,Zeta,Eta,Delta,xdot,device).detach().cpu().numpy()\n",
                "q_tt_pred = lagrangianforward(xi_L,Zeta,Eta,Delta,xdot,device).detach().cpu().numpy()\n",
                "q_tt = Xdot[:,2:4]\n",
                "\n",
                "t = np.arange(0,2000)\n",
                "plt.plot(t,Tau[:2000,0])\n",
                "plt.plot(t,TauPred[0,:2000])\n",
                "plt.show()\n",
                "\n",
                "plt.plot(t,Tau[:2000,1])\n",
                "plt.plot(t,TauPred[1,:2000])\n",
                "plt.show()\n",
                "\n",
                "t = np.arange(0,2000)\n",
                "plt.plot(t,q_tt[:2000,0])\n",
                "plt.plot(t,q_tt_pred[0,:2000])\n",
                "plt.show()\n",
                "\n",
                "plt.plot(t,q_tt[:2000,1])\n",
                "plt.plot(t,q_tt_pred[1,:2000])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.10 ('SystemIdentification')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "a4ed4680c7c46a218b8058c2660cec6a650dc98debbf7bcbd09838ba710de1ba"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
