{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys \n",
    "sys.path.append(r'../Python Script/')\n",
    "\n",
    "from sympy import symbols, simplify, derive_by_array\n",
    "from scipy.integrate import solve_ivp\n",
    "from xLSINDy import *\n",
    "from sympy.physics.mechanics import *\n",
    "from sympy import *\n",
    "import sympy\n",
    "import sympy\n",
    "import torch\n",
    "import HLsearch as HL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def generate_data(func, time, init_values):\n",
    "    sol = solve_ivp(func,[time[0],time[-1]],init_values,t_eval=time, method='RK45',rtol=1e-10,atol=1e-10)\n",
    "    return sol.y.T, np.array([func(0,sol.y.T[i,:]) for i in range(sol.y.T.shape[0])],dtype=np.float64)\n",
    "\n",
    "def pendulum(t,x):\n",
    "    return x[1],-9.81*np.sin(x[0])\n",
    "\n",
    "g=9.81\n",
    "mp=0.5\n",
    "\n",
    "mc=1\n",
    "l=1\n",
    "\n",
    "def cartpole(t,y,f=0.0):\n",
    "    theta,x,thetadot,xdot = y\n",
    "    xdotdot = (f+mp*np.sin(theta)*(l*thetadot**2+g*np.cos(theta)))/(mc+mp*np.sin(theta)**2)\n",
    "    thetadotdot = (-f*np.cos(theta)-mp*l*thetadot**2*np.cos(theta)*np.sin(theta)-(mc+mp)*g*np.sin(theta))/(l*(mc+mp*np.sin(theta)**2))\n",
    "    return thetadot,xdot,thetadotdot,xdotdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Directory\n",
    "rootdir = \"../Cart Pendulum/Data/\"\n",
    "\n",
    "num_sample = 100\n",
    "create_data = True\n",
    "training = True\n",
    "save = False\n",
    "noiselevel = 2e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(create_data):\n",
    "    X, Xdot = [], []\n",
    "    for i in range(num_sample):\n",
    "        t = np.arange(0,5,0.01)\n",
    "        theta = np.random.uniform(-np.pi, np.pi)\n",
    "        thetadot = np.random.uniform(0,0)\n",
    "\n",
    "        y0=np.array([theta, 0, thetadot, 0])\n",
    "        x,xdot = generate_data(cartpole,t,y0)\n",
    "        X.append(x)\n",
    "        Xdot.append(xdot)\n",
    "    X = np.vstack(X)\n",
    "    Xdot = np.vstack(Xdot) \n",
    "    if(save==True):\n",
    "        np.save(rootdir + \"X.npy\", X)\n",
    "        np.save(rootdir + \"Xdot.npy\",Xdot)\n",
    "\n",
    "  \n",
    "else:\n",
    "    X = np.load(rootdir + \"X.npy\")\n",
    "    Xdot = np.load(rootdir + \"Xdot.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding noise\n",
    "mu, sigma = 0, noiselevel\n",
    "noise = np.random.normal(mu, sigma, X.shape[0])\n",
    "for i in range(X.shape[1]):\n",
    "    X[:,i] = X[:,i]+noise\n",
    "    Xdot[:,i] = Xdot[:,i]+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_dim = 4\n",
    "states = ()\n",
    "states_dot = ()\n",
    "for i in range(states_dim):\n",
    "    if(i<states_dim//2):\n",
    "        states = states + (symbols('x{}'.format(i)),)\n",
    "        states_dot = states_dot + (symbols('x{}_t'.format(i)),)\n",
    "    else:\n",
    "        states = states + (symbols('x{}_t'.format(i-states_dim//2)),)\n",
    "        states_dot = states_dot + (symbols('x{}_tt'.format(i-states_dim//2)),)\n",
    "print('states are:',states)\n",
    "print('states derivatives are: ', states_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn from sympy to str\n",
    "states_sym = states\n",
    "states_dot_sym = states_dot\n",
    "states = list(str(descr) for descr in states)\n",
    "states_dot = list(str(descr) for descr in states_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating states of pendulum and cart\n",
    "pendulum_states = []\n",
    "cartpole_states = []\n",
    "for i in range(states_dim):\n",
    "    if(i%2==0):\n",
    "        pendulum_states.append(states[i])\n",
    "    else:\n",
    "        cartpole_states.append(states[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build function expression for the library in str\n",
    "pend_terms = HL.buildFunctionExpressions(1,states_dim//2,pendulum_states,use_sine=True)\n",
    "cartpole_terms = HL.buildFunctionExpressions(1,states_dim//2,cartpole_states,use_sine=False)\n",
    "\n",
    "#Assuming we get a prior knowledge about a single pendulum equations\n",
    "temp = pend_terms[1:] + cartpole_terms\n",
    "expr = HL.buildFunctionExpressions(3,len(temp),temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating library tensor\n",
    "Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating known and unknown terms\n",
    "expr = np.array(expr)\n",
    "i1 = np.where(expr == 'x0_t**2')[0]\n",
    "\n",
    "#Deleting unused terms\n",
    "idx = np.arange(0,len(expr))\n",
    "idx = np.delete(idx,i1)\n",
    "known_expr = expr[i1].tolist()\n",
    "expr = np.delete(expr,i1)\n",
    "\n",
    "#non-penalty index from prev knowledge\n",
    "i2 = np.where(expr == 'cos(x0)')[0][0]\n",
    "nonpenaltyidx = [i2]\n",
    "\n",
    "expr = expr.tolist()\n",
    "\n",
    "Zeta_ = Zeta[:,:,i1,:].clone().detach()\n",
    "Eta_ = Eta[:,:,i1,:].clone().detach()\n",
    "Delta_ = Delta[:,i1,:].clone().detach()\n",
    "\n",
    "Zeta = Zeta[:,:,idx,:]\n",
    "Eta = Eta[:,:,idx,:]\n",
    "Delta = Delta[:,idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving to Cuda\n",
    "device = 'cuda:0'\n",
    "\n",
    "Zeta = Zeta.to(device)\n",
    "Eta = Eta.to(device)\n",
    "Delta = Delta.to(device)\n",
    "\n",
    "Zeta_ = Zeta_.to(device)\n",
    "Eta_ = Eta_.to(device)\n",
    "Delta_ = Delta_.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_L = torch.ones(len(expr), device=device).data.uniform_(-10,10)\n",
    "prevxi_L = xi_L.clone().detach()\n",
    "c = torch.ones(len(known_expr), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, targ):\n",
    "    loss = torch.mean((pred - targ)**2) \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(w, alpha):\n",
    "    clipped = torch.minimum(w,alpha)\n",
    "    clipped = torch.maximum(clipped,-alpha)\n",
    "    return clipped\n",
    "\n",
    "def proxL1norm(w_hat, alpha, nonpenaltyidx):\n",
    "    if(torch.is_tensor(alpha)==False):\n",
    "        alpha = torch.tensor(alpha)\n",
    "    w = w_hat - clip(w_hat,alpha)\n",
    "    for idx in nonpenaltyidx:\n",
    "        w[idx] = w_hat[idx]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(c, coef, prevcoef, RHS, LHS, xdot, bs, lr, lam, momentum=True):\n",
    "    loss_list = []\n",
    "    tl = xdot.shape[0]\n",
    "    n = xdot.shape[1]\n",
    "\n",
    "    Zeta_, Eta_, Delta_ = LHS\n",
    "    Zeta, Eta, Delta = RHS\n",
    "\n",
    "    if(torch.is_tensor(xdot)==False):\n",
    "        xdot = torch.from_numpy(xdot).to(device).float()\n",
    "    \n",
    "    v = coef.clone().detach().requires_grad_(True)\n",
    "    prev = v\n",
    "    \n",
    "    for i in range(tl//bs):\n",
    "                \n",
    "        #computing acceleration with momentum\n",
    "        if(momentum==True):\n",
    "            vhat = (v + ((i-1)/(i+2))*(v - prev)).clone().detach().requires_grad_(True)\n",
    "        else:\n",
    "            vhat = v.requires_grad_(True).clone().detach().requires_grad_(True)\n",
    "   \n",
    "        prev = v\n",
    "\n",
    "        #Computing loss\n",
    "        zeta = Zeta[:,:,:,i*bs:(i+1)*bs]\n",
    "        eta = Eta[:,:,:,i*bs:(i+1)*bs]\n",
    "        delta = Delta[:,:,i*bs:(i+1)*bs]\n",
    "\n",
    "        zeta_ = Zeta_[:,:,:,i*bs:(i+1)*bs]\n",
    "        eta_ = Eta_[:,:,:,i*bs:(i+1)*bs]\n",
    "        delta_ = Delta_[:,:,i*bs:(i+1)*bs]\n",
    "        \n",
    "        x_t = xdot[i*bs:(i+1)*bs,:]\n",
    "\n",
    "        #forward\n",
    "        pred = -ELforward(vhat,zeta,eta,delta,x_t,device)\n",
    "        targ = ELforward(c,zeta_,eta_,delta_,x_t,device)\n",
    "        \n",
    "        lossval = loss(pred, targ)\n",
    "        \n",
    "        #Backpropagation\n",
    "        lossval.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            v = vhat - lr*vhat.grad\n",
    "            v = (proxL1norm(v,lr*lam,nonpenaltyidx))\n",
    "            \n",
    "            # Manually zero the gradients after updating weights\n",
    "            vhat.grad = None\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        loss_list.append(lossval.item())\n",
    "    print(\"Average loss : \" , torch.tensor(loss_list).mean().item())\n",
    "    return v, prevcoef, torch.tensor(loss_list).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First Stage\")\n",
    "Epoch = 100\n",
    "i = 0\n",
    "lr = 1e-5\n",
    "lam = 1\n",
    "temp = 1000\n",
    "RHS = [Zeta, Eta, Delta]\n",
    "LHS = [Zeta_, Eta_, Delta_]\n",
    "while(i<=Epoch):\n",
    "    print(\"\\n\")\n",
    "    print(\"Epoch \"+str(i) + \"/\" + str(Epoch))\n",
    "    print(\"Learning rate : \", lr)\n",
    "    xi_L, prevxi_L, lossitem= training_loop(c, xi_L,prevxi_L,RHS,LHS,Xdot,128,lr=lr,lam=lam)\n",
    "    temp = lossitem\n",
    "    if(i>50):\n",
    "        lr = 1e-5\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thresholding\n",
    "threshold = 1e-2\n",
    "surv_index = ((torch.abs(xi_L) >= threshold)).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
    "expr = np.array(expr)[surv_index].tolist()\n",
    "\n",
    "xi_L =xi_L[surv_index].clone().detach().requires_grad_(True)\n",
    "prevxi_L = xi_L.clone().detach()\n",
    "\n",
    "## obtaining analytical model\n",
    "xi_Lcpu = np.around(xi_L.detach().cpu().numpy(),decimals=2)\n",
    "L = HL.generateExpression(xi_Lcpu,expr,threshold=1e-3)\n",
    "print(\"Result stage 1: \", simplify(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next round selection ##\n",
    "for stage in range(3):\n",
    "\n",
    "    #Redefine computation after thresholding\n",
    "    expr.append(known_expr[0])\n",
    "    Zeta, Eta, Delta = LagrangianLibraryTensor(X,Xdot,expr,states,states_dot, scaling=False)\n",
    "\n",
    "    expr = np.array(expr)\n",
    "    i1 = np.where(expr == 'x0_t**2')[0]\n",
    "    idx = np.arange(0,len(expr))\n",
    "    idx = np.delete(idx,i1)\n",
    "    known_expr = expr[i1].tolist()\n",
    "    expr = np.delete(expr,i1).tolist()\n",
    "    nonpenaltyidx = []\n",
    "\n",
    "    Zeta_ = Zeta[:,:,i1,:].clone().detach()\n",
    "    Eta_ = Eta[:,:,i1,:].clone().detach()\n",
    "    Delta_ = Delta[:,i1,:].clone().detach()\n",
    "\n",
    "    Zeta = Zeta[:,:,idx,:]\n",
    "    Eta = Eta[:,:,idx,:]\n",
    "    Delta = Delta[:,idx,:]\n",
    "\n",
    "    Zeta = Zeta.to(device)\n",
    "    Eta = Eta.to(device)\n",
    "    Delta = Delta.to(device)\n",
    "    Zeta_ = Zeta_.to(device)\n",
    "    Eta_ = Eta_.to(device)\n",
    "    Delta_ = Delta_.to(device)\n",
    "\n",
    "    #Training\n",
    "    Epoch = 100\n",
    "    i = 0\n",
    "    lr += lr\n",
    "    if(stage==3):\n",
    "        lam = 0\n",
    "    else:\n",
    "        lam = 0.1\n",
    "    temp = 1000\n",
    "    RHS = [Zeta, Eta, Delta]\n",
    "    LHS = [Zeta_, Eta_, Delta_]\n",
    "    while(i<=Epoch):\n",
    "        print(\"\\n\")\n",
    "        print(\"Epoch \"+str(i) + \"/\" + str(Epoch))\n",
    "        print(\"Learning rate : \", lr)\n",
    "        xi_L, prevxi_L, lossitem= training_loop(c, xi_L,prevxi_L,RHS,LHS,Xdot,128,lr=lr,lam=lam)\n",
    "        temp = lossitem\n",
    "        i+=1\n",
    "        if(temp <2e-3):\n",
    "            break\n",
    "    \n",
    "    ## Thresholding\n",
    "    threshold = 1e-1\n",
    "    surv_index = ((torch.abs(xi_L) >= threshold)).nonzero(as_tuple=True)[0].detach().cpu().numpy()\n",
    "    expr = np.array(expr)[surv_index].tolist()\n",
    "\n",
    "    xi_L =xi_L[surv_index].clone().detach().requires_grad_(True)\n",
    "    prevxi_L = xi_L.clone().detach()\n",
    "\n",
    "    ## obtaining analytical model\n",
    "    xi_Lcpu = np.around(xi_L.detach().cpu().numpy(),decimals=3)\n",
    "    L = HL.generateExpression(xi_Lcpu,expr,threshold=1e-2)\n",
    "    print(\"Result stage \" + str(stage+2) + \":\" , simplify(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding known terms\n",
    "L = str(simplify(L)) + \" + \" + known_expr[0]\n",
    "print(\"Obtained Lagrangain:\" ,L)\n",
    "\n",
    "expr = expr + known_expr\n",
    "xi_L = torch.cat((xi_L, c))\n",
    "mask = torch.ones(len(xi_L),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(save==True):\n",
    "    #Saving Equation in string\n",
    "    text_file = open(rootdir + \"lagrangian_\" + str(noiselevel)+ \"_noise.txt\", \"w\")\n",
    "    text_file.write(L)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('SystemIdentification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4ed4680c7c46a218b8058c2660cec6a650dc98debbf7bcbd09838ba710de1ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
